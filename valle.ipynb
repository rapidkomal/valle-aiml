{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rapidkomal/valle-aiml/blob/valle-project/valle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL_jUD_kbXUC",
        "outputId": "4e886cf0-ee3a-415b-9134-bb8e68837f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.10\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "ModuleNotFoundError: No module named 'pip'\n"
          ]
        }
      ],
      "source": [
        "!python --version; pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_qqXduflv9B",
        "outputId": "af79d3cb-dd75-4705-efcd-5174b07b6b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 2513k  100 2513k    0     0  41.6M      0 --:--:-- --:--:-- --:--:-- 41.6M\n"
          ]
        }
      ],
      "source": [
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQNUmCx7lwhN",
        "outputId": "0198774a-b03a-46ef-eeaa-dcacb5c7e773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip\n",
            "  Using cached pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.4.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-23.0.1 setuptools-67.4.0 wheel-0.38.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python get-pip.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycn1bIIWoMwN",
        "outputId": "7644dd41-1f06-4eeb-eca1-fd2544b09e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.10\n",
            "pip 23.0.1 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n"
          ]
        }
      ],
      "source": [
        "!python --version; pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsFXmcGHl43W",
        "outputId": "6d75f9af-48c3-4a48-c7a3-48bf11e40765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.10-minimal libpython3.10-stdlib python3.10-minimal\n",
            "Suggested packages:\n",
            "  python3.10-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.10-minimal libpython3.10-stdlib python3.10 python3.10-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 5,225 kB of archives.\n",
            "After this operation, 20.2 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.10-minimal amd64 3.10.10-1+focal1 [822 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.10-minimal amd64 3.10.10-1+focal1 [2,093 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.10-stdlib amd64 3.10.10-1+focal1 [1,759 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.10 amd64 3.10.10-1+focal1 [551 kB]\n",
            "Fetched 5,225 kB in 7s (769 kB/s)\n",
            "Selecting previously unselected package libpython3.10-minimal:amd64.\n",
            "(Reading database ... 128208 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.10-minimal_3.10.10-1+focal1_amd64.deb ...\n",
            "Unpacking libpython3.10-minimal:amd64 (3.10.10-1+focal1) ...\n",
            "Selecting previously unselected package python3.10-minimal.\n",
            "Preparing to unpack .../python3.10-minimal_3.10.10-1+focal1_amd64.deb ...\n",
            "Unpacking python3.10-minimal (3.10.10-1+focal1) ...\n",
            "Selecting previously unselected package libpython3.10-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.10-stdlib_3.10.10-1+focal1_amd64.deb ...\n",
            "Unpacking libpython3.10-stdlib:amd64 (3.10.10-1+focal1) ...\n",
            "Selecting previously unselected package python3.10.\n",
            "Preparing to unpack .../python3.10_3.10.10-1+focal1_amd64.deb ...\n",
            "Unpacking python3.10 (3.10.10-1+focal1) ...\n",
            "Setting up libpython3.10-minimal:amd64 (3.10.10-1+focal1) ...\n",
            "Setting up python3.10-minimal (3.10.10-1+focal1) ...\n",
            "Setting up libpython3.10-stdlib:amd64 (3.10.10-1+focal1) ...\n",
            "Setting up python3.10 (3.10.10-1+focal1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install python3.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zJDTDPaWmALB"
      },
      "outputs": [],
      "source": [
        "!ln -sf /usr/bin/python3.10 /usr/bin/python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNWiI_ZrW3Nz",
        "outputId": "3a0fbde0-f24a-4a6e-a21d-79cdb8b9c4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/include/python3.10\n"
          ]
        }
      ],
      "source": [
        "!python3 -c \"import distutils.sysconfig as sysconfig; print(sysconfig.get_python_inc())\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Kl0SA_Womp",
        "outputId": "2037b5a9-6c15-4a47-8a6e-e79a9c35ee99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.10-dev is already the newest version (3.10.10-1+focal1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install python3.10-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbkZUaXdmC5g",
        "outputId": "34fc8706-1b90-4731-cc4e-0ca89b6eeac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.10\n"
          ]
        }
      ],
      "source": [
        "!python3 --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wu_1-U9lwxX",
        "outputId": "d9d1690a-d31b-44c6-cb4b-02cafcb443d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vall-e'...\n",
            "remote: Enumerating objects: 407, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 407 (delta 45), reused 41 (delta 41), pack-reused 336\u001b[K\n",
            "Receiving objects: 100% (407/407), 1.94 MiB | 16.60 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n",
            "Submodule 'mini_vall_e/utils' (https://github.com/enhuiz/pytorch-training-utils.git) registered for path 'vall_e/utils'\n",
            "Cloning into '/content/vall-e/vall_e/utils'...\n",
            "remote: Enumerating objects: 331, done.        \n",
            "remote: Counting objects: 100% (36/36), done.        \n",
            "remote: Compressing objects: 100% (12/12), done.        \n",
            "remote: Total 331 (delta 29), reused 25 (delta 24), pack-reused 295        \n",
            "Receiving objects: 100% (331/331), 58.42 KiB | 14.60 MiB/s, done.\n",
            "Resolving deltas: 100% (207/207), done.\n",
            "Submodule path 'vall_e/utils': checked out '603cb4c4840a5787c6803e9595badba6b98e93ac'\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/enhuiz/vall-e.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2Du1pXrdY7Q",
        "outputId": "bbcfd367-28b4-47d1-90b1-923d4b11916e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vall-e\n"
          ]
        }
      ],
      "source": [
        "%cd vall-e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t0GAebE-dsFk",
        "outputId": "53a1dc6c-2681-48b6-fd25-10976df0a542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/vall-e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coloredlogs>=15.0.1\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed>=0.7.7\n",
            "  Downloading deepspeed-0.8.1.tar.gz (759 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.6/759.6 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting diskcache>=5.4.0\n",
            "  Downloading diskcache-5.4.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec>=0.1.1\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting g2p_en>=2.1.0\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanize>=4.4.0\n",
            "  Downloading humanize-4.6.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=3.6.0\n",
            "  Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.23.3\n",
            "  Downloading numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.2.3\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openTSNE>=0.6.2\n",
            "  Downloading openTSNE-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=1.5.0\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soundfile>=0.11.0\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=1.13.0\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio>=0.13.0\n",
            "  Downloading torchaudio-0.13.1-cp310-cp310-manylinux1_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-cpuinfo\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-1.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distance>=0.1.3\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting inflect>=0.3.1\n",
            "  Downloading inflect-6.0.2-py3-none-any.whl (34 kB)\n",
            "Collecting nltk>=3.2.4\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=0.20\n",
            "  Downloading scikit_learn-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cffi>=1.0\n",
            "  Downloading cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.8/441.8 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->vall-e==0.0.1.dev20230119082310) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->vall-e==0.0.1.dev20230119082310) (67.4.0)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex>=2021.8.3\n",
            "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: vall-e, deepspeed, encodec, antlr4-python3-runtime, distance\n",
            "  Building wheel for vall-e (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vall-e: filename=vall_e-0.0.1.dev20230119082310-py3-none-any.whl size=30928 sha256=5dd724ef7928208f5c8455ca5416038ea335889f667e4f141f6efc498cd105bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e2/f3/52410740625c97ef2dc7209314c9039d0cf700c40a373f6c16\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.8.1-py3-none-any.whl size=765841 sha256=0f020051788e17922f8d0e5e85f1b3003d8cf4a624221dfb155fe87fc529eeeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/3b/f3/0d41f09dee0c141026b75113dad74a13f22356caeaf0c6e175\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45761 sha256=18a1f30516a1e2b3eb35a219e232fff3268bdfb3a41dae2091720c6008af37bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=feac831b56b29208c1bbecb7f7099b6538743ca96cbba93349fb7c1902101ddb\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16257 sha256=be7d6298d59e49a34116c95e734753c88be06278f5570ba7353da258430e7726\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "Successfully built vall-e deepspeed encodec antlr4-python3-runtime distance\n",
            "Installing collected packages: pytz, py-cpuinfo, ninja, hjson, distance, antlr4-python3-runtime, typing-extensions, tqdm, threadpoolctl, six, regex, PyYAML, pyparsing, pycparser, psutil, pillow, packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, kiwisolver, joblib, humanize, humanfriendly, fonttools, einops, diskcache, cycler, click, scipy, python-dateutil, pydantic, omegaconf, nvidia-cudnn-cu11, nltk, contourpy, coloredlogs, cffi, torch, soundfile, scikit-learn, pandas, matplotlib, inflect, torchaudio, openTSNE, g2p_en, deepspeed, encodec, vall-e\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.9.3 cffi-1.15.1 click-8.1.3 coloredlogs-15.0.1 contourpy-1.0.7 cycler-0.11.0 deepspeed-0.8.1 diskcache-5.4.0 distance-0.1.3 einops-0.6.0 encodec-0.1.1 fonttools-4.38.0 g2p_en-2.1.0 hjson-3.1.0 humanfriendly-10.0 humanize-4.6.0 inflect-6.0.2 joblib-1.2.0 kiwisolver-1.4.4 matplotlib-3.7.0 ninja-1.11.1 nltk-3.8.1 numpy-1.24.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.3.0 openTSNE-0.7.1 packaging-23.0 pandas-1.5.3 pillow-9.4.0 psutil-5.9.4 py-cpuinfo-9.0.0 pycparser-2.21 pydantic-1.10.5 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.7.1 regex-2022.10.31 scikit-learn-1.2.1 scipy-1.10.1 six-1.16.0 soundfile-0.12.1 threadpoolctl-3.1.0 torch-1.13.1 torchaudio-0.13.1 tqdm-4.64.1 typing-extensions-4.5.0 vall-e-0.0.1.dev20230119082310\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cffi",
                  "cycler",
                  "dateutil",
                  "kiwisolver"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdVTkbJWT9xO",
        "outputId": "284be1f8-b4a3-42cd-9608-5cef15a649d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade ninja\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeYSDE17Puw0",
        "outputId": "40395945-1674-43c4-b44d-8bb37fed487c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test2.phn.txt  test.normalized.txt  test.qnt.pt\n",
            "test2.qnt.pt   test.phn.txt\t    test.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMgWyPw-pN1o",
        "outputId": "9a0f86a2-d7aa-4ef0-9cfe-093c54a5e395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/1 [00:00<?, ?it/s]\r100% 1/1 [00:00<00:00, 5275.85it/s]\n"
          ]
        }
      ],
      "source": [
        "!python -m vall_e.emb.qnt data/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRDVTnt6pVom",
        "outputId": "2d8f1659-81ae-4777-a3d8-56fa8f971fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
            "100% 1/1 [00:00<00:00, 12985.46it/s]\n"
          ]
        }
      ],
      "source": [
        "!python -m vall_e.emb.g2p data/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzxiRSYpV10",
        "outputId": "40260714-bf41-427e-ddc9-c19beb81bdd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0019330978393554688,\n",
            "  \"model.lr\": 0.000124778,\n",
            "  \"model.grad_norm\": 0.05602109432220459,\n",
            "  \"model.elapsed_time\": 0.07186603546142578,\n",
            "  \"model.engine_step\": 624,\n",
            "  \"model.loss.nll\": 0.0019330978393554688,\n",
            "  \"elapsed_time\": 0.07186603546142578,\n",
            "  \"wall_time\": 1677241366.365419,\n",
            "  \"global_step\": 624\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0104217529296875,\n",
            "  \"model.lr\": 0.000124977,\n",
            "  \"model.grad_norm\": 0.8402513861656189,\n",
            "  \"model.elapsed_time\": 0.06535100936889648,\n",
            "  \"model.engine_step\": 625,\n",
            "  \"model.loss.nll\": 0.0104217529296875,\n",
            "  \"elapsed_time\": 0.06535100936889648,\n",
            "  \"wall_time\": 1677241366.4377658,\n",
            "  \"global_step\": 625\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0145416259765625,\n",
            "  \"model.lr\": 0.000125176,\n",
            "  \"model.grad_norm\": 1.3764934539794922,\n",
            "  \"model.elapsed_time\": 0.0661020278930664,\n",
            "  \"model.engine_step\": 626,\n",
            "  \"model.loss.nll\": 0.0145416259765625,\n",
            "  \"elapsed_time\": 0.0661020278930664,\n",
            "  \"wall_time\": 1677241366.5059743,\n",
            "  \"global_step\": 626\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001758575439453125,\n",
            "  \"model.lr\": 0.000125375,\n",
            "  \"model.grad_norm\": 0.047535240650177,\n",
            "  \"model.elapsed_time\": 0.06663966178894043,\n",
            "  \"model.engine_step\": 627,\n",
            "  \"model.loss.nll\": 0.001758575439453125,\n",
            "  \"elapsed_time\": 0.06663966178894043,\n",
            "  \"wall_time\": 1677241366.5800505,\n",
            "  \"global_step\": 627\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0092926025390625,\n",
            "  \"model.lr\": 0.00012557400000000001,\n",
            "  \"model.grad_norm\": 0.845553457736969,\n",
            "  \"model.elapsed_time\": 0.07200241088867188,\n",
            "  \"model.engine_step\": 628,\n",
            "  \"model.loss.nll\": 0.0092926025390625,\n",
            "  \"elapsed_time\": 0.07200241088867188,\n",
            "  \"wall_time\": 1677241366.6542697,\n",
            "  \"global_step\": 628\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0020198822021484375,\n",
            "  \"model.lr\": 0.000125773,\n",
            "  \"model.grad_norm\": 0.07660593092441559,\n",
            "  \"model.elapsed_time\": 0.06952524185180664,\n",
            "  \"model.engine_step\": 629,\n",
            "  \"model.loss.nll\": 0.0020198822021484375,\n",
            "  \"elapsed_time\": 0.06952524185180664,\n",
            "  \"wall_time\": 1677241366.732041,\n",
            "  \"global_step\": 629\n",
            "}\n",
            "[2023-02-24 12:22:46,798] [INFO] [logging.py:75:log_dist] [Rank 0] step=630, skipped=1, lr=[0.000125972], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:46,800] [INFO] [timer.py:198:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=13.03991466326342, CurrSamplesPerSec=14.92342779882941, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.034698486328125,\n",
            "  \"model.lr\": 0.000125972,\n",
            "  \"model.grad_norm\": 1.493747591972351,\n",
            "  \"model.elapsed_time\": 0.06748747825622559,\n",
            "  \"model.engine_step\": 630,\n",
            "  \"model.loss.nll\": 0.034698486328125,\n",
            "  \"elapsed_time\": 0.06748747825622559,\n",
            "  \"wall_time\": 1677241366.8017244,\n",
            "  \"global_step\": 630\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.01009368896484375,\n",
            "  \"model.lr\": 0.000126171,\n",
            "  \"model.grad_norm\": 0.6763054728507996,\n",
            "  \"model.elapsed_time\": 0.08138918876647949,\n",
            "  \"model.engine_step\": 631,\n",
            "  \"model.loss.nll\": 0.01009368896484375,\n",
            "  \"elapsed_time\": 0.08138918876647949,\n",
            "  \"wall_time\": 1677241366.8911176,\n",
            "  \"global_step\": 631\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00899505615234375,\n",
            "  \"model.lr\": 0.00012637,\n",
            "  \"model.grad_norm\": 0.6679186820983887,\n",
            "  \"model.elapsed_time\": 0.07643747329711914,\n",
            "  \"model.engine_step\": 632,\n",
            "  \"model.loss.nll\": 0.00899505615234375,\n",
            "  \"elapsed_time\": 0.07643747329711914,\n",
            "  \"wall_time\": 1677241366.9698465,\n",
            "  \"global_step\": 632\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:46\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0017461776733398438,\n",
            "  \"model.lr\": 0.00012656900000000001,\n",
            "  \"model.grad_norm\": 0.04963291436433792,\n",
            "  \"model.elapsed_time\": 0.07481598854064941,\n",
            "  \"model.engine_step\": 633,\n",
            "  \"model.loss.nll\": 0.0017461776733398438,\n",
            "  \"elapsed_time\": 0.07481598854064941,\n",
            "  \"wall_time\": 1677241367.052417,\n",
            "  \"global_step\": 633\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.022308349609375,\n",
            "  \"model.lr\": 0.000126768,\n",
            "  \"model.grad_norm\": 1.6048879623413086,\n",
            "  \"model.elapsed_time\": 0.07134675979614258,\n",
            "  \"model.engine_step\": 634,\n",
            "  \"model.loss.nll\": 0.022308349609375,\n",
            "  \"elapsed_time\": 0.07134675979614258,\n",
            "  \"wall_time\": 1677241367.1259925,\n",
            "  \"global_step\": 634\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0021839141845703125,\n",
            "  \"model.lr\": 0.00012696700000000002,\n",
            "  \"model.grad_norm\": 0.14793415367603302,\n",
            "  \"model.elapsed_time\": 0.08886456489562988,\n",
            "  \"model.engine_step\": 635,\n",
            "  \"model.loss.nll\": 0.0021839141845703125,\n",
            "  \"elapsed_time\": 0.08886456489562988,\n",
            "  \"wall_time\": 1677241367.22242,\n",
            "  \"global_step\": 635\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.004047393798828125,\n",
            "  \"model.lr\": 0.000127166,\n",
            "  \"model.grad_norm\": 0.14973750710487366,\n",
            "  \"model.elapsed_time\": 0.07198953628540039,\n",
            "  \"model.engine_step\": 636,\n",
            "  \"model.loss.nll\": 0.004047393798828125,\n",
            "  \"elapsed_time\": 0.07198953628540039,\n",
            "  \"wall_time\": 1677241367.2977676,\n",
            "  \"global_step\": 636\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.050933837890625,\n",
            "  \"model.lr\": 0.000127365,\n",
            "  \"model.grad_norm\": 1.941670298576355,\n",
            "  \"model.elapsed_time\": 0.08221244812011719,\n",
            "  \"model.engine_step\": 637,\n",
            "  \"model.loss.nll\": 0.050933837890625,\n",
            "  \"elapsed_time\": 0.08221244812011719,\n",
            "  \"wall_time\": 1677241367.388859,\n",
            "  \"global_step\": 637\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0014181137084960938,\n",
            "  \"model.lr\": 0.00012756400000000001,\n",
            "  \"model.grad_norm\": 0.0231479499489069,\n",
            "  \"model.elapsed_time\": 0.07155680656433105,\n",
            "  \"model.engine_step\": 638,\n",
            "  \"model.loss.nll\": 0.0014181137084960938,\n",
            "  \"elapsed_time\": 0.07155680656433105,\n",
            "  \"wall_time\": 1677241367.4630418,\n",
            "  \"global_step\": 638\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0019931793212890625,\n",
            "  \"model.lr\": 0.000127763,\n",
            "  \"model.grad_norm\": 0.10821676254272461,\n",
            "  \"model.elapsed_time\": 0.0707390308380127,\n",
            "  \"model.engine_step\": 639,\n",
            "  \"model.loss.nll\": 0.0019931793212890625,\n",
            "  \"elapsed_time\": 0.0707390308380127,\n",
            "  \"wall_time\": 1677241367.541881,\n",
            "  \"global_step\": 639\n",
            "}\n",
            "[2023-02-24 12:22:47,618] [INFO] [logging.py:75:log_dist] [Rank 0] step=640, skipped=1, lr=[0.00012796200000000002], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:47,620] [INFO] [timer.py:198:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=13.040374785919617, CurrSamplesPerSec=13.053883046432228, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.004779815673828125,\n",
            "  \"model.lr\": 0.00012796200000000002,\n",
            "  \"model.grad_norm\": 0.2418508231639862,\n",
            "  \"model.elapsed_time\": 0.07707667350769043,\n",
            "  \"model.engine_step\": 640,\n",
            "  \"model.loss.nll\": 0.004779815673828125,\n",
            "  \"elapsed_time\": 0.07707667350769043,\n",
            "  \"wall_time\": 1677241367.6214404,\n",
            "  \"global_step\": 640\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.01708984375,\n",
            "  \"model.lr\": 0.000128161,\n",
            "  \"model.grad_norm\": 1.2069141864776611,\n",
            "  \"model.elapsed_time\": 0.07310700416564941,\n",
            "  \"model.engine_step\": 641,\n",
            "  \"model.loss.nll\": 0.01708984375,\n",
            "  \"elapsed_time\": 0.07310700416564941,\n",
            "  \"wall_time\": 1677241367.7025092,\n",
            "  \"global_step\": 641\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0061798095703125,\n",
            "  \"model.lr\": 0.00012836,\n",
            "  \"model.grad_norm\": 0.11621227860450745,\n",
            "  \"model.elapsed_time\": 0.07032918930053711,\n",
            "  \"model.engine_step\": 642,\n",
            "  \"model.loss.nll\": 0.0061798095703125,\n",
            "  \"elapsed_time\": 0.07032918930053711,\n",
            "  \"wall_time\": 1677241367.775833,\n",
            "  \"global_step\": 642\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0015878677368164062,\n",
            "  \"model.lr\": 0.00012855900000000001,\n",
            "  \"model.grad_norm\": 0.048102591186761856,\n",
            "  \"model.elapsed_time\": 0.06715655326843262,\n",
            "  \"model.engine_step\": 643,\n",
            "  \"model.loss.nll\": 0.0015878677368164062,\n",
            "  \"elapsed_time\": 0.06715655326843262,\n",
            "  \"wall_time\": 1677241367.8511117,\n",
            "  \"global_step\": 643\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0017137527465820312,\n",
            "  \"model.lr\": 0.000128758,\n",
            "  \"model.grad_norm\": 0.04067377373576164,\n",
            "  \"model.elapsed_time\": 0.06680512428283691,\n",
            "  \"model.engine_step\": 644,\n",
            "  \"model.loss.nll\": 0.0017137527465820312,\n",
            "  \"elapsed_time\": 0.06680512428283691,\n",
            "  \"wall_time\": 1677241367.9204915,\n",
            "  \"global_step\": 644\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:47\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00463104248046875,\n",
            "  \"model.lr\": 0.00012895700000000002,\n",
            "  \"model.grad_norm\": 0.22190417349338531,\n",
            "  \"model.elapsed_time\": 0.07512927055358887,\n",
            "  \"model.engine_step\": 645,\n",
            "  \"model.loss.nll\": 0.00463104248046875,\n",
            "  \"elapsed_time\": 0.07512927055358887,\n",
            "  \"wall_time\": 1677241368.0026882,\n",
            "  \"global_step\": 645\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0033397674560546875,\n",
            "  \"model.lr\": 0.000129156,\n",
            "  \"model.grad_norm\": 0.07575241476297379,\n",
            "  \"model.elapsed_time\": 0.06890320777893066,\n",
            "  \"model.engine_step\": 646,\n",
            "  \"model.loss.nll\": 0.0033397674560546875,\n",
            "  \"elapsed_time\": 0.06890320777893066,\n",
            "  \"wall_time\": 1677241368.0736885,\n",
            "  \"global_step\": 646\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0028514862060546875,\n",
            "  \"model.lr\": 0.000129355,\n",
            "  \"model.grad_norm\": 0.062301211059093475,\n",
            "  \"model.elapsed_time\": 0.07183456420898438,\n",
            "  \"model.engine_step\": 647,\n",
            "  \"model.loss.nll\": 0.0028514862060546875,\n",
            "  \"elapsed_time\": 0.07183456420898438,\n",
            "  \"wall_time\": 1677241368.15254,\n",
            "  \"global_step\": 647\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0023403167724609375,\n",
            "  \"model.lr\": 0.000129554,\n",
            "  \"model.grad_norm\": 0.09189849346876144,\n",
            "  \"model.elapsed_time\": 0.07666254043579102,\n",
            "  \"model.engine_step\": 648,\n",
            "  \"model.loss.nll\": 0.0023403167724609375,\n",
            "  \"elapsed_time\": 0.07666254043579102,\n",
            "  \"wall_time\": 1677241368.2322307,\n",
            "  \"global_step\": 648\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0022373199462890625,\n",
            "  \"model.lr\": 0.000129753,\n",
            "  \"model.grad_norm\": 0.1488102823495865,\n",
            "  \"model.elapsed_time\": 0.06801176071166992,\n",
            "  \"model.engine_step\": 649,\n",
            "  \"model.loss.nll\": 0.0022373199462890625,\n",
            "  \"elapsed_time\": 0.06801176071166992,\n",
            "  \"wall_time\": 1677241368.3079276,\n",
            "  \"global_step\": 649\n",
            "}\n",
            "[2023-02-24 12:22:48,393] [INFO] [logging.py:75:log_dist] [Rank 0] step=650, skipped=1, lr=[0.00012995200000000002], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:48,394] [INFO] [timer.py:198:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=13.052055255377846, CurrSamplesPerSec=11.746217202452133, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.004276275634765625,\n",
            "  \"model.lr\": 0.00012995200000000002,\n",
            "  \"model.grad_norm\": 0.2318556308746338,\n",
            "  \"model.elapsed_time\": 0.0856778621673584,\n",
            "  \"model.engine_step\": 650,\n",
            "  \"model.loss.nll\": 0.004276275634765625,\n",
            "  \"elapsed_time\": 0.0856778621673584,\n",
            "  \"wall_time\": 1677241368.3960588,\n",
            "  \"global_step\": 650\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.01534271240234375,\n",
            "  \"model.lr\": 0.000130151,\n",
            "  \"model.grad_norm\": 1.3022313117980957,\n",
            "  \"model.elapsed_time\": 0.11233758926391602,\n",
            "  \"model.engine_step\": 651,\n",
            "  \"model.loss.nll\": 0.01534271240234375,\n",
            "  \"elapsed_time\": 0.11233758926391602,\n",
            "  \"wall_time\": 1677241368.5223246,\n",
            "  \"global_step\": 651\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.005626678466796875,\n",
            "  \"model.lr\": 0.00013035,\n",
            "  \"model.grad_norm\": 0.40715891122817993,\n",
            "  \"model.elapsed_time\": 0.10392951965332031,\n",
            "  \"model.engine_step\": 652,\n",
            "  \"model.loss.nll\": 0.005626678466796875,\n",
            "  \"elapsed_time\": 0.10392951965332031,\n",
            "  \"wall_time\": 1677241368.6305707,\n",
            "  \"global_step\": 652\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.01068878173828125,\n",
            "  \"model.lr\": 0.000130549,\n",
            "  \"model.grad_norm\": 0.4913845360279083,\n",
            "  \"model.elapsed_time\": 0.09694600105285645,\n",
            "  \"model.engine_step\": 653,\n",
            "  \"model.loss.nll\": 0.01068878173828125,\n",
            "  \"elapsed_time\": 0.09694600105285645,\n",
            "  \"wall_time\": 1677241368.7378511,\n",
            "  \"global_step\": 653\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0015850067138671875,\n",
            "  \"model.lr\": 0.000130748,\n",
            "  \"model.grad_norm\": 0.04461685195565224,\n",
            "  \"model.elapsed_time\": 0.09447860717773438,\n",
            "  \"model.engine_step\": 654,\n",
            "  \"model.loss.nll\": 0.0015850067138671875,\n",
            "  \"elapsed_time\": 0.09447860717773438,\n",
            "  \"wall_time\": 1677241368.8358881,\n",
            "  \"global_step\": 654\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:48\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.006351470947265625,\n",
            "  \"model.lr\": 0.00013094700000000002,\n",
            "  \"model.grad_norm\": 0.1990152895450592,\n",
            "  \"model.elapsed_time\": 0.0948953628540039,\n",
            "  \"model.engine_step\": 655,\n",
            "  \"model.loss.nll\": 0.006351470947265625,\n",
            "  \"elapsed_time\": 0.0948953628540039,\n",
            "  \"wall_time\": 1677241368.9405792,\n",
            "  \"global_step\": 655\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0013437271118164062,\n",
            "  \"model.lr\": 0.000131146,\n",
            "  \"model.grad_norm\": 0.02495867945253849,\n",
            "  \"model.elapsed_time\": 0.09400677680969238,\n",
            "  \"model.engine_step\": 656,\n",
            "  \"model.loss.nll\": 0.0013437271118164062,\n",
            "  \"elapsed_time\": 0.09400677680969238,\n",
            "  \"wall_time\": 1677241369.038289,\n",
            "  \"global_step\": 656\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0017147064208984375,\n",
            "  \"model.lr\": 0.00013134500000000002,\n",
            "  \"model.grad_norm\": 0.09507708996534348,\n",
            "  \"model.elapsed_time\": 0.09271597862243652,\n",
            "  \"model.engine_step\": 657,\n",
            "  \"model.loss.nll\": 0.0017147064208984375,\n",
            "  \"elapsed_time\": 0.09271597862243652,\n",
            "  \"wall_time\": 1677241369.1413648,\n",
            "  \"global_step\": 657\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.046722412109375,\n",
            "  \"model.lr\": 0.000131544,\n",
            "  \"model.grad_norm\": 1.531495451927185,\n",
            "  \"model.elapsed_time\": 0.1083834171295166,\n",
            "  \"model.engine_step\": 658,\n",
            "  \"model.loss.nll\": 0.046722412109375,\n",
            "  \"elapsed_time\": 0.1083834171295166,\n",
            "  \"wall_time\": 1677241369.2534833,\n",
            "  \"global_step\": 658\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0015344619750976562,\n",
            "  \"model.lr\": 0.000131743,\n",
            "  \"model.grad_norm\": 0.04881085827946663,\n",
            "  \"model.elapsed_time\": 0.09300780296325684,\n",
            "  \"model.engine_step\": 659,\n",
            "  \"model.loss.nll\": 0.0015344619750976562,\n",
            "  \"elapsed_time\": 0.09300780296325684,\n",
            "  \"wall_time\": 1677241369.3573108,\n",
            "  \"global_step\": 659\n",
            "}\n",
            "[2023-02-24 12:22:49,448] [INFO] [logging.py:75:log_dist] [Rank 0] step=660, skipped=1, lr=[0.00013194200000000002], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:49,449] [INFO] [timer.py:198:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=12.9971033130851, CurrSamplesPerSec=11.17116694810072, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00864410400390625,\n",
            "  \"model.lr\": 0.00013194200000000002,\n",
            "  \"model.grad_norm\": 0.49285826086997986,\n",
            "  \"model.elapsed_time\": 0.09017205238342285,\n",
            "  \"model.engine_step\": 660,\n",
            "  \"model.loss.nll\": 0.00864410400390625,\n",
            "  \"elapsed_time\": 0.09017205238342285,\n",
            "  \"wall_time\": 1677241369.4506538,\n",
            "  \"global_step\": 660\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0014772415161132812,\n",
            "  \"model.lr\": 0.000132141,\n",
            "  \"model.grad_norm\": 0.05615433305501938,\n",
            "  \"model.elapsed_time\": 0.09409332275390625,\n",
            "  \"model.engine_step\": 661,\n",
            "  \"model.loss.nll\": 0.0014772415161132812,\n",
            "  \"elapsed_time\": 0.09409332275390625,\n",
            "  \"wall_time\": 1677241369.5565407,\n",
            "  \"global_step\": 661\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0038089752197265625,\n",
            "  \"model.lr\": 0.00013234000000000002,\n",
            "  \"model.grad_norm\": 0.22129756212234497,\n",
            "  \"model.elapsed_time\": 0.10345935821533203,\n",
            "  \"model.engine_step\": 662,\n",
            "  \"model.loss.nll\": 0.0038089752197265625,\n",
            "  \"elapsed_time\": 0.10345935821533203,\n",
            "  \"wall_time\": 1677241369.6637132,\n",
            "  \"global_step\": 662\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0030345916748046875,\n",
            "  \"model.lr\": 0.000132539,\n",
            "  \"model.grad_norm\": 0.08917482942342758,\n",
            "  \"model.elapsed_time\": 0.09707188606262207,\n",
            "  \"model.engine_step\": 663,\n",
            "  \"model.loss.nll\": 0.0030345916748046875,\n",
            "  \"elapsed_time\": 0.09707188606262207,\n",
            "  \"wall_time\": 1677241369.7679987,\n",
            "  \"global_step\": 663\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.01180267333984375,\n",
            "  \"model.lr\": 0.000132738,\n",
            "  \"model.grad_norm\": 0.6575414538383484,\n",
            "  \"model.elapsed_time\": 0.09732556343078613,\n",
            "  \"model.engine_step\": 664,\n",
            "  \"model.loss.nll\": 0.01180267333984375,\n",
            "  \"elapsed_time\": 0.09732556343078613,\n",
            "  \"wall_time\": 1677241369.868968,\n",
            "  \"global_step\": 664\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:49\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0015497207641601562,\n",
            "  \"model.lr\": 0.00013293700000000002,\n",
            "  \"model.grad_norm\": 0.05493422970175743,\n",
            "  \"model.elapsed_time\": 0.09609293937683105,\n",
            "  \"model.engine_step\": 665,\n",
            "  \"model.loss.nll\": 0.0015497207641601562,\n",
            "  \"elapsed_time\": 0.09609293937683105,\n",
            "  \"wall_time\": 1677241369.9881697,\n",
            "  \"global_step\": 665\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00179290771484375,\n",
            "  \"model.lr\": 0.000133136,\n",
            "  \"model.grad_norm\": 0.09741926193237305,\n",
            "  \"model.elapsed_time\": 0.10011720657348633,\n",
            "  \"model.engine_step\": 666,\n",
            "  \"model.loss.nll\": 0.00179290771484375,\n",
            "  \"elapsed_time\": 0.10011720657348633,\n",
            "  \"wall_time\": 1677241370.0918078,\n",
            "  \"global_step\": 666\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00188446044921875,\n",
            "  \"model.lr\": 0.00013333500000000002,\n",
            "  \"model.grad_norm\": 0.15702033042907715,\n",
            "  \"model.elapsed_time\": 0.10200047492980957,\n",
            "  \"model.engine_step\": 667,\n",
            "  \"model.loss.nll\": 0.00188446044921875,\n",
            "  \"elapsed_time\": 0.10200047492980957,\n",
            "  \"wall_time\": 1677241370.2043312,\n",
            "  \"global_step\": 667\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00865936279296875,\n",
            "  \"model.lr\": 0.000133534,\n",
            "  \"model.grad_norm\": 1.1361860036849976,\n",
            "  \"model.elapsed_time\": 0.0964958667755127,\n",
            "  \"model.engine_step\": 668,\n",
            "  \"model.loss.nll\": 0.00865936279296875,\n",
            "  \"elapsed_time\": 0.0964958667755127,\n",
            "  \"wall_time\": 1677241370.303704,\n",
            "  \"global_step\": 668\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.01546478271484375,\n",
            "  \"model.lr\": 0.000133733,\n",
            "  \"model.grad_norm\": 1.316511869430542,\n",
            "  \"model.elapsed_time\": 0.09906649589538574,\n",
            "  \"model.engine_step\": 669,\n",
            "  \"model.loss.nll\": 0.01546478271484375,\n",
            "  \"elapsed_time\": 0.09906649589538574,\n",
            "  \"wall_time\": 1677241370.411521,\n",
            "  \"global_step\": 669\n",
            "}\n",
            "[2023-02-24 12:22:50,510] [INFO] [logging.py:75:log_dist] [Rank 0] step=670, skipped=1, lr=[0.00013393200000000002], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:50,510] [INFO] [timer.py:198:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=12.943645689227825, CurrSamplesPerSec=10.313574867585658, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011749267578125,\n",
            "  \"model.lr\": 0.00013393200000000002,\n",
            "  \"model.grad_norm\": 0.017922628670930862,\n",
            "  \"model.elapsed_time\": 0.09761309623718262,\n",
            "  \"model.engine_step\": 670,\n",
            "  \"model.loss.nll\": 0.0011749267578125,\n",
            "  \"elapsed_time\": 0.09761309623718262,\n",
            "  \"wall_time\": 1677241370.5124516,\n",
            "  \"global_step\": 670\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011529922485351562,\n",
            "  \"model.lr\": 0.000134131,\n",
            "  \"model.grad_norm\": 0.02060924470424652,\n",
            "  \"model.elapsed_time\": 0.1024019718170166,\n",
            "  \"model.engine_step\": 671,\n",
            "  \"model.loss.nll\": 0.0011529922485351562,\n",
            "  \"elapsed_time\": 0.1024019718170166,\n",
            "  \"wall_time\": 1677241370.6249385,\n",
            "  \"global_step\": 671\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.003322601318359375,\n",
            "  \"model.lr\": 0.00013433000000000002,\n",
            "  \"model.grad_norm\": 0.5553786754608154,\n",
            "  \"model.elapsed_time\": 0.09297919273376465,\n",
            "  \"model.engine_step\": 672,\n",
            "  \"model.loss.nll\": 0.003322601318359375,\n",
            "  \"elapsed_time\": 0.09297919273376465,\n",
            "  \"wall_time\": 1677241370.721978,\n",
            "  \"global_step\": 672\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0026187896728515625,\n",
            "  \"model.lr\": 0.000134529,\n",
            "  \"model.grad_norm\": 0.4000891447067261,\n",
            "  \"model.elapsed_time\": 0.09498167037963867,\n",
            "  \"model.engine_step\": 673,\n",
            "  \"model.loss.nll\": 0.0026187896728515625,\n",
            "  \"elapsed_time\": 0.09498167037963867,\n",
            "  \"wall_time\": 1677241370.828745,\n",
            "  \"global_step\": 673\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0225677490234375,\n",
            "  \"model.lr\": 0.000134728,\n",
            "  \"model.grad_norm\": 1.8080724477767944,\n",
            "  \"model.elapsed_time\": 0.0932760238647461,\n",
            "  \"model.engine_step\": 674,\n",
            "  \"model.loss.nll\": 0.0225677490234375,\n",
            "  \"elapsed_time\": 0.0932760238647461,\n",
            "  \"wall_time\": 1677241370.9248042,\n",
            "  \"global_step\": 674\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:50\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00182342529296875,\n",
            "  \"model.lr\": 0.00013492700000000002,\n",
            "  \"model.grad_norm\": 0.12140585482120514,\n",
            "  \"model.elapsed_time\": 0.09572267532348633,\n",
            "  \"model.engine_step\": 675,\n",
            "  \"model.loss.nll\": 0.00182342529296875,\n",
            "  \"elapsed_time\": 0.09572267532348633,\n",
            "  \"wall_time\": 1677241371.0322292,\n",
            "  \"global_step\": 675\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0014810562133789062,\n",
            "  \"model.lr\": 0.000135126,\n",
            "  \"model.grad_norm\": 0.030643567442893982,\n",
            "  \"model.elapsed_time\": 0.11445784568786621,\n",
            "  \"model.engine_step\": 676,\n",
            "  \"model.loss.nll\": 0.0014810562133789062,\n",
            "  \"elapsed_time\": 0.11445784568786621,\n",
            "  \"wall_time\": 1677241371.1500583,\n",
            "  \"global_step\": 676\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0012598037719726562,\n",
            "  \"model.lr\": 0.00013532500000000002,\n",
            "  \"model.grad_norm\": 0.043991416692733765,\n",
            "  \"model.elapsed_time\": 0.09572625160217285,\n",
            "  \"model.engine_step\": 677,\n",
            "  \"model.loss.nll\": 0.0012598037719726562,\n",
            "  \"elapsed_time\": 0.09572625160217285,\n",
            "  \"wall_time\": 1677241371.2570999,\n",
            "  \"global_step\": 677\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0036106109619140625,\n",
            "  \"model.lr\": 0.000135524,\n",
            "  \"model.grad_norm\": 0.15228930115699768,\n",
            "  \"model.elapsed_time\": 0.10728120803833008,\n",
            "  \"model.engine_step\": 678,\n",
            "  \"model.loss.nll\": 0.0036106109619140625,\n",
            "  \"elapsed_time\": 0.10728120803833008,\n",
            "  \"wall_time\": 1677241371.3673406,\n",
            "  \"global_step\": 678\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0028533935546875,\n",
            "  \"model.lr\": 0.000135723,\n",
            "  \"model.grad_norm\": 0.12106668204069138,\n",
            "  \"model.elapsed_time\": 0.08815622329711914,\n",
            "  \"model.engine_step\": 679,\n",
            "  \"model.loss.nll\": 0.0028533935546875,\n",
            "  \"elapsed_time\": 0.08815622329711914,\n",
            "  \"wall_time\": 1677241371.4657376,\n",
            "  \"global_step\": 679\n",
            "}\n",
            "[2023-02-24 12:22:51,555] [INFO] [logging.py:75:log_dist] [Rank 0] step=680, skipped=1, lr=[0.00013592200000000002], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:51,556] [INFO] [timer.py:198:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=12.894305951349113, CurrSamplesPerSec=11.243245561598815, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0029735565185546875,\n",
            "  \"model.lr\": 0.00013592200000000002,\n",
            "  \"model.grad_norm\": 0.06665387004613876,\n",
            "  \"model.elapsed_time\": 0.08956551551818848,\n",
            "  \"model.engine_step\": 680,\n",
            "  \"model.loss.nll\": 0.0029735565185546875,\n",
            "  \"elapsed_time\": 0.08956551551818848,\n",
            "  \"wall_time\": 1677241371.5579295,\n",
            "  \"global_step\": 680\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.060638427734375,\n",
            "  \"model.lr\": 0.000136121,\n",
            "  \"model.grad_norm\": 1.9590826034545898,\n",
            "  \"model.elapsed_time\": 0.09094357490539551,\n",
            "  \"model.engine_step\": 681,\n",
            "  \"model.loss.nll\": 0.060638427734375,\n",
            "  \"elapsed_time\": 0.09094357490539551,\n",
            "  \"wall_time\": 1677241371.6598005,\n",
            "  \"global_step\": 681\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002475738525390625,\n",
            "  \"model.lr\": 0.00013632000000000002,\n",
            "  \"model.grad_norm\": 0.2987251579761505,\n",
            "  \"model.elapsed_time\": 0.10045695304870605,\n",
            "  \"model.engine_step\": 682,\n",
            "  \"model.loss.nll\": 0.002475738525390625,\n",
            "  \"elapsed_time\": 0.10045695304870605,\n",
            "  \"wall_time\": 1677241371.762998,\n",
            "  \"global_step\": 682\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0013284683227539062,\n",
            "  \"model.lr\": 0.000136519,\n",
            "  \"model.grad_norm\": 0.02727125957608223,\n",
            "  \"model.elapsed_time\": 0.08821892738342285,\n",
            "  \"model.engine_step\": 683,\n",
            "  \"model.loss.nll\": 0.0013284683227539062,\n",
            "  \"elapsed_time\": 0.08821892738342285,\n",
            "  \"wall_time\": 1677241371.8629484,\n",
            "  \"global_step\": 683\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0013895034790039062,\n",
            "  \"model.lr\": 0.00013671800000000003,\n",
            "  \"model.grad_norm\": 0.02154485695064068,\n",
            "  \"model.elapsed_time\": 0.09171128273010254,\n",
            "  \"model.engine_step\": 684,\n",
            "  \"model.loss.nll\": 0.0013895034790039062,\n",
            "  \"elapsed_time\": 0.09171128273010254,\n",
            "  \"wall_time\": 1677241371.9572916,\n",
            "  \"global_step\": 684\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:51\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011653900146484375,\n",
            "  \"model.lr\": 0.00013691700000000002,\n",
            "  \"model.grad_norm\": 0.024714872241020203,\n",
            "  \"model.elapsed_time\": 0.09877324104309082,\n",
            "  \"model.engine_step\": 685,\n",
            "  \"model.loss.nll\": 0.0011653900146484375,\n",
            "  \"elapsed_time\": 0.09877324104309082,\n",
            "  \"wall_time\": 1677241372.0694358,\n",
            "  \"global_step\": 685\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0030517578125,\n",
            "  \"model.lr\": 0.000137116,\n",
            "  \"model.grad_norm\": 0.33395469188690186,\n",
            "  \"model.elapsed_time\": 0.09646391868591309,\n",
            "  \"model.engine_step\": 686,\n",
            "  \"model.loss.nll\": 0.0030517578125,\n",
            "  \"elapsed_time\": 0.09646391868591309,\n",
            "  \"wall_time\": 1677241372.1702087,\n",
            "  \"global_step\": 686\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0230560302734375,\n",
            "  \"model.lr\": 0.00013731500000000002,\n",
            "  \"model.grad_norm\": 1.222470760345459,\n",
            "  \"model.elapsed_time\": 0.09365344047546387,\n",
            "  \"model.engine_step\": 687,\n",
            "  \"model.loss.nll\": 0.0230560302734375,\n",
            "  \"elapsed_time\": 0.09365344047546387,\n",
            "  \"wall_time\": 1677241372.2754004,\n",
            "  \"global_step\": 687\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0012636184692382812,\n",
            "  \"model.lr\": 0.000137514,\n",
            "  \"model.grad_norm\": 0.03208569437265396,\n",
            "  \"model.elapsed_time\": 0.09982800483703613,\n",
            "  \"model.engine_step\": 688,\n",
            "  \"model.loss.nll\": 0.0012636184692382812,\n",
            "  \"elapsed_time\": 0.09982800483703613,\n",
            "  \"wall_time\": 1677241372.3796048,\n",
            "  \"global_step\": 688\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0014142990112304688,\n",
            "  \"model.lr\": 0.00013771300000000003,\n",
            "  \"model.grad_norm\": 0.041530411690473557,\n",
            "  \"model.elapsed_time\": 0.0955657958984375,\n",
            "  \"model.engine_step\": 689,\n",
            "  \"model.loss.nll\": 0.0014142990112304688,\n",
            "  \"elapsed_time\": 0.0955657958984375,\n",
            "  \"wall_time\": 1677241372.485425,\n",
            "  \"global_step\": 689\n",
            "}\n",
            "[2023-02-24 12:22:52,589] [INFO] [logging.py:75:log_dist] [Rank 0] step=690, skipped=1, lr=[0.000137912], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:52,590] [INFO] [timer.py:198:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=12.850604778607218, CurrSamplesPerSec=9.771830093377817, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0023250579833984375,\n",
            "  \"model.lr\": 0.000137912,\n",
            "  \"model.grad_norm\": 0.05555512383580208,\n",
            "  \"model.elapsed_time\": 0.10304498672485352,\n",
            "  \"model.engine_step\": 690,\n",
            "  \"model.loss.nll\": 0.0023250579833984375,\n",
            "  \"elapsed_time\": 0.10304498672485352,\n",
            "  \"wall_time\": 1677241372.5922422,\n",
            "  \"global_step\": 690\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0032958984375,\n",
            "  \"model.lr\": 0.000138111,\n",
            "  \"model.grad_norm\": 0.254047691822052,\n",
            "  \"model.elapsed_time\": 0.10553121566772461,\n",
            "  \"model.engine_step\": 691,\n",
            "  \"model.loss.nll\": 0.0032958984375,\n",
            "  \"elapsed_time\": 0.10553121566772461,\n",
            "  \"wall_time\": 1677241372.7076187,\n",
            "  \"global_step\": 691\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0012874603271484375,\n",
            "  \"model.lr\": 0.00013831,\n",
            "  \"model.grad_norm\": 0.03637256100773811,\n",
            "  \"model.elapsed_time\": 0.11680340766906738,\n",
            "  \"model.engine_step\": 692,\n",
            "  \"model.loss.nll\": 0.0012874603271484375,\n",
            "  \"elapsed_time\": 0.11680340766906738,\n",
            "  \"wall_time\": 1677241372.8280666,\n",
            "  \"global_step\": 692\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:52\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010156631469726562,\n",
            "  \"model.lr\": 0.00013850899999999998,\n",
            "  \"model.grad_norm\": 0.028767548501491547,\n",
            "  \"model.elapsed_time\": 0.10369396209716797,\n",
            "  \"model.engine_step\": 693,\n",
            "  \"model.loss.nll\": 0.0010156631469726562,\n",
            "  \"elapsed_time\": 0.10369396209716797,\n",
            "  \"wall_time\": 1677241372.9408388,\n",
            "  \"global_step\": 693\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00112152099609375,\n",
            "  \"model.lr\": 0.000138708,\n",
            "  \"model.grad_norm\": 0.014111780561506748,\n",
            "  \"model.elapsed_time\": 0.10170817375183105,\n",
            "  \"model.engine_step\": 694,\n",
            "  \"model.loss.nll\": 0.00112152099609375,\n",
            "  \"elapsed_time\": 0.10170817375183105,\n",
            "  \"wall_time\": 1677241373.046097,\n",
            "  \"global_step\": 694\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009732246398925781,\n",
            "  \"model.lr\": 0.000138907,\n",
            "  \"model.grad_norm\": 0.011304618790745735,\n",
            "  \"model.elapsed_time\": 0.10943913459777832,\n",
            "  \"model.engine_step\": 695,\n",
            "  \"model.loss.nll\": 0.0009732246398925781,\n",
            "  \"elapsed_time\": 0.10943913459777832,\n",
            "  \"wall_time\": 1677241373.1660962,\n",
            "  \"global_step\": 695\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001209259033203125,\n",
            "  \"model.lr\": 0.000139106,\n",
            "  \"model.grad_norm\": 0.02119680680334568,\n",
            "  \"model.elapsed_time\": 0.1030421257019043,\n",
            "  \"model.engine_step\": 696,\n",
            "  \"model.loss.nll\": 0.001209259033203125,\n",
            "  \"elapsed_time\": 0.1030421257019043,\n",
            "  \"wall_time\": 1677241373.2721093,\n",
            "  \"global_step\": 696\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011844635009765625,\n",
            "  \"model.lr\": 0.000139305,\n",
            "  \"model.grad_norm\": 0.026597412303090096,\n",
            "  \"model.elapsed_time\": 0.10935378074645996,\n",
            "  \"model.engine_step\": 697,\n",
            "  \"model.loss.nll\": 0.0011844635009765625,\n",
            "  \"elapsed_time\": 0.10935378074645996,\n",
            "  \"wall_time\": 1677241373.390209,\n",
            "  \"global_step\": 697\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010356903076171875,\n",
            "  \"model.lr\": 0.00013950399999999998,\n",
            "  \"model.grad_norm\": 0.014264623634517193,\n",
            "  \"model.elapsed_time\": 0.0988759994506836,\n",
            "  \"model.engine_step\": 698,\n",
            "  \"model.loss.nll\": 0.0010356903076171875,\n",
            "  \"elapsed_time\": 0.0988759994506836,\n",
            "  \"wall_time\": 1677241373.4970353,\n",
            "  \"global_step\": 698\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001163482666015625,\n",
            "  \"model.lr\": 0.000139703,\n",
            "  \"model.grad_norm\": 0.027389967814087868,\n",
            "  \"model.elapsed_time\": 0.10061049461364746,\n",
            "  \"model.engine_step\": 699,\n",
            "  \"model.loss.nll\": 0.001163482666015625,\n",
            "  \"elapsed_time\": 0.10061049461364746,\n",
            "  \"wall_time\": 1677241373.606144,\n",
            "  \"global_step\": 699\n",
            "}\n",
            "[2023-02-24 12:22:53,708] [INFO] [logging.py:75:log_dist] [Rank 0] step=700, skipped=1, lr=[0.000139902], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:53,709] [INFO] [timer.py:198:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=12.786788252370329, CurrSamplesPerSec=9.862939996566798, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001251220703125,\n",
            "  \"model.lr\": 0.000139902,\n",
            "  \"model.grad_norm\": 0.05201981961727142,\n",
            "  \"model.elapsed_time\": 0.10200095176696777,\n",
            "  \"model.engine_step\": 700,\n",
            "  \"model.loss.nll\": 0.001251220703125,\n",
            "  \"elapsed_time\": 0.10200095176696777,\n",
            "  \"wall_time\": 1677241373.711277,\n",
            "  \"global_step\": 700\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0340576171875,\n",
            "  \"model.lr\": 0.000140101,\n",
            "  \"model.grad_norm\": 1.4726128578186035,\n",
            "  \"model.elapsed_time\": 0.1011347770690918,\n",
            "  \"model.engine_step\": 701,\n",
            "  \"model.loss.nll\": 0.0340576171875,\n",
            "  \"elapsed_time\": 0.1011347770690918,\n",
            "  \"wall_time\": 1677241373.8222811,\n",
            "  \"global_step\": 701\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0103759765625,\n",
            "  \"model.lr\": 0.0001403,\n",
            "  \"model.grad_norm\": 1.023208737373352,\n",
            "  \"model.elapsed_time\": 0.0985260009765625,\n",
            "  \"model.engine_step\": 702,\n",
            "  \"model.loss.nll\": 0.0103759765625,\n",
            "  \"elapsed_time\": 0.0985260009765625,\n",
            "  \"wall_time\": 1677241373.9240148,\n",
            "  \"global_step\": 702\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:53\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0024890899658203125,\n",
            "  \"model.lr\": 0.00014049899999999998,\n",
            "  \"model.grad_norm\": 0.08824357390403748,\n",
            "  \"model.elapsed_time\": 0.10927963256835938,\n",
            "  \"model.engine_step\": 703,\n",
            "  \"model.loss.nll\": 0.0024890899658203125,\n",
            "  \"elapsed_time\": 0.10927963256835938,\n",
            "  \"wall_time\": 1677241374.0438335,\n",
            "  \"global_step\": 703\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0053558349609375,\n",
            "  \"model.lr\": 0.000140698,\n",
            "  \"model.grad_norm\": 0.5828479528427124,\n",
            "  \"model.elapsed_time\": 0.1039438247680664,\n",
            "  \"model.engine_step\": 704,\n",
            "  \"model.loss.nll\": 0.0053558349609375,\n",
            "  \"elapsed_time\": 0.1039438247680664,\n",
            "  \"wall_time\": 1677241374.15127,\n",
            "  \"global_step\": 704\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00214385986328125,\n",
            "  \"model.lr\": 0.000140897,\n",
            "  \"model.grad_norm\": 0.1920420229434967,\n",
            "  \"model.elapsed_time\": 0.09851837158203125,\n",
            "  \"model.engine_step\": 705,\n",
            "  \"model.loss.nll\": 0.00214385986328125,\n",
            "  \"elapsed_time\": 0.09851837158203125,\n",
            "  \"wall_time\": 1677241374.2608337,\n",
            "  \"global_step\": 705\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00945281982421875,\n",
            "  \"model.lr\": 0.000141096,\n",
            "  \"model.grad_norm\": 0.8253207802772522,\n",
            "  \"model.elapsed_time\": 0.10195374488830566,\n",
            "  \"model.engine_step\": 706,\n",
            "  \"model.loss.nll\": 0.00945281982421875,\n",
            "  \"elapsed_time\": 0.10195374488830566,\n",
            "  \"wall_time\": 1677241374.3656654,\n",
            "  \"global_step\": 706\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0146942138671875,\n",
            "  \"model.lr\": 0.000141295,\n",
            "  \"model.grad_norm\": 1.1415042877197266,\n",
            "  \"model.elapsed_time\": 0.11261296272277832,\n",
            "  \"model.engine_step\": 707,\n",
            "  \"model.loss.nll\": 0.0146942138671875,\n",
            "  \"elapsed_time\": 0.11261296272277832,\n",
            "  \"wall_time\": 1677241374.4891868,\n",
            "  \"global_step\": 707\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00554656982421875,\n",
            "  \"model.lr\": 0.000141494,\n",
            "  \"model.grad_norm\": 0.4387909173965454,\n",
            "  \"model.elapsed_time\": 0.10722708702087402,\n",
            "  \"model.engine_step\": 708,\n",
            "  \"model.loss.nll\": 0.00554656982421875,\n",
            "  \"elapsed_time\": 0.10722708702087402,\n",
            "  \"wall_time\": 1677241374.601858,\n",
            "  \"global_step\": 708\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009908676147460938,\n",
            "  \"model.lr\": 0.000141693,\n",
            "  \"model.grad_norm\": 0.01490373071283102,\n",
            "  \"model.elapsed_time\": 0.10266447067260742,\n",
            "  \"model.engine_step\": 709,\n",
            "  \"model.loss.nll\": 0.0009908676147460938,\n",
            "  \"elapsed_time\": 0.10266447067260742,\n",
            "  \"wall_time\": 1677241374.7149692,\n",
            "  \"global_step\": 709\n",
            "}\n",
            "[2023-02-24 12:22:54,817] [INFO] [logging.py:75:log_dist] [Rank 0] step=710, skipped=1, lr=[0.000141892], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:54,818] [INFO] [timer.py:198:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=12.72921528987149, CurrSamplesPerSec=9.891736494183071, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010099411010742188,\n",
            "  \"model.lr\": 0.000141892,\n",
            "  \"model.grad_norm\": 0.016565611585974693,\n",
            "  \"model.elapsed_time\": 0.10175275802612305,\n",
            "  \"model.engine_step\": 710,\n",
            "  \"model.loss.nll\": 0.0010099411010742188,\n",
            "  \"elapsed_time\": 0.10175275802612305,\n",
            "  \"wall_time\": 1677241374.8200161,\n",
            "  \"global_step\": 710\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:54\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0024013519287109375,\n",
            "  \"model.lr\": 0.000142091,\n",
            "  \"model.grad_norm\": 0.05268298462033272,\n",
            "  \"model.elapsed_time\": 0.0996556282043457,\n",
            "  \"model.engine_step\": 711,\n",
            "  \"model.loss.nll\": 0.0024013519287109375,\n",
            "  \"elapsed_time\": 0.0996556282043457,\n",
            "  \"wall_time\": 1677241374.9312885,\n",
            "  \"global_step\": 711\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001300811767578125,\n",
            "  \"model.lr\": 0.00014229,\n",
            "  \"model.grad_norm\": 0.07444189488887787,\n",
            "  \"model.elapsed_time\": 0.1074521541595459,\n",
            "  \"model.engine_step\": 712,\n",
            "  \"model.loss.nll\": 0.001300811767578125,\n",
            "  \"elapsed_time\": 0.1074521541595459,\n",
            "  \"wall_time\": 1677241375.0416808,\n",
            "  \"global_step\": 712\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.020843505859375,\n",
            "  \"model.lr\": 0.000142489,\n",
            "  \"model.grad_norm\": 1.2566636800765991,\n",
            "  \"model.elapsed_time\": 0.10081267356872559,\n",
            "  \"model.engine_step\": 713,\n",
            "  \"model.loss.nll\": 0.020843505859375,\n",
            "  \"elapsed_time\": 0.10081267356872559,\n",
            "  \"wall_time\": 1677241375.1538625,\n",
            "  \"global_step\": 713\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0192718505859375,\n",
            "  \"model.lr\": 0.000142688,\n",
            "  \"model.grad_norm\": 1.123964786529541,\n",
            "  \"model.elapsed_time\": 0.10368800163269043,\n",
            "  \"model.engine_step\": 714,\n",
            "  \"model.loss.nll\": 0.0192718505859375,\n",
            "  \"elapsed_time\": 0.10368800163269043,\n",
            "  \"wall_time\": 1677241375.2603455,\n",
            "  \"global_step\": 714\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0014867782592773438,\n",
            "  \"model.lr\": 0.000142887,\n",
            "  \"model.grad_norm\": 0.08569861203432083,\n",
            "  \"model.elapsed_time\": 0.1012418270111084,\n",
            "  \"model.engine_step\": 715,\n",
            "  \"model.loss.nll\": 0.0014867782592773438,\n",
            "  \"elapsed_time\": 0.1012418270111084,\n",
            "  \"wall_time\": 1677241375.372023,\n",
            "  \"global_step\": 715\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002140045166015625,\n",
            "  \"model.lr\": 0.000143086,\n",
            "  \"model.grad_norm\": 0.044149160385131836,\n",
            "  \"model.elapsed_time\": 0.10413265228271484,\n",
            "  \"model.engine_step\": 716,\n",
            "  \"model.loss.nll\": 0.002140045166015625,\n",
            "  \"elapsed_time\": 0.10413265228271484,\n",
            "  \"wall_time\": 1677241375.4790242,\n",
            "  \"global_step\": 716\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009083747863769531,\n",
            "  \"model.lr\": 0.000143285,\n",
            "  \"model.grad_norm\": 0.010818961076438427,\n",
            "  \"model.elapsed_time\": 0.11012005805969238,\n",
            "  \"model.engine_step\": 717,\n",
            "  \"model.loss.nll\": 0.0009083747863769531,\n",
            "  \"elapsed_time\": 0.11012005805969238,\n",
            "  \"wall_time\": 1677241375.604714,\n",
            "  \"global_step\": 717\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002361297607421875,\n",
            "  \"model.lr\": 0.000143484,\n",
            "  \"model.grad_norm\": 0.144109308719635,\n",
            "  \"model.elapsed_time\": 0.1036982536315918,\n",
            "  \"model.engine_step\": 718,\n",
            "  \"model.loss.nll\": 0.002361297607421875,\n",
            "  \"elapsed_time\": 0.1036982536315918,\n",
            "  \"wall_time\": 1677241375.7112753,\n",
            "  \"global_step\": 718\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002838134765625,\n",
            "  \"model.lr\": 0.000143683,\n",
            "  \"model.grad_norm\": 0.15704400837421417,\n",
            "  \"model.elapsed_time\": 0.10313582420349121,\n",
            "  \"model.engine_step\": 719,\n",
            "  \"model.loss.nll\": 0.002838134765625,\n",
            "  \"elapsed_time\": 0.10313582420349121,\n",
            "  \"wall_time\": 1677241375.8279884,\n",
            "  \"global_step\": 719\n",
            "}\n",
            "[2023-02-24 12:22:55,931] [INFO] [logging.py:75:log_dist] [Rank 0] step=720, skipped=1, lr=[0.000143882], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:55,932] [INFO] [timer.py:198:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=12.673279081250957, CurrSamplesPerSec=9.825395189325437, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001007080078125,\n",
            "  \"model.lr\": 0.000143882,\n",
            "  \"model.grad_norm\": 0.014413944445550442,\n",
            "  \"model.elapsed_time\": 0.10242605209350586,\n",
            "  \"model.engine_step\": 720,\n",
            "  \"model.loss.nll\": 0.001007080078125,\n",
            "  \"elapsed_time\": 0.10242605209350586,\n",
            "  \"wall_time\": 1677241375.9337072,\n",
            "  \"global_step\": 720\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:55\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.012664794921875,\n",
            "  \"model.lr\": 0.000144081,\n",
            "  \"model.grad_norm\": 1.1144055128097534,\n",
            "  \"model.elapsed_time\": 0.10731816291809082,\n",
            "  \"model.engine_step\": 721,\n",
            "  \"model.loss.nll\": 0.012664794921875,\n",
            "  \"elapsed_time\": 0.10731816291809082,\n",
            "  \"wall_time\": 1677241376.051904,\n",
            "  \"global_step\": 721\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009703636169433594,\n",
            "  \"model.lr\": 0.00014428,\n",
            "  \"model.grad_norm\": 0.013153230771422386,\n",
            "  \"model.elapsed_time\": 0.10178160667419434,\n",
            "  \"model.engine_step\": 722,\n",
            "  \"model.loss.nll\": 0.0009703636169433594,\n",
            "  \"elapsed_time\": 0.10178160667419434,\n",
            "  \"wall_time\": 1677241376.1565201,\n",
            "  \"global_step\": 722\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0355224609375,\n",
            "  \"model.lr\": 0.000144479,\n",
            "  \"model.grad_norm\": 1.1803746223449707,\n",
            "  \"model.elapsed_time\": 0.10917830467224121,\n",
            "  \"model.engine_step\": 723,\n",
            "  \"model.loss.nll\": 0.0355224609375,\n",
            "  \"elapsed_time\": 0.10917830467224121,\n",
            "  \"wall_time\": 1677241376.2758152,\n",
            "  \"global_step\": 723\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010652542114257812,\n",
            "  \"model.lr\": 0.000144678,\n",
            "  \"model.grad_norm\": 0.015846939757466316,\n",
            "  \"model.elapsed_time\": 0.1008305549621582,\n",
            "  \"model.engine_step\": 724,\n",
            "  \"model.loss.nll\": 0.0010652542114257812,\n",
            "  \"elapsed_time\": 0.1008305549621582,\n",
            "  \"wall_time\": 1677241376.3795478,\n",
            "  \"global_step\": 724\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009722709655761719,\n",
            "  \"model.lr\": 0.000144877,\n",
            "  \"model.grad_norm\": 0.017605692148208618,\n",
            "  \"model.elapsed_time\": 0.09900474548339844,\n",
            "  \"model.engine_step\": 725,\n",
            "  \"model.loss.nll\": 0.0009722709655761719,\n",
            "  \"elapsed_time\": 0.09900474548339844,\n",
            "  \"wall_time\": 1677241376.487792,\n",
            "  \"global_step\": 725\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002162933349609375,\n",
            "  \"model.lr\": 0.000145076,\n",
            "  \"model.grad_norm\": 0.2476351112127304,\n",
            "  \"model.elapsed_time\": 0.10414719581604004,\n",
            "  \"model.engine_step\": 726,\n",
            "  \"model.loss.nll\": 0.002162933349609375,\n",
            "  \"elapsed_time\": 0.10414719581604004,\n",
            "  \"wall_time\": 1677241376.594784,\n",
            "  \"global_step\": 726\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00206756591796875,\n",
            "  \"model.lr\": 0.000145275,\n",
            "  \"model.grad_norm\": 0.19532480835914612,\n",
            "  \"model.elapsed_time\": 0.10223984718322754,\n",
            "  \"model.engine_step\": 727,\n",
            "  \"model.loss.nll\": 0.00206756591796875,\n",
            "  \"elapsed_time\": 0.10223984718322754,\n",
            "  \"wall_time\": 1677241376.705227,\n",
            "  \"global_step\": 727\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0167694091796875,\n",
            "  \"model.lr\": 0.000145474,\n",
            "  \"model.grad_norm\": 1.1151775121688843,\n",
            "  \"model.elapsed_time\": 0.10295319557189941,\n",
            "  \"model.engine_step\": 728,\n",
            "  \"model.loss.nll\": 0.0167694091796875,\n",
            "  \"elapsed_time\": 0.10295319557189941,\n",
            "  \"wall_time\": 1677241376.8109686,\n",
            "  \"global_step\": 728\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:56\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0013103485107421875,\n",
            "  \"model.lr\": 0.000145673,\n",
            "  \"model.grad_norm\": 0.07300455123186111,\n",
            "  \"model.elapsed_time\": 0.10096955299377441,\n",
            "  \"model.engine_step\": 729,\n",
            "  \"model.loss.nll\": 0.0013103485107421875,\n",
            "  \"elapsed_time\": 0.10096955299377441,\n",
            "  \"wall_time\": 1677241376.9314542,\n",
            "  \"global_step\": 729\n",
            "}\n",
            "[2023-02-24 12:22:57,034] [INFO] [logging.py:75:log_dist] [Rank 0] step=730, skipped=1, lr=[0.00014587200000000002], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:57,035] [INFO] [timer.py:198:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=12.620451411372633, CurrSamplesPerSec=9.786833299888466, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.010467529296875,\n",
            "  \"model.lr\": 0.00014587200000000002,\n",
            "  \"model.grad_norm\": 0.9028534889221191,\n",
            "  \"model.elapsed_time\": 0.10283565521240234,\n",
            "  \"model.engine_step\": 730,\n",
            "  \"model.loss.nll\": 0.010467529296875,\n",
            "  \"elapsed_time\": 0.10283565521240234,\n",
            "  \"wall_time\": 1677241377.037126,\n",
            "  \"global_step\": 730\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008759498596191406,\n",
            "  \"model.lr\": 0.000146071,\n",
            "  \"model.grad_norm\": 0.011750652454793453,\n",
            "  \"model.elapsed_time\": 0.12191224098205566,\n",
            "  \"model.engine_step\": 731,\n",
            "  \"model.loss.nll\": 0.0008759498596191406,\n",
            "  \"elapsed_time\": 0.12191224098205566,\n",
            "  \"wall_time\": 1677241377.1694012,\n",
            "  \"global_step\": 731\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011968612670898438,\n",
            "  \"model.lr\": 0.00014627,\n",
            "  \"model.grad_norm\": 0.03400411084294319,\n",
            "  \"model.elapsed_time\": 0.10192203521728516,\n",
            "  \"model.engine_step\": 732,\n",
            "  \"model.loss.nll\": 0.0011968612670898438,\n",
            "  \"elapsed_time\": 0.10192203521728516,\n",
            "  \"wall_time\": 1677241377.2741811,\n",
            "  \"global_step\": 732\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0024394989013671875,\n",
            "  \"model.lr\": 0.000146469,\n",
            "  \"model.grad_norm\": 0.08121846616268158,\n",
            "  \"model.elapsed_time\": 0.10172176361083984,\n",
            "  \"model.engine_step\": 733,\n",
            "  \"model.loss.nll\": 0.0024394989013671875,\n",
            "  \"elapsed_time\": 0.10172176361083984,\n",
            "  \"wall_time\": 1677241377.3867843,\n",
            "  \"global_step\": 733\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001567840576171875,\n",
            "  \"model.lr\": 0.000146668,\n",
            "  \"model.grad_norm\": 0.02292119339108467,\n",
            "  \"model.elapsed_time\": 0.10354113578796387,\n",
            "  \"model.engine_step\": 734,\n",
            "  \"model.loss.nll\": 0.001567840576171875,\n",
            "  \"elapsed_time\": 0.10354113578796387,\n",
            "  \"wall_time\": 1677241377.493238,\n",
            "  \"global_step\": 734\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010805130004882812,\n",
            "  \"model.lr\": 0.00014686700000000002,\n",
            "  \"model.grad_norm\": 0.03092767298221588,\n",
            "  \"model.elapsed_time\": 0.1059422492980957,\n",
            "  \"model.engine_step\": 735,\n",
            "  \"model.loss.nll\": 0.0010805130004882812,\n",
            "  \"elapsed_time\": 0.1059422492980957,\n",
            "  \"wall_time\": 1677241377.6085212,\n",
            "  \"global_step\": 735\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010881423950195312,\n",
            "  \"model.lr\": 0.000147066,\n",
            "  \"model.grad_norm\": 0.03409561514854431,\n",
            "  \"model.elapsed_time\": 0.10165262222290039,\n",
            "  \"model.engine_step\": 736,\n",
            "  \"model.loss.nll\": 0.0010881423950195312,\n",
            "  \"elapsed_time\": 0.10165262222290039,\n",
            "  \"wall_time\": 1677241377.7129226,\n",
            "  \"global_step\": 736\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002857208251953125,\n",
            "  \"model.lr\": 0.000147265,\n",
            "  \"model.grad_norm\": 0.35229694843292236,\n",
            "  \"model.elapsed_time\": 0.09799313545227051,\n",
            "  \"model.engine_step\": 737,\n",
            "  \"model.loss.nll\": 0.002857208251953125,\n",
            "  \"elapsed_time\": 0.09799313545227051,\n",
            "  \"wall_time\": 1677241377.8221123,\n",
            "  \"global_step\": 737\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0024356842041015625,\n",
            "  \"model.lr\": 0.000147464,\n",
            "  \"model.grad_norm\": 0.22804976999759674,\n",
            "  \"model.elapsed_time\": 0.09982585906982422,\n",
            "  \"model.engine_step\": 738,\n",
            "  \"model.loss.nll\": 0.0024356842041015625,\n",
            "  \"elapsed_time\": 0.09982585906982422,\n",
            "  \"wall_time\": 1677241377.9252703,\n",
            "  \"global_step\": 738\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:57\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0014333724975585938,\n",
            "  \"model.lr\": 0.000147663,\n",
            "  \"model.grad_norm\": 0.0871698409318924,\n",
            "  \"model.elapsed_time\": 0.10922360420227051,\n",
            "  \"model.engine_step\": 739,\n",
            "  \"model.loss.nll\": 0.0014333724975585938,\n",
            "  \"elapsed_time\": 0.10922360420227051,\n",
            "  \"wall_time\": 1677241378.0453467,\n",
            "  \"global_step\": 739\n",
            "}\n",
            "[2023-02-24 12:22:58,148] [INFO] [logging.py:75:log_dist] [Rank 0] step=740, skipped=1, lr=[0.00014786200000000002], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:58,149] [INFO] [timer.py:198:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=12.566348888090149, CurrSamplesPerSec=9.853625302764407, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0012531280517578125,\n",
            "  \"model.lr\": 0.00014786200000000002,\n",
            "  \"model.grad_norm\": 0.06651897728443146,\n",
            "  \"model.elapsed_time\": 0.10217142105102539,\n",
            "  \"model.engine_step\": 740,\n",
            "  \"model.loss.nll\": 0.0012531280517578125,\n",
            "  \"elapsed_time\": 0.10217142105102539,\n",
            "  \"wall_time\": 1677241378.151242,\n",
            "  \"global_step\": 740\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.004886627197265625,\n",
            "  \"model.lr\": 0.000148061,\n",
            "  \"model.grad_norm\": 0.6844617128372192,\n",
            "  \"model.elapsed_time\": 0.10025334358215332,\n",
            "  \"model.engine_step\": 741,\n",
            "  \"model.loss.nll\": 0.004886627197265625,\n",
            "  \"elapsed_time\": 0.10025334358215332,\n",
            "  \"wall_time\": 1677241378.261397,\n",
            "  \"global_step\": 741\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.020294189453125,\n",
            "  \"model.lr\": 0.00014826,\n",
            "  \"model.grad_norm\": 1.1018837690353394,\n",
            "  \"model.elapsed_time\": 0.10715341567993164,\n",
            "  \"model.engine_step\": 742,\n",
            "  \"model.loss.nll\": 0.020294189453125,\n",
            "  \"elapsed_time\": 0.10715341567993164,\n",
            "  \"wall_time\": 1677241378.371805,\n",
            "  \"global_step\": 742\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011720657348632812,\n",
            "  \"model.lr\": 0.000148459,\n",
            "  \"model.grad_norm\": 0.0648680254817009,\n",
            "  \"model.elapsed_time\": 0.10145688056945801,\n",
            "  \"model.engine_step\": 743,\n",
            "  \"model.loss.nll\": 0.0011720657348632812,\n",
            "  \"elapsed_time\": 0.10145688056945801,\n",
            "  \"wall_time\": 1677241378.4825904,\n",
            "  \"global_step\": 743\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00145721435546875,\n",
            "  \"model.lr\": 0.000148658,\n",
            "  \"model.grad_norm\": 0.017164131626486778,\n",
            "  \"model.elapsed_time\": 0.0996086597442627,\n",
            "  \"model.engine_step\": 744,\n",
            "  \"model.loss.nll\": 0.00145721435546875,\n",
            "  \"elapsed_time\": 0.0996086597442627,\n",
            "  \"wall_time\": 1677241378.5854099,\n",
            "  \"global_step\": 744\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011320114135742188,\n",
            "  \"model.lr\": 0.00014885700000000001,\n",
            "  \"model.grad_norm\": 0.05257267877459526,\n",
            "  \"model.elapsed_time\": 0.10109281539916992,\n",
            "  \"model.engine_step\": 745,\n",
            "  \"model.loss.nll\": 0.0011320114135742188,\n",
            "  \"elapsed_time\": 0.10109281539916992,\n",
            "  \"wall_time\": 1677241378.6950464,\n",
            "  \"global_step\": 745\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0027866363525390625,\n",
            "  \"model.lr\": 0.000149056,\n",
            "  \"model.grad_norm\": 0.34622320532798767,\n",
            "  \"model.elapsed_time\": 0.10319185256958008,\n",
            "  \"model.engine_step\": 746,\n",
            "  \"model.loss.nll\": 0.0027866363525390625,\n",
            "  \"elapsed_time\": 0.10319185256958008,\n",
            "  \"wall_time\": 1677241378.8011622,\n",
            "  \"global_step\": 746\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:58\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0125885009765625,\n",
            "  \"model.lr\": 0.000149255,\n",
            "  \"model.grad_norm\": 1.0984838008880615,\n",
            "  \"model.elapsed_time\": 0.10275483131408691,\n",
            "  \"model.engine_step\": 747,\n",
            "  \"model.loss.nll\": 0.0125885009765625,\n",
            "  \"elapsed_time\": 0.10275483131408691,\n",
            "  \"wall_time\": 1677241378.9152303,\n",
            "  \"global_step\": 747\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00737762451171875,\n",
            "  \"model.lr\": 0.000149454,\n",
            "  \"model.grad_norm\": 0.912342369556427,\n",
            "  \"model.elapsed_time\": 0.10164546966552734,\n",
            "  \"model.engine_step\": 748,\n",
            "  \"model.loss.nll\": 0.00737762451171875,\n",
            "  \"elapsed_time\": 0.10164546966552734,\n",
            "  \"wall_time\": 1677241379.023131,\n",
            "  \"global_step\": 748\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0016412734985351562,\n",
            "  \"model.lr\": 0.000149653,\n",
            "  \"model.grad_norm\": 0.1498090624809265,\n",
            "  \"model.elapsed_time\": 0.1060495376586914,\n",
            "  \"model.engine_step\": 749,\n",
            "  \"model.loss.nll\": 0.0016412734985351562,\n",
            "  \"elapsed_time\": 0.1060495376586914,\n",
            "  \"wall_time\": 1677241379.1452055,\n",
            "  \"global_step\": 749\n",
            "}\n",
            "[2023-02-24 12:22:59,223] [INFO] [logging.py:75:log_dist] [Rank 0] step=750, skipped=1, lr=[0.00014985200000000001], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:59,225] [INFO] [timer.py:198:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=12.523288989453242, CurrSamplesPerSec=12.763308603806196, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011491775512695312,\n",
            "  \"model.lr\": 0.00014985200000000001,\n",
            "  \"model.grad_norm\": 0.0321364663541317,\n",
            "  \"model.elapsed_time\": 0.07878684997558594,\n",
            "  \"model.engine_step\": 750,\n",
            "  \"model.loss.nll\": 0.0011491775512695312,\n",
            "  \"elapsed_time\": 0.07878684997558594,\n",
            "  \"wall_time\": 1677241379.2263672,\n",
            "  \"global_step\": 750\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000995635986328125,\n",
            "  \"model.lr\": 0.000150051,\n",
            "  \"model.grad_norm\": 0.016966598108410835,\n",
            "  \"model.elapsed_time\": 0.06627130508422852,\n",
            "  \"model.engine_step\": 751,\n",
            "  \"model.loss.nll\": 0.000995635986328125,\n",
            "  \"elapsed_time\": 0.06627130508422852,\n",
            "  \"wall_time\": 1677241379.2995973,\n",
            "  \"global_step\": 751\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008826255798339844,\n",
            "  \"model.lr\": 0.00015025000000000002,\n",
            "  \"model.grad_norm\": 0.02824476547539234,\n",
            "  \"model.elapsed_time\": 0.07513952255249023,\n",
            "  \"model.engine_step\": 752,\n",
            "  \"model.loss.nll\": 0.0008826255798339844,\n",
            "  \"elapsed_time\": 0.07513952255249023,\n",
            "  \"wall_time\": 1677241379.3772364,\n",
            "  \"global_step\": 752\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00107574462890625,\n",
            "  \"model.lr\": 0.000150449,\n",
            "  \"model.grad_norm\": 0.044222794473171234,\n",
            "  \"model.elapsed_time\": 0.06397676467895508,\n",
            "  \"model.engine_step\": 753,\n",
            "  \"model.loss.nll\": 0.00107574462890625,\n",
            "  \"elapsed_time\": 0.06397676467895508,\n",
            "  \"wall_time\": 1677241379.4500113,\n",
            "  \"global_step\": 753\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0017938613891601562,\n",
            "  \"model.lr\": 0.000150648,\n",
            "  \"model.grad_norm\": 0.16003203392028809,\n",
            "  \"model.elapsed_time\": 0.06384563446044922,\n",
            "  \"model.engine_step\": 754,\n",
            "  \"model.loss.nll\": 0.0017938613891601562,\n",
            "  \"elapsed_time\": 0.06384563446044922,\n",
            "  \"wall_time\": 1677241379.5158052,\n",
            "  \"global_step\": 754\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002376556396484375,\n",
            "  \"model.lr\": 0.00015084700000000001,\n",
            "  \"model.grad_norm\": 0.29417136311531067,\n",
            "  \"model.elapsed_time\": 0.06662464141845703,\n",
            "  \"model.engine_step\": 755,\n",
            "  \"model.loss.nll\": 0.002376556396484375,\n",
            "  \"elapsed_time\": 0.06662464141845703,\n",
            "  \"wall_time\": 1677241379.5903327,\n",
            "  \"global_step\": 755\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.01247406005859375,\n",
            "  \"model.lr\": 0.000151046,\n",
            "  \"model.grad_norm\": 0.8122683763504028,\n",
            "  \"model.elapsed_time\": 0.08042192459106445,\n",
            "  \"model.engine_step\": 756,\n",
            "  \"model.loss.nll\": 0.01247406005859375,\n",
            "  \"elapsed_time\": 0.08042192459106445,\n",
            "  \"wall_time\": 1677241379.6727905,\n",
            "  \"global_step\": 756\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0209197998046875,\n",
            "  \"model.lr\": 0.00015124500000000002,\n",
            "  \"model.grad_norm\": 1.3600472211837769,\n",
            "  \"model.elapsed_time\": 0.06864476203918457,\n",
            "  \"model.engine_step\": 757,\n",
            "  \"model.loss.nll\": 0.0209197998046875,\n",
            "  \"elapsed_time\": 0.06864476203918457,\n",
            "  \"wall_time\": 1677241379.7486484,\n",
            "  \"global_step\": 757\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009098052978515625,\n",
            "  \"model.lr\": 0.000151444,\n",
            "  \"model.grad_norm\": 0.014120414853096008,\n",
            "  \"model.elapsed_time\": 0.06481075286865234,\n",
            "  \"model.engine_step\": 758,\n",
            "  \"model.loss.nll\": 0.0009098052978515625,\n",
            "  \"elapsed_time\": 0.06481075286865234,\n",
            "  \"wall_time\": 1677241379.8162687,\n",
            "  \"global_step\": 758\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0028896331787109375,\n",
            "  \"model.lr\": 0.000151643,\n",
            "  \"model.grad_norm\": 0.16604970395565033,\n",
            "  \"model.elapsed_time\": 0.07118749618530273,\n",
            "  \"model.engine_step\": 759,\n",
            "  \"model.loss.nll\": 0.0028896331787109375,\n",
            "  \"elapsed_time\": 0.07118749618530273,\n",
            "  \"wall_time\": 1677241379.8945963,\n",
            "  \"global_step\": 759\n",
            "}\n",
            "[2023-02-24 12:22:59,971] [INFO] [logging.py:75:log_dist] [Rank 0] step=760, skipped=1, lr=[0.00015184200000000001], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:22:59,973] [INFO] [timer.py:198:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=12.544386501024453, CurrSamplesPerSec=13.071254051358764, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009403228759765625,\n",
            "  \"model.lr\": 0.00015184200000000001,\n",
            "  \"model.grad_norm\": 0.02357635460793972,\n",
            "  \"model.elapsed_time\": 0.07696366310119629,\n",
            "  \"model.engine_step\": 760,\n",
            "  \"model.loss.nll\": 0.0009403228759765625,\n",
            "  \"elapsed_time\": 0.07696366310119629,\n",
            "  \"wall_time\": 1677241379.974303,\n",
            "  \"global_step\": 760\n",
            "}\n",
            "\u001b[32m2023-02-24 12:22:59\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.004123687744140625,\n",
            "  \"model.lr\": 0.000152041,\n",
            "  \"model.grad_norm\": 0.3610406219959259,\n",
            "  \"model.elapsed_time\": 0.07361078262329102,\n",
            "  \"model.engine_step\": 761,\n",
            "  \"model.loss.nll\": 0.004123687744140625,\n",
            "  \"elapsed_time\": 0.07361078262329102,\n",
            "  \"wall_time\": 1677241380.0551152,\n",
            "  \"global_step\": 761\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.060546875,\n",
            "  \"model.lr\": 0.00015224000000000002,\n",
            "  \"model.grad_norm\": 1.2452399730682373,\n",
            "  \"model.elapsed_time\": 0.07144331932067871,\n",
            "  \"model.engine_step\": 762,\n",
            "  \"model.loss.nll\": 0.060546875,\n",
            "  \"elapsed_time\": 0.07144331932067871,\n",
            "  \"wall_time\": 1677241380.1292045,\n",
            "  \"global_step\": 762\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001026153564453125,\n",
            "  \"model.lr\": 0.000152439,\n",
            "  \"model.grad_norm\": 0.04876940697431564,\n",
            "  \"model.elapsed_time\": 0.07016944885253906,\n",
            "  \"model.engine_step\": 763,\n",
            "  \"model.loss.nll\": 0.001026153564453125,\n",
            "  \"elapsed_time\": 0.07016944885253906,\n",
            "  \"wall_time\": 1677241380.2071588,\n",
            "  \"global_step\": 763\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009555816650390625,\n",
            "  \"model.lr\": 0.000152638,\n",
            "  \"model.grad_norm\": 0.026369763538241386,\n",
            "  \"model.elapsed_time\": 0.07163596153259277,\n",
            "  \"model.engine_step\": 764,\n",
            "  \"model.loss.nll\": 0.0009555816650390625,\n",
            "  \"elapsed_time\": 0.07163596153259277,\n",
            "  \"wall_time\": 1677241380.2818878,\n",
            "  \"global_step\": 764\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008549690246582031,\n",
            "  \"model.lr\": 0.00015283700000000001,\n",
            "  \"model.grad_norm\": 0.015623246319591999,\n",
            "  \"model.elapsed_time\": 0.06852436065673828,\n",
            "  \"model.engine_step\": 765,\n",
            "  \"model.loss.nll\": 0.0008549690246582031,\n",
            "  \"elapsed_time\": 0.06852436065673828,\n",
            "  \"wall_time\": 1677241380.3598096,\n",
            "  \"global_step\": 765\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007600784301757812,\n",
            "  \"model.lr\": 0.000153036,\n",
            "  \"model.grad_norm\": 0.01624409854412079,\n",
            "  \"model.elapsed_time\": 0.06444263458251953,\n",
            "  \"model.engine_step\": 766,\n",
            "  \"model.loss.nll\": 0.0007600784301757812,\n",
            "  \"elapsed_time\": 0.06444263458251953,\n",
            "  \"wall_time\": 1677241380.4263983,\n",
            "  \"global_step\": 766\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.008636474609375,\n",
            "  \"model.lr\": 0.00015323500000000002,\n",
            "  \"model.grad_norm\": 0.5593514442443848,\n",
            "  \"model.elapsed_time\": 0.0729970932006836,\n",
            "  \"model.engine_step\": 767,\n",
            "  \"model.loss.nll\": 0.008636474609375,\n",
            "  \"elapsed_time\": 0.0729970932006836,\n",
            "  \"wall_time\": 1677241380.506267,\n",
            "  \"global_step\": 767\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006914138793945312,\n",
            "  \"model.lr\": 0.000153434,\n",
            "  \"model.grad_norm\": 0.009915541857481003,\n",
            "  \"model.elapsed_time\": 0.07178878784179688,\n",
            "  \"model.engine_step\": 768,\n",
            "  \"model.loss.nll\": 0.0006914138793945312,\n",
            "  \"elapsed_time\": 0.07178878784179688,\n",
            "  \"wall_time\": 1677241380.5807717,\n",
            "  \"global_step\": 768\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008559226989746094,\n",
            "  \"model.lr\": 0.000153633,\n",
            "  \"model.grad_norm\": 0.019361210986971855,\n",
            "  \"model.elapsed_time\": 0.06363344192504883,\n",
            "  \"model.engine_step\": 769,\n",
            "  \"model.loss.nll\": 0.0008559226989746094,\n",
            "  \"elapsed_time\": 0.06363344192504883,\n",
            "  \"wall_time\": 1677241380.651305,\n",
            "  \"global_step\": 769\n",
            "}\n",
            "[2023-02-24 12:23:00,721] [INFO] [logging.py:75:log_dist] [Rank 0] step=770, skipped=1, lr=[0.00015383200000000001], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:00,723] [INFO] [timer.py:198:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=12.564903401281766, CurrSamplesPerSec=14.342933351571316, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008454322814941406,\n",
            "  \"model.lr\": 0.00015383200000000001,\n",
            "  \"model.grad_norm\": 0.016133230179548264,\n",
            "  \"model.elapsed_time\": 0.07014012336730957,\n",
            "  \"model.engine_step\": 770,\n",
            "  \"model.loss.nll\": 0.0008454322814941406,\n",
            "  \"elapsed_time\": 0.07014012336730957,\n",
            "  \"wall_time\": 1677241380.7241066,\n",
            "  \"global_step\": 770\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009093284606933594,\n",
            "  \"model.lr\": 0.000154031,\n",
            "  \"model.grad_norm\": 0.03169211372733116,\n",
            "  \"model.elapsed_time\": 0.0650019645690918,\n",
            "  \"model.engine_step\": 771,\n",
            "  \"model.loss.nll\": 0.0009093284606933594,\n",
            "  \"elapsed_time\": 0.0650019645690918,\n",
            "  \"wall_time\": 1677241380.7956226,\n",
            "  \"global_step\": 771\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008053779602050781,\n",
            "  \"model.lr\": 0.00015423000000000002,\n",
            "  \"model.grad_norm\": 0.020198779180645943,\n",
            "  \"model.elapsed_time\": 0.06908082962036133,\n",
            "  \"model.engine_step\": 772,\n",
            "  \"model.loss.nll\": 0.0008053779602050781,\n",
            "  \"elapsed_time\": 0.06908082962036133,\n",
            "  \"wall_time\": 1677241380.8671894,\n",
            "  \"global_step\": 772\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:00\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009927749633789062,\n",
            "  \"model.lr\": 0.000154429,\n",
            "  \"model.grad_norm\": 0.030837683007121086,\n",
            "  \"model.elapsed_time\": 0.06635618209838867,\n",
            "  \"model.engine_step\": 773,\n",
            "  \"model.loss.nll\": 0.0009927749633789062,\n",
            "  \"elapsed_time\": 0.06635618209838867,\n",
            "  \"wall_time\": 1677241380.9413898,\n",
            "  \"global_step\": 773\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002105712890625,\n",
            "  \"model.lr\": 0.000154628,\n",
            "  \"model.grad_norm\": 0.06309163570404053,\n",
            "  \"model.elapsed_time\": 0.06730508804321289,\n",
            "  \"model.engine_step\": 774,\n",
            "  \"model.loss.nll\": 0.002105712890625,\n",
            "  \"elapsed_time\": 0.06730508804321289,\n",
            "  \"wall_time\": 1677241381.0108066,\n",
            "  \"global_step\": 774\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008034706115722656,\n",
            "  \"model.lr\": 0.00015482700000000001,\n",
            "  \"model.grad_norm\": 0.014735388569533825,\n",
            "  \"model.elapsed_time\": 0.07149648666381836,\n",
            "  \"model.engine_step\": 775,\n",
            "  \"model.loss.nll\": 0.0008034706115722656,\n",
            "  \"elapsed_time\": 0.07149648666381836,\n",
            "  \"wall_time\": 1677241381.0913177,\n",
            "  \"global_step\": 775\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009870529174804688,\n",
            "  \"model.lr\": 0.000155026,\n",
            "  \"model.grad_norm\": 0.046180956065654755,\n",
            "  \"model.elapsed_time\": 0.0647578239440918,\n",
            "  \"model.engine_step\": 776,\n",
            "  \"model.loss.nll\": 0.0009870529174804688,\n",
            "  \"elapsed_time\": 0.0647578239440918,\n",
            "  \"wall_time\": 1677241381.158067,\n",
            "  \"global_step\": 776\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0018053054809570312,\n",
            "  \"model.lr\": 0.00015522500000000002,\n",
            "  \"model.grad_norm\": 0.07731420546770096,\n",
            "  \"model.elapsed_time\": 0.06737923622131348,\n",
            "  \"model.engine_step\": 777,\n",
            "  \"model.loss.nll\": 0.0018053054809570312,\n",
            "  \"elapsed_time\": 0.06737923622131348,\n",
            "  \"wall_time\": 1677241381.2324035,\n",
            "  \"global_step\": 777\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002544403076171875,\n",
            "  \"model.lr\": 0.000155424,\n",
            "  \"model.grad_norm\": 0.11073656380176544,\n",
            "  \"model.elapsed_time\": 0.0639810562133789,\n",
            "  \"model.engine_step\": 778,\n",
            "  \"model.loss.nll\": 0.002544403076171875,\n",
            "  \"elapsed_time\": 0.0639810562133789,\n",
            "  \"wall_time\": 1677241381.2983124,\n",
            "  \"global_step\": 778\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.04644775390625,\n",
            "  \"model.lr\": 0.00015562300000000002,\n",
            "  \"model.grad_norm\": 1.0522624254226685,\n",
            "  \"model.elapsed_time\": 0.07142448425292969,\n",
            "  \"model.engine_step\": 779,\n",
            "  \"model.loss.nll\": 0.04644775390625,\n",
            "  \"elapsed_time\": 0.07142448425292969,\n",
            "  \"wall_time\": 1677241381.3774917,\n",
            "  \"global_step\": 779\n",
            "}\n",
            "[2023-02-24 12:23:01,440] [INFO] [logging.py:75:log_dist] [Rank 0] step=780, skipped=1, lr=[0.000155822], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:01,442] [INFO] [timer.py:198:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=12.59059605047958, CurrSamplesPerSec=15.776600866634569, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007538795471191406,\n",
            "  \"model.lr\": 0.000155822,\n",
            "  \"model.grad_norm\": 0.01339926477521658,\n",
            "  \"model.elapsed_time\": 0.06380891799926758,\n",
            "  \"model.engine_step\": 780,\n",
            "  \"model.loss.nll\": 0.0007538795471191406,\n",
            "  \"elapsed_time\": 0.06380891799926758,\n",
            "  \"wall_time\": 1677241381.4434278,\n",
            "  \"global_step\": 780\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008001327514648438,\n",
            "  \"model.lr\": 0.000156021,\n",
            "  \"model.grad_norm\": 0.01946989819407463,\n",
            "  \"model.elapsed_time\": 0.06490135192871094,\n",
            "  \"model.engine_step\": 781,\n",
            "  \"model.loss.nll\": 0.0008001327514648438,\n",
            "  \"elapsed_time\": 0.06490135192871094,\n",
            "  \"wall_time\": 1677241381.5166864,\n",
            "  \"global_step\": 781\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007710456848144531,\n",
            "  \"model.lr\": 0.00015622000000000002,\n",
            "  \"model.grad_norm\": 0.011276395060122013,\n",
            "  \"model.elapsed_time\": 0.06421971321105957,\n",
            "  \"model.engine_step\": 782,\n",
            "  \"model.loss.nll\": 0.0007710456848144531,\n",
            "  \"elapsed_time\": 0.06421971321105957,\n",
            "  \"wall_time\": 1677241381.5828552,\n",
            "  \"global_step\": 782\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007948875427246094,\n",
            "  \"model.lr\": 0.000156419,\n",
            "  \"model.grad_norm\": 0.022952957078814507,\n",
            "  \"model.elapsed_time\": 0.06377458572387695,\n",
            "  \"model.engine_step\": 783,\n",
            "  \"model.loss.nll\": 0.0007948875427246094,\n",
            "  \"elapsed_time\": 0.06377458572387695,\n",
            "  \"wall_time\": 1677241381.6552515,\n",
            "  \"global_step\": 783\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.007411956787109375,\n",
            "  \"model.lr\": 0.00015661800000000002,\n",
            "  \"model.grad_norm\": 0.4623574912548065,\n",
            "  \"model.elapsed_time\": 0.07111883163452148,\n",
            "  \"model.engine_step\": 784,\n",
            "  \"model.loss.nll\": 0.007411956787109375,\n",
            "  \"elapsed_time\": 0.07111883163452148,\n",
            "  \"wall_time\": 1677241381.7286346,\n",
            "  \"global_step\": 784\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0016326904296875,\n",
            "  \"model.lr\": 0.000156817,\n",
            "  \"model.grad_norm\": 0.033170368522405624,\n",
            "  \"model.elapsed_time\": 0.06450414657592773,\n",
            "  \"model.engine_step\": 785,\n",
            "  \"model.loss.nll\": 0.0016326904296875,\n",
            "  \"elapsed_time\": 0.06450414657592773,\n",
            "  \"wall_time\": 1677241381.7995055,\n",
            "  \"global_step\": 785\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00107574462890625,\n",
            "  \"model.lr\": 0.000157016,\n",
            "  \"model.grad_norm\": 0.059190865606069565,\n",
            "  \"model.elapsed_time\": 0.06458330154418945,\n",
            "  \"model.engine_step\": 786,\n",
            "  \"model.loss.nll\": 0.00107574462890625,\n",
            "  \"elapsed_time\": 0.06458330154418945,\n",
            "  \"wall_time\": 1677241381.8665981,\n",
            "  \"global_step\": 786\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:01\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002429962158203125,\n",
            "  \"model.lr\": 0.00015721500000000002,\n",
            "  \"model.grad_norm\": 0.25181931257247925,\n",
            "  \"model.elapsed_time\": 0.06707334518432617,\n",
            "  \"model.engine_step\": 787,\n",
            "  \"model.loss.nll\": 0.002429962158203125,\n",
            "  \"elapsed_time\": 0.06707334518432617,\n",
            "  \"wall_time\": 1677241381.9407349,\n",
            "  \"global_step\": 787\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002498626708984375,\n",
            "  \"model.lr\": 0.000157414,\n",
            "  \"model.grad_norm\": 0.2789984941482544,\n",
            "  \"model.elapsed_time\": 0.07450366020202637,\n",
            "  \"model.engine_step\": 788,\n",
            "  \"model.loss.nll\": 0.002498626708984375,\n",
            "  \"elapsed_time\": 0.07450366020202637,\n",
            "  \"wall_time\": 1677241382.017913,\n",
            "  \"global_step\": 788\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.007083892822265625,\n",
            "  \"model.lr\": 0.00015761300000000002,\n",
            "  \"model.grad_norm\": 0.7127513289451599,\n",
            "  \"model.elapsed_time\": 0.06782269477844238,\n",
            "  \"model.engine_step\": 789,\n",
            "  \"model.loss.nll\": 0.007083892822265625,\n",
            "  \"elapsed_time\": 0.06782269477844238,\n",
            "  \"wall_time\": 1677241382.0938685,\n",
            "  \"global_step\": 789\n",
            "}\n",
            "[2023-02-24 12:23:02,157] [INFO] [logging.py:75:log_dist] [Rank 0] step=790, skipped=1, lr=[0.000157812], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:02,159] [INFO] [timer.py:198:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=12.616472842449065, CurrSamplesPerSec=15.589542308750177, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00115203857421875,\n",
            "  \"model.lr\": 0.000157812,\n",
            "  \"model.grad_norm\": 0.04974064603447914,\n",
            "  \"model.elapsed_time\": 0.0645451545715332,\n",
            "  \"model.engine_step\": 790,\n",
            "  \"model.loss.nll\": 0.00115203857421875,\n",
            "  \"elapsed_time\": 0.0645451545715332,\n",
            "  \"wall_time\": 1677241382.1604483,\n",
            "  \"global_step\": 790\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007448196411132812,\n",
            "  \"model.lr\": 0.000158011,\n",
            "  \"model.grad_norm\": 0.015695884823799133,\n",
            "  \"model.elapsed_time\": 0.06517791748046875,\n",
            "  \"model.engine_step\": 791,\n",
            "  \"model.loss.nll\": 0.0007448196411132812,\n",
            "  \"elapsed_time\": 0.06517791748046875,\n",
            "  \"wall_time\": 1677241382.2324321,\n",
            "  \"global_step\": 791\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0084686279296875,\n",
            "  \"model.lr\": 0.00015821000000000002,\n",
            "  \"model.grad_norm\": 0.45085448026657104,\n",
            "  \"model.elapsed_time\": 0.07253694534301758,\n",
            "  \"model.engine_step\": 792,\n",
            "  \"model.loss.nll\": 0.0084686279296875,\n",
            "  \"elapsed_time\": 0.07253694534301758,\n",
            "  \"wall_time\": 1677241382.3075671,\n",
            "  \"global_step\": 792\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006480216979980469,\n",
            "  \"model.lr\": 0.000158409,\n",
            "  \"model.grad_norm\": 0.011136211454868317,\n",
            "  \"model.elapsed_time\": 0.06580710411071777,\n",
            "  \"model.engine_step\": 793,\n",
            "  \"model.loss.nll\": 0.0006480216979980469,\n",
            "  \"elapsed_time\": 0.06580710411071777,\n",
            "  \"wall_time\": 1677241382.3806956,\n",
            "  \"global_step\": 793\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0015535354614257812,\n",
            "  \"model.lr\": 0.00015860800000000002,\n",
            "  \"model.grad_norm\": 0.04166775196790695,\n",
            "  \"model.elapsed_time\": 0.0641782283782959,\n",
            "  \"model.engine_step\": 794,\n",
            "  \"model.loss.nll\": 0.0015535354614257812,\n",
            "  \"elapsed_time\": 0.0641782283782959,\n",
            "  \"wall_time\": 1677241382.446835,\n",
            "  \"global_step\": 794\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008544921875,\n",
            "  \"model.lr\": 0.000158807,\n",
            "  \"model.grad_norm\": 0.016405681148171425,\n",
            "  \"model.elapsed_time\": 0.06781291961669922,\n",
            "  \"model.engine_step\": 795,\n",
            "  \"model.loss.nll\": 0.0008544921875,\n",
            "  \"elapsed_time\": 0.06781291961669922,\n",
            "  \"wall_time\": 1677241382.5221148,\n",
            "  \"global_step\": 795\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006532669067382812,\n",
            "  \"model.lr\": 0.000159006,\n",
            "  \"model.grad_norm\": 0.01904493197798729,\n",
            "  \"model.elapsed_time\": 0.06314873695373535,\n",
            "  \"model.engine_step\": 796,\n",
            "  \"model.loss.nll\": 0.0006532669067382812,\n",
            "  \"elapsed_time\": 0.06314873695373535,\n",
            "  \"wall_time\": 1677241382.5872009,\n",
            "  \"global_step\": 796\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006737709045410156,\n",
            "  \"model.lr\": 0.00015920500000000002,\n",
            "  \"model.grad_norm\": 0.016833001747727394,\n",
            "  \"model.elapsed_time\": 0.06738400459289551,\n",
            "  \"model.engine_step\": 797,\n",
            "  \"model.loss.nll\": 0.0006737709045410156,\n",
            "  \"elapsed_time\": 0.06738400459289551,\n",
            "  \"wall_time\": 1677241382.6617172,\n",
            "  \"global_step\": 797\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011959075927734375,\n",
            "  \"model.lr\": 0.000159404,\n",
            "  \"model.grad_norm\": 0.0690353587269783,\n",
            "  \"model.elapsed_time\": 0.0724949836730957,\n",
            "  \"model.engine_step\": 798,\n",
            "  \"model.loss.nll\": 0.0011959075927734375,\n",
            "  \"elapsed_time\": 0.0724949836730957,\n",
            "  \"wall_time\": 1677241382.7370737,\n",
            "  \"global_step\": 798\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.006999969482421875,\n",
            "  \"model.lr\": 0.00015960300000000002,\n",
            "  \"model.grad_norm\": 0.8712183833122253,\n",
            "  \"model.elapsed_time\": 0.07241439819335938,\n",
            "  \"model.engine_step\": 799,\n",
            "  \"model.loss.nll\": 0.006999969482421875,\n",
            "  \"elapsed_time\": 0.07241439819335938,\n",
            "  \"wall_time\": 1677241382.8170438,\n",
            "  \"global_step\": 799\n",
            "}\n",
            "[2023-02-24 12:23:02,883] [INFO] [logging.py:75:log_dist] [Rank 0] step=800, skipped=1, lr=[0.000159802], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:02,884] [INFO] [timer.py:198:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=12.639803804441852, CurrSamplesPerSec=15.234785388161026, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008697509765625,\n",
            "  \"model.lr\": 0.000159802,\n",
            "  \"model.grad_norm\": 0.03001824952661991,\n",
            "  \"model.elapsed_time\": 0.06608915328979492,\n",
            "  \"model.engine_step\": 800,\n",
            "  \"model.loss.nll\": 0.0008697509765625,\n",
            "  \"elapsed_time\": 0.06608915328979492,\n",
            "  \"wall_time\": 1677241382.8859777,\n",
            "  \"global_step\": 800\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:02\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006818771362304688,\n",
            "  \"model.lr\": 0.00016000100000000003,\n",
            "  \"model.grad_norm\": 0.008601438254117966,\n",
            "  \"model.elapsed_time\": 0.06595993041992188,\n",
            "  \"model.engine_step\": 801,\n",
            "  \"model.loss.nll\": 0.0006818771362304688,\n",
            "  \"elapsed_time\": 0.06595993041992188,\n",
            "  \"wall_time\": 1677241382.9593394,\n",
            "  \"global_step\": 801\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000675201416015625,\n",
            "  \"model.lr\": 0.00016020000000000002,\n",
            "  \"model.grad_norm\": 0.01513877883553505,\n",
            "  \"model.elapsed_time\": 0.07141423225402832,\n",
            "  \"model.engine_step\": 802,\n",
            "  \"model.loss.nll\": 0.000675201416015625,\n",
            "  \"elapsed_time\": 0.07141423225402832,\n",
            "  \"wall_time\": 1677241383.0333436,\n",
            "  \"global_step\": 802\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000762939453125,\n",
            "  \"model.lr\": 0.000160399,\n",
            "  \"model.grad_norm\": 0.011030837893486023,\n",
            "  \"model.elapsed_time\": 0.06719493865966797,\n",
            "  \"model.engine_step\": 803,\n",
            "  \"model.loss.nll\": 0.000762939453125,\n",
            "  \"elapsed_time\": 0.06719493865966797,\n",
            "  \"wall_time\": 1677241383.1094418,\n",
            "  \"global_step\": 803\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008406639099121094,\n",
            "  \"model.lr\": 0.00016059800000000002,\n",
            "  \"model.grad_norm\": 0.022809777408838272,\n",
            "  \"model.elapsed_time\": 0.06842803955078125,\n",
            "  \"model.engine_step\": 804,\n",
            "  \"model.loss.nll\": 0.0008406639099121094,\n",
            "  \"elapsed_time\": 0.06842803955078125,\n",
            "  \"wall_time\": 1677241383.1810536,\n",
            "  \"global_step\": 804\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.006313323974609375,\n",
            "  \"model.lr\": 0.000160797,\n",
            "  \"model.grad_norm\": 0.3439086079597473,\n",
            "  \"model.elapsed_time\": 0.06708073616027832,\n",
            "  \"model.engine_step\": 805,\n",
            "  \"model.loss.nll\": 0.006313323974609375,\n",
            "  \"elapsed_time\": 0.06708073616027832,\n",
            "  \"wall_time\": 1677241383.2568803,\n",
            "  \"global_step\": 805\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00101470947265625,\n",
            "  \"model.lr\": 0.00016099600000000003,\n",
            "  \"model.grad_norm\": 0.05577832832932472,\n",
            "  \"model.elapsed_time\": 0.06734538078308105,\n",
            "  \"model.engine_step\": 806,\n",
            "  \"model.loss.nll\": 0.00101470947265625,\n",
            "  \"elapsed_time\": 0.06734538078308105,\n",
            "  \"wall_time\": 1677241383.3268707,\n",
            "  \"global_step\": 806\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0033130645751953125,\n",
            "  \"model.lr\": 0.00016119500000000002,\n",
            "  \"model.grad_norm\": 0.09477970749139786,\n",
            "  \"model.elapsed_time\": 0.06815624237060547,\n",
            "  \"model.engine_step\": 807,\n",
            "  \"model.loss.nll\": 0.0033130645751953125,\n",
            "  \"elapsed_time\": 0.06815624237060547,\n",
            "  \"wall_time\": 1677241383.4025934,\n",
            "  \"global_step\": 807\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006051063537597656,\n",
            "  \"model.lr\": 0.000161394,\n",
            "  \"model.grad_norm\": 0.008063897490501404,\n",
            "  \"model.elapsed_time\": 0.06793951988220215,\n",
            "  \"model.engine_step\": 808,\n",
            "  \"model.loss.nll\": 0.0006051063537597656,\n",
            "  \"elapsed_time\": 0.06793951988220215,\n",
            "  \"wall_time\": 1677241383.4736013,\n",
            "  \"global_step\": 808\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005960464477539062,\n",
            "  \"model.lr\": 0.00016159300000000002,\n",
            "  \"model.grad_norm\": 0.00794230680912733,\n",
            "  \"model.elapsed_time\": 0.06807112693786621,\n",
            "  \"model.engine_step\": 809,\n",
            "  \"model.loss.nll\": 0.0005960464477539062,\n",
            "  \"elapsed_time\": 0.06807112693786621,\n",
            "  \"wall_time\": 1677241383.554512,\n",
            "  \"global_step\": 809\n",
            "}\n",
            "[2023-02-24 12:23:03,623] [INFO] [logging.py:75:log_dist] [Rank 0] step=810, skipped=1, lr=[0.000161792], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:03,624] [INFO] [timer.py:198:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=12.661914369285114, CurrSamplesPerSec=14.551631302127424, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006327629089355469,\n",
            "  \"model.lr\": 0.000161792,\n",
            "  \"model.grad_norm\": 0.01057822722941637,\n",
            "  \"model.elapsed_time\": 0.06916022300720215,\n",
            "  \"model.engine_step\": 810,\n",
            "  \"model.loss.nll\": 0.0006327629089355469,\n",
            "  \"elapsed_time\": 0.06916022300720215,\n",
            "  \"wall_time\": 1677241383.6258702,\n",
            "  \"global_step\": 810\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.003276824951171875,\n",
            "  \"model.lr\": 0.00016199100000000003,\n",
            "  \"model.grad_norm\": 0.0673564150929451,\n",
            "  \"model.elapsed_time\": 0.06847000122070312,\n",
            "  \"model.engine_step\": 811,\n",
            "  \"model.loss.nll\": 0.003276824951171875,\n",
            "  \"elapsed_time\": 0.06847000122070312,\n",
            "  \"wall_time\": 1677241383.7029884,\n",
            "  \"global_step\": 811\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009794235229492188,\n",
            "  \"model.lr\": 0.00016219000000000002,\n",
            "  \"model.grad_norm\": 0.05661580711603165,\n",
            "  \"model.elapsed_time\": 0.08446955680847168,\n",
            "  \"model.engine_step\": 812,\n",
            "  \"model.loss.nll\": 0.0009794235229492188,\n",
            "  \"elapsed_time\": 0.08446955680847168,\n",
            "  \"wall_time\": 1677241383.7899694,\n",
            "  \"global_step\": 812\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007100105285644531,\n",
            "  \"model.lr\": 0.000162389,\n",
            "  \"model.grad_norm\": 0.021129602566361427,\n",
            "  \"model.elapsed_time\": 0.06722116470336914,\n",
            "  \"model.engine_step\": 813,\n",
            "  \"model.loss.nll\": 0.0007100105285644531,\n",
            "  \"elapsed_time\": 0.06722116470336914,\n",
            "  \"wall_time\": 1677241383.8657935,\n",
            "  \"global_step\": 813\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.004093170166015625,\n",
            "  \"model.lr\": 0.00016258800000000002,\n",
            "  \"model.grad_norm\": 0.11544597893953323,\n",
            "  \"model.elapsed_time\": 0.06618309020996094,\n",
            "  \"model.engine_step\": 814,\n",
            "  \"model.loss.nll\": 0.004093170166015625,\n",
            "  \"elapsed_time\": 0.06618309020996094,\n",
            "  \"wall_time\": 1677241383.9340875,\n",
            "  \"global_step\": 814\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:03\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006780624389648438,\n",
            "  \"model.lr\": 0.00016278699999999998,\n",
            "  \"model.grad_norm\": 0.014545081183314323,\n",
            "  \"model.elapsed_time\": 0.06738853454589844,\n",
            "  \"model.engine_step\": 815,\n",
            "  \"model.loss.nll\": 0.0006780624389648438,\n",
            "  \"elapsed_time\": 0.06738853454589844,\n",
            "  \"wall_time\": 1677241384.009423,\n",
            "  \"global_step\": 815\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002811431884765625,\n",
            "  \"model.lr\": 0.000162986,\n",
            "  \"model.grad_norm\": 0.20880341529846191,\n",
            "  \"model.elapsed_time\": 0.06897401809692383,\n",
            "  \"model.engine_step\": 816,\n",
            "  \"model.loss.nll\": 0.002811431884765625,\n",
            "  \"elapsed_time\": 0.06897401809692383,\n",
            "  \"wall_time\": 1677241384.0805264,\n",
            "  \"global_step\": 816\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007572174072265625,\n",
            "  \"model.lr\": 0.000163185,\n",
            "  \"model.grad_norm\": 0.027958804741501808,\n",
            "  \"model.elapsed_time\": 0.0668344497680664,\n",
            "  \"model.engine_step\": 817,\n",
            "  \"model.loss.nll\": 0.0007572174072265625,\n",
            "  \"elapsed_time\": 0.0668344497680664,\n",
            "  \"wall_time\": 1677241384.1577482,\n",
            "  \"global_step\": 817\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006823539733886719,\n",
            "  \"model.lr\": 0.000163384,\n",
            "  \"model.grad_norm\": 0.017169736325740814,\n",
            "  \"model.elapsed_time\": 0.07243132591247559,\n",
            "  \"model.engine_step\": 818,\n",
            "  \"model.loss.nll\": 0.0006823539733886719,\n",
            "  \"elapsed_time\": 0.07243132591247559,\n",
            "  \"wall_time\": 1677241384.232881,\n",
            "  \"global_step\": 818\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000621795654296875,\n",
            "  \"model.lr\": 0.000163583,\n",
            "  \"model.grad_norm\": 0.012500024400651455,\n",
            "  \"model.elapsed_time\": 0.07026290893554688,\n",
            "  \"model.engine_step\": 819,\n",
            "  \"model.loss.nll\": 0.000621795654296875,\n",
            "  \"elapsed_time\": 0.07026290893554688,\n",
            "  \"wall_time\": 1677241384.310747,\n",
            "  \"global_step\": 819\n",
            "}\n",
            "[2023-02-24 12:23:04,380] [INFO] [logging.py:75:log_dist] [Rank 0] step=820, skipped=1, lr=[0.00016378199999999998], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:04,381] [INFO] [timer.py:198:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=12.679409810903456, CurrSamplesPerSec=14.466160123336287, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00067138671875,\n",
            "  \"model.lr\": 0.00016378199999999998,\n",
            "  \"model.grad_norm\": 0.012004256248474121,\n",
            "  \"model.elapsed_time\": 0.06959295272827148,\n",
            "  \"model.engine_step\": 820,\n",
            "  \"model.loss.nll\": 0.00067138671875,\n",
            "  \"elapsed_time\": 0.06959295272827148,\n",
            "  \"wall_time\": 1677241384.383139,\n",
            "  \"global_step\": 820\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0031490325927734375,\n",
            "  \"model.lr\": 0.000163981,\n",
            "  \"model.grad_norm\": 0.11253487318754196,\n",
            "  \"model.elapsed_time\": 0.06511664390563965,\n",
            "  \"model.engine_step\": 821,\n",
            "  \"model.loss.nll\": 0.0031490325927734375,\n",
            "  \"elapsed_time\": 0.06511664390563965,\n",
            "  \"wall_time\": 1677241384.4603095,\n",
            "  \"global_step\": 821\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006947517395019531,\n",
            "  \"model.lr\": 0.00016418,\n",
            "  \"model.grad_norm\": 0.018647421151399612,\n",
            "  \"model.elapsed_time\": 0.06550717353820801,\n",
            "  \"model.engine_step\": 822,\n",
            "  \"model.loss.nll\": 0.0006947517395019531,\n",
            "  \"elapsed_time\": 0.06550717353820801,\n",
            "  \"wall_time\": 1677241384.5284777,\n",
            "  \"global_step\": 822\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006432533264160156,\n",
            "  \"model.lr\": 0.000164379,\n",
            "  \"model.grad_norm\": 0.01159440167248249,\n",
            "  \"model.elapsed_time\": 0.07310605049133301,\n",
            "  \"model.engine_step\": 823,\n",
            "  \"model.loss.nll\": 0.0006432533264160156,\n",
            "  \"elapsed_time\": 0.07310605049133301,\n",
            "  \"wall_time\": 1677241384.6100414,\n",
            "  \"global_step\": 823\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006461143493652344,\n",
            "  \"model.lr\": 0.000164578,\n",
            "  \"model.grad_norm\": 0.016261115670204163,\n",
            "  \"model.elapsed_time\": 0.06585144996643066,\n",
            "  \"model.engine_step\": 824,\n",
            "  \"model.loss.nll\": 0.0006461143493652344,\n",
            "  \"elapsed_time\": 0.06585144996643066,\n",
            "  \"wall_time\": 1677241384.6781363,\n",
            "  \"global_step\": 824\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.003276824951171875,\n",
            "  \"model.lr\": 0.000164777,\n",
            "  \"model.grad_norm\": 0.07362695038318634,\n",
            "  \"model.elapsed_time\": 0.07341456413269043,\n",
            "  \"model.engine_step\": 825,\n",
            "  \"model.loss.nll\": 0.003276824951171875,\n",
            "  \"elapsed_time\": 0.07341456413269043,\n",
            "  \"wall_time\": 1677241384.7587771,\n",
            "  \"global_step\": 825\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007266998291015625,\n",
            "  \"model.lr\": 0.000164976,\n",
            "  \"model.grad_norm\": 0.017260495573282242,\n",
            "  \"model.elapsed_time\": 0.06442809104919434,\n",
            "  \"model.engine_step\": 826,\n",
            "  \"model.loss.nll\": 0.0007266998291015625,\n",
            "  \"elapsed_time\": 0.06442809104919434,\n",
            "  \"wall_time\": 1677241384.8257458,\n",
            "  \"global_step\": 826\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007238388061523438,\n",
            "  \"model.lr\": 0.000165175,\n",
            "  \"model.grad_norm\": 0.03692442551255226,\n",
            "  \"model.elapsed_time\": 0.07168245315551758,\n",
            "  \"model.engine_step\": 827,\n",
            "  \"model.loss.nll\": 0.0007238388061523438,\n",
            "  \"elapsed_time\": 0.07168245315551758,\n",
            "  \"wall_time\": 1677241384.9051137,\n",
            "  \"global_step\": 827\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000576019287109375,\n",
            "  \"model.lr\": 0.000165374,\n",
            "  \"model.grad_norm\": 0.008938632905483246,\n",
            "  \"model.elapsed_time\": 0.06953120231628418,\n",
            "  \"model.engine_step\": 828,\n",
            "  \"model.loss.nll\": 0.000576019287109375,\n",
            "  \"elapsed_time\": 0.06953120231628418,\n",
            "  \"wall_time\": 1677241384.9773211,\n",
            "  \"global_step\": 828\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:04\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006527900695800781,\n",
            "  \"model.lr\": 0.000165573,\n",
            "  \"model.grad_norm\": 0.012990757822990417,\n",
            "  \"model.elapsed_time\": 0.06925153732299805,\n",
            "  \"model.engine_step\": 829,\n",
            "  \"model.loss.nll\": 0.0006527900695800781,\n",
            "  \"elapsed_time\": 0.06925153732299805,\n",
            "  \"wall_time\": 1677241385.0552993,\n",
            "  \"global_step\": 829\n",
            "}\n",
            "[2023-02-24 12:23:05,128] [INFO] [logging.py:75:log_dist] [Rank 0] step=830, skipped=1, lr=[0.000165772], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:05,130] [INFO] [timer.py:198:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=12.698532274385808, CurrSamplesPerSec=13.656311760703018, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006256103515625,\n",
            "  \"model.lr\": 0.000165772,\n",
            "  \"model.grad_norm\": 0.015218490734696388,\n",
            "  \"model.elapsed_time\": 0.07365965843200684,\n",
            "  \"model.engine_step\": 830,\n",
            "  \"model.loss.nll\": 0.0006256103515625,\n",
            "  \"elapsed_time\": 0.07365965843200684,\n",
            "  \"wall_time\": 1677241385.1315136,\n",
            "  \"global_step\": 830\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0020732879638671875,\n",
            "  \"model.lr\": 0.000165971,\n",
            "  \"model.grad_norm\": 0.12217597663402557,\n",
            "  \"model.elapsed_time\": 0.0679011344909668,\n",
            "  \"model.engine_step\": 831,\n",
            "  \"model.loss.nll\": 0.0020732879638671875,\n",
            "  \"elapsed_time\": 0.0679011344909668,\n",
            "  \"wall_time\": 1677241385.206268,\n",
            "  \"global_step\": 831\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006594657897949219,\n",
            "  \"model.lr\": 0.00016617,\n",
            "  \"model.grad_norm\": 0.016653288155794144,\n",
            "  \"model.elapsed_time\": 0.06511473655700684,\n",
            "  \"model.engine_step\": 832,\n",
            "  \"model.loss.nll\": 0.0006594657897949219,\n",
            "  \"elapsed_time\": 0.06511473655700684,\n",
            "  \"wall_time\": 1677241385.2738175,\n",
            "  \"global_step\": 832\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0011205673217773438,\n",
            "  \"model.lr\": 0.000166369,\n",
            "  \"model.grad_norm\": 0.06885338574647903,\n",
            "  \"model.elapsed_time\": 0.07832980155944824,\n",
            "  \"model.engine_step\": 833,\n",
            "  \"model.loss.nll\": 0.0011205673217773438,\n",
            "  \"elapsed_time\": 0.07832980155944824,\n",
            "  \"wall_time\": 1677241385.3592305,\n",
            "  \"global_step\": 833\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006875991821289062,\n",
            "  \"model.lr\": 0.000166568,\n",
            "  \"model.grad_norm\": 0.009376296773552895,\n",
            "  \"model.elapsed_time\": 0.07290267944335938,\n",
            "  \"model.engine_step\": 834,\n",
            "  \"model.loss.nll\": 0.0006875991821289062,\n",
            "  \"elapsed_time\": 0.07290267944335938,\n",
            "  \"wall_time\": 1677241385.4347374,\n",
            "  \"global_step\": 834\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0032596588134765625,\n",
            "  \"model.lr\": 0.000166767,\n",
            "  \"model.grad_norm\": 0.07439667731523514,\n",
            "  \"model.elapsed_time\": 0.062146663665771484,\n",
            "  \"model.engine_step\": 835,\n",
            "  \"model.loss.nll\": 0.0032596588134765625,\n",
            "  \"elapsed_time\": 0.062146663665771484,\n",
            "  \"wall_time\": 1677241385.50479,\n",
            "  \"global_step\": 835\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006432533264160156,\n",
            "  \"model.lr\": 0.000166966,\n",
            "  \"model.grad_norm\": 0.01170463114976883,\n",
            "  \"model.elapsed_time\": 0.06405115127563477,\n",
            "  \"model.engine_step\": 836,\n",
            "  \"model.loss.nll\": 0.0006432533264160156,\n",
            "  \"elapsed_time\": 0.06405115127563477,\n",
            "  \"wall_time\": 1677241385.5707607,\n",
            "  \"global_step\": 836\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006480216979980469,\n",
            "  \"model.lr\": 0.000167165,\n",
            "  \"model.grad_norm\": 0.026794644072651863,\n",
            "  \"model.elapsed_time\": 0.06372523307800293,\n",
            "  \"model.engine_step\": 837,\n",
            "  \"model.loss.nll\": 0.0006480216979980469,\n",
            "  \"elapsed_time\": 0.06372523307800293,\n",
            "  \"wall_time\": 1677241385.6424825,\n",
            "  \"global_step\": 837\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0028533935546875,\n",
            "  \"model.lr\": 0.000167364,\n",
            "  \"model.grad_norm\": 0.06963199377059937,\n",
            "  \"model.elapsed_time\": 0.06766176223754883,\n",
            "  \"model.engine_step\": 838,\n",
            "  \"model.loss.nll\": 0.0028533935546875,\n",
            "  \"elapsed_time\": 0.06766176223754883,\n",
            "  \"wall_time\": 1677241385.7122233,\n",
            "  \"global_step\": 838\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005431175231933594,\n",
            "  \"model.lr\": 0.000167563,\n",
            "  \"model.grad_norm\": 0.008137243799865246,\n",
            "  \"model.elapsed_time\": 0.07321882247924805,\n",
            "  \"model.engine_step\": 839,\n",
            "  \"model.loss.nll\": 0.0005431175231933594,\n",
            "  \"elapsed_time\": 0.07321882247924805,\n",
            "  \"wall_time\": 1677241385.7932034,\n",
            "  \"global_step\": 839\n",
            "}\n",
            "[2023-02-24 12:23:05,857] [INFO] [logging.py:75:log_dist] [Rank 0] step=840, skipped=1, lr=[0.000167762], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:05,858] [INFO] [timer.py:198:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=12.719613741549729, CurrSamplesPerSec=15.677414049592954, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0031452178955078125,\n",
            "  \"model.lr\": 0.000167762,\n",
            "  \"model.grad_norm\": 0.09175686538219452,\n",
            "  \"model.elapsed_time\": 0.06424975395202637,\n",
            "  \"model.engine_step\": 840,\n",
            "  \"model.loss.nll\": 0.0031452178955078125,\n",
            "  \"elapsed_time\": 0.06424975395202637,\n",
            "  \"wall_time\": 1677241385.8595703,\n",
            "  \"global_step\": 840\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:05\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005955696105957031,\n",
            "  \"model.lr\": 0.000167961,\n",
            "  \"model.grad_norm\": 0.008739844895899296,\n",
            "  \"model.elapsed_time\": 0.06950664520263672,\n",
            "  \"model.engine_step\": 841,\n",
            "  \"model.loss.nll\": 0.0005955696105957031,\n",
            "  \"elapsed_time\": 0.06950664520263672,\n",
            "  \"wall_time\": 1677241385.936563,\n",
            "  \"global_step\": 841\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007596015930175781,\n",
            "  \"model.lr\": 0.00016816,\n",
            "  \"model.grad_norm\": 0.04554063826799393,\n",
            "  \"model.elapsed_time\": 0.06656670570373535,\n",
            "  \"model.engine_step\": 842,\n",
            "  \"model.loss.nll\": 0.0007596015930175781,\n",
            "  \"elapsed_time\": 0.06656670570373535,\n",
            "  \"wall_time\": 1677241386.0056865,\n",
            "  \"global_step\": 842\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005755424499511719,\n",
            "  \"model.lr\": 0.000168359,\n",
            "  \"model.grad_norm\": 0.010665897279977798,\n",
            "  \"model.elapsed_time\": 0.07115435600280762,\n",
            "  \"model.engine_step\": 843,\n",
            "  \"model.loss.nll\": 0.0005755424499511719,\n",
            "  \"elapsed_time\": 0.07115435600280762,\n",
            "  \"wall_time\": 1677241386.0840924,\n",
            "  \"global_step\": 843\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004968643188476562,\n",
            "  \"model.lr\": 0.000168558,\n",
            "  \"model.grad_norm\": 0.007113857194781303,\n",
            "  \"model.elapsed_time\": 0.06853342056274414,\n",
            "  \"model.engine_step\": 844,\n",
            "  \"model.loss.nll\": 0.0004968643188476562,\n",
            "  \"elapsed_time\": 0.06853342056274414,\n",
            "  \"wall_time\": 1677241386.1556697,\n",
            "  \"global_step\": 844\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005588531494140625,\n",
            "  \"model.lr\": 0.000168757,\n",
            "  \"model.grad_norm\": 0.01044307928532362,\n",
            "  \"model.elapsed_time\": 0.07224011421203613,\n",
            "  \"model.engine_step\": 845,\n",
            "  \"model.loss.nll\": 0.0005588531494140625,\n",
            "  \"elapsed_time\": 0.07224011421203613,\n",
            "  \"wall_time\": 1677241386.2355354,\n",
            "  \"global_step\": 845\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010766983032226562,\n",
            "  \"model.lr\": 0.000168956,\n",
            "  \"model.grad_norm\": 0.02281033992767334,\n",
            "  \"model.elapsed_time\": 0.06811976432800293,\n",
            "  \"model.engine_step\": 846,\n",
            "  \"model.loss.nll\": 0.0010766983032226562,\n",
            "  \"elapsed_time\": 0.06811976432800293,\n",
            "  \"wall_time\": 1677241386.3060806,\n",
            "  \"global_step\": 846\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00048542022705078125,\n",
            "  \"model.lr\": 0.000169155,\n",
            "  \"model.grad_norm\": 0.00684009213000536,\n",
            "  \"model.elapsed_time\": 0.0697789192199707,\n",
            "  \"model.engine_step\": 847,\n",
            "  \"model.loss.nll\": 0.00048542022705078125,\n",
            "  \"elapsed_time\": 0.0697789192199707,\n",
            "  \"wall_time\": 1677241386.3839757,\n",
            "  \"global_step\": 847\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006384849548339844,\n",
            "  \"model.lr\": 0.000169354,\n",
            "  \"model.grad_norm\": 0.016287053003907204,\n",
            "  \"model.elapsed_time\": 0.06495833396911621,\n",
            "  \"model.engine_step\": 848,\n",
            "  \"model.loss.nll\": 0.0006384849548339844,\n",
            "  \"elapsed_time\": 0.06495833396911621,\n",
            "  \"wall_time\": 1677241386.4513626,\n",
            "  \"global_step\": 848\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0025806427001953125,\n",
            "  \"model.lr\": 0.000169553,\n",
            "  \"model.grad_norm\": 0.0912432074546814,\n",
            "  \"model.elapsed_time\": 0.06890535354614258,\n",
            "  \"model.engine_step\": 849,\n",
            "  \"model.loss.nll\": 0.0025806427001953125,\n",
            "  \"elapsed_time\": 0.06890535354614258,\n",
            "  \"wall_time\": 1677241386.528096,\n",
            "  \"global_step\": 849\n",
            "}\n",
            "[2023-02-24 12:23:06,591] [INFO] [logging.py:75:log_dist] [Rank 0] step=850, skipped=1, lr=[0.000169752], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:06,593] [INFO] [timer.py:198:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=12.73940881692488, CurrSamplesPerSec=15.736468893274404, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006532669067382812,\n",
            "  \"model.lr\": 0.000169752,\n",
            "  \"model.grad_norm\": 0.04423772543668747,\n",
            "  \"model.elapsed_time\": 0.06397724151611328,\n",
            "  \"model.engine_step\": 850,\n",
            "  \"model.loss.nll\": 0.0006532669067382812,\n",
            "  \"elapsed_time\": 0.06397724151611328,\n",
            "  \"wall_time\": 1677241386.594101,\n",
            "  \"global_step\": 850\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000720977783203125,\n",
            "  \"model.lr\": 0.000169951,\n",
            "  \"model.grad_norm\": 0.026666931807994843,\n",
            "  \"model.elapsed_time\": 0.06293392181396484,\n",
            "  \"model.engine_step\": 851,\n",
            "  \"model.loss.nll\": 0.000720977783203125,\n",
            "  \"elapsed_time\": 0.06293392181396484,\n",
            "  \"wall_time\": 1677241386.6648676,\n",
            "  \"global_step\": 851\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005154609680175781,\n",
            "  \"model.lr\": 0.00017015000000000002,\n",
            "  \"model.grad_norm\": 0.010517193004488945,\n",
            "  \"model.elapsed_time\": 0.06444573402404785,\n",
            "  \"model.engine_step\": 852,\n",
            "  \"model.loss.nll\": 0.0005154609680175781,\n",
            "  \"elapsed_time\": 0.06444573402404785,\n",
            "  \"wall_time\": 1677241386.7312107,\n",
            "  \"global_step\": 852\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0012874603271484375,\n",
            "  \"model.lr\": 0.000170349,\n",
            "  \"model.grad_norm\": 0.03108789213001728,\n",
            "  \"model.elapsed_time\": 0.07496857643127441,\n",
            "  \"model.engine_step\": 853,\n",
            "  \"model.loss.nll\": 0.0012874603271484375,\n",
            "  \"elapsed_time\": 0.07496857643127441,\n",
            "  \"wall_time\": 1677241386.813655,\n",
            "  \"global_step\": 853\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006771087646484375,\n",
            "  \"model.lr\": 0.000170548,\n",
            "  \"model.grad_norm\": 0.017877794802188873,\n",
            "  \"model.elapsed_time\": 0.06965994834899902,\n",
            "  \"model.engine_step\": 854,\n",
            "  \"model.loss.nll\": 0.0006771087646484375,\n",
            "  \"elapsed_time\": 0.06965994834899902,\n",
            "  \"wall_time\": 1677241386.8858404,\n",
            "  \"global_step\": 854\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:06\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006394386291503906,\n",
            "  \"model.lr\": 0.000170747,\n",
            "  \"model.grad_norm\": 0.017174143344163895,\n",
            "  \"model.elapsed_time\": 0.06377196311950684,\n",
            "  \"model.engine_step\": 855,\n",
            "  \"model.loss.nll\": 0.0006394386291503906,\n",
            "  \"elapsed_time\": 0.06377196311950684,\n",
            "  \"wall_time\": 1677241386.957735,\n",
            "  \"global_step\": 855\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0014181137084960938,\n",
            "  \"model.lr\": 0.000170946,\n",
            "  \"model.grad_norm\": 0.05563819408416748,\n",
            "  \"model.elapsed_time\": 0.0679471492767334,\n",
            "  \"model.engine_step\": 856,\n",
            "  \"model.loss.nll\": 0.0014181137084960938,\n",
            "  \"elapsed_time\": 0.0679471492767334,\n",
            "  \"wall_time\": 1677241387.0278852,\n",
            "  \"global_step\": 856\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004916191101074219,\n",
            "  \"model.lr\": 0.00017114500000000002,\n",
            "  \"model.grad_norm\": 0.008721807040274143,\n",
            "  \"model.elapsed_time\": 0.06705784797668457,\n",
            "  \"model.engine_step\": 857,\n",
            "  \"model.loss.nll\": 0.0004916191101074219,\n",
            "  \"elapsed_time\": 0.06705784797668457,\n",
            "  \"wall_time\": 1677241387.1028125,\n",
            "  \"global_step\": 857\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001331329345703125,\n",
            "  \"model.lr\": 0.000171344,\n",
            "  \"model.grad_norm\": 0.026299837976694107,\n",
            "  \"model.elapsed_time\": 0.06550979614257812,\n",
            "  \"model.engine_step\": 858,\n",
            "  \"model.loss.nll\": 0.001331329345703125,\n",
            "  \"elapsed_time\": 0.06550979614257812,\n",
            "  \"wall_time\": 1677241387.1704943,\n",
            "  \"global_step\": 858\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005350112915039062,\n",
            "  \"model.lr\": 0.000171543,\n",
            "  \"model.grad_norm\": 0.009775849059224129,\n",
            "  \"model.elapsed_time\": 0.06776881217956543,\n",
            "  \"model.engine_step\": 859,\n",
            "  \"model.loss.nll\": 0.0005350112915039062,\n",
            "  \"elapsed_time\": 0.06776881217956543,\n",
            "  \"wall_time\": 1677241387.2467833,\n",
            "  \"global_step\": 859\n",
            "}\n",
            "[2023-02-24 12:23:07,324] [INFO] [logging.py:75:log_dist] [Rank 0] step=860, skipped=1, lr=[0.000171742], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:07,325] [INFO] [timer.py:198:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=12.7591100002429, CurrSamplesPerSec=12.882639490383257, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004935264587402344,\n",
            "  \"model.lr\": 0.000171742,\n",
            "  \"model.grad_norm\": 0.00615965761244297,\n",
            "  \"model.elapsed_time\": 0.07805728912353516,\n",
            "  \"model.engine_step\": 860,\n",
            "  \"model.loss.nll\": 0.0004935264587402344,\n",
            "  \"elapsed_time\": 0.07805728912353516,\n",
            "  \"wall_time\": 1677241387.32689,\n",
            "  \"global_step\": 860\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010519027709960938,\n",
            "  \"model.lr\": 0.000171941,\n",
            "  \"model.grad_norm\": 0.017543649300932884,\n",
            "  \"model.elapsed_time\": 0.0652003288269043,\n",
            "  \"model.engine_step\": 861,\n",
            "  \"model.loss.nll\": 0.0010519027709960938,\n",
            "  \"elapsed_time\": 0.0652003288269043,\n",
            "  \"wall_time\": 1677241387.3988478,\n",
            "  \"global_step\": 861\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004832744598388672,\n",
            "  \"model.lr\": 0.00017214000000000002,\n",
            "  \"model.grad_norm\": 0.009095295332372189,\n",
            "  \"model.elapsed_time\": 0.0661933422088623,\n",
            "  \"model.engine_step\": 862,\n",
            "  \"model.loss.nll\": 0.0004832744598388672,\n",
            "  \"elapsed_time\": 0.0661933422088623,\n",
            "  \"wall_time\": 1677241387.4678087,\n",
            "  \"global_step\": 862\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005393028259277344,\n",
            "  \"model.lr\": 0.000172339,\n",
            "  \"model.grad_norm\": 0.011579672805964947,\n",
            "  \"model.elapsed_time\": 0.0656740665435791,\n",
            "  \"model.engine_step\": 863,\n",
            "  \"model.loss.nll\": 0.0005393028259277344,\n",
            "  \"elapsed_time\": 0.0656740665435791,\n",
            "  \"wall_time\": 1677241387.5422354,\n",
            "  \"global_step\": 863\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005884170532226562,\n",
            "  \"model.lr\": 0.000172538,\n",
            "  \"model.grad_norm\": 0.008091242052614689,\n",
            "  \"model.elapsed_time\": 0.0650944709777832,\n",
            "  \"model.engine_step\": 864,\n",
            "  \"model.loss.nll\": 0.0005884170532226562,\n",
            "  \"elapsed_time\": 0.0650944709777832,\n",
            "  \"wall_time\": 1677241387.6095533,\n",
            "  \"global_step\": 864\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0013685226440429688,\n",
            "  \"model.lr\": 0.000172737,\n",
            "  \"model.grad_norm\": 0.023266734555363655,\n",
            "  \"model.elapsed_time\": 0.06859493255615234,\n",
            "  \"model.engine_step\": 865,\n",
            "  \"model.loss.nll\": 0.0013685226440429688,\n",
            "  \"elapsed_time\": 0.06859493255615234,\n",
            "  \"wall_time\": 1677241387.6896863,\n",
            "  \"global_step\": 865\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00470733642578125,\n",
            "  \"model.lr\": 0.000172936,\n",
            "  \"model.grad_norm\": 0.5036064982414246,\n",
            "  \"model.elapsed_time\": 0.06686115264892578,\n",
            "  \"model.engine_step\": 866,\n",
            "  \"model.loss.nll\": 0.00470733642578125,\n",
            "  \"elapsed_time\": 0.06686115264892578,\n",
            "  \"wall_time\": 1677241387.7588625,\n",
            "  \"global_step\": 866\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004341602325439453,\n",
            "  \"model.lr\": 0.00017313500000000002,\n",
            "  \"model.grad_norm\": 0.005151235032826662,\n",
            "  \"model.elapsed_time\": 0.07944321632385254,\n",
            "  \"model.engine_step\": 867,\n",
            "  \"model.loss.nll\": 0.0004341602325439453,\n",
            "  \"elapsed_time\": 0.07944321632385254,\n",
            "  \"wall_time\": 1677241387.846372,\n",
            "  \"global_step\": 867\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005526542663574219,\n",
            "  \"model.lr\": 0.000173334,\n",
            "  \"model.grad_norm\": 0.01190594956278801,\n",
            "  \"model.elapsed_time\": 0.06667470932006836,\n",
            "  \"model.engine_step\": 868,\n",
            "  \"model.loss.nll\": 0.0005526542663574219,\n",
            "  \"elapsed_time\": 0.06667470932006836,\n",
            "  \"wall_time\": 1677241387.9165723,\n",
            "  \"global_step\": 868\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:07\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010442733764648438,\n",
            "  \"model.lr\": 0.000173533,\n",
            "  \"model.grad_norm\": 0.019331149756908417,\n",
            "  \"model.elapsed_time\": 0.06482672691345215,\n",
            "  \"model.engine_step\": 869,\n",
            "  \"model.loss.nll\": 0.0010442733764648438,\n",
            "  \"elapsed_time\": 0.06482672691345215,\n",
            "  \"wall_time\": 1677241387.990831,\n",
            "  \"global_step\": 869\n",
            "}\n",
            "[2023-02-24 12:23:08,055] [INFO] [logging.py:75:log_dist] [Rank 0] step=870, skipped=1, lr=[0.000173732], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:08,057] [INFO] [timer.py:198:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=12.780022946539562, CurrSamplesPerSec=15.464354186945108, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006256103515625,\n",
            "  \"model.lr\": 0.000173732,\n",
            "  \"model.grad_norm\": 0.03709523752331734,\n",
            "  \"model.elapsed_time\": 0.06531548500061035,\n",
            "  \"model.engine_step\": 870,\n",
            "  \"model.loss.nll\": 0.0006256103515625,\n",
            "  \"elapsed_time\": 0.06531548500061035,\n",
            "  \"wall_time\": 1677241388.0592713,\n",
            "  \"global_step\": 870\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00154876708984375,\n",
            "  \"model.lr\": 0.000173931,\n",
            "  \"model.grad_norm\": 0.06869980692863464,\n",
            "  \"model.elapsed_time\": 0.07090473175048828,\n",
            "  \"model.engine_step\": 871,\n",
            "  \"model.loss.nll\": 0.00154876708984375,\n",
            "  \"elapsed_time\": 0.07090473175048828,\n",
            "  \"wall_time\": 1677241388.1382484,\n",
            "  \"global_step\": 871\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005965232849121094,\n",
            "  \"model.lr\": 0.00017413000000000002,\n",
            "  \"model.grad_norm\": 0.032016314566135406,\n",
            "  \"model.elapsed_time\": 0.06581902503967285,\n",
            "  \"model.engine_step\": 872,\n",
            "  \"model.loss.nll\": 0.0005965232849121094,\n",
            "  \"elapsed_time\": 0.06581902503967285,\n",
            "  \"wall_time\": 1677241388.2061732,\n",
            "  \"global_step\": 872\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005598068237304688,\n",
            "  \"model.lr\": 0.000174329,\n",
            "  \"model.grad_norm\": 0.014875741675496101,\n",
            "  \"model.elapsed_time\": 0.06718754768371582,\n",
            "  \"model.engine_step\": 873,\n",
            "  \"model.loss.nll\": 0.0005598068237304688,\n",
            "  \"elapsed_time\": 0.06718754768371582,\n",
            "  \"wall_time\": 1677241388.2817972,\n",
            "  \"global_step\": 873\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006022453308105469,\n",
            "  \"model.lr\": 0.00017452800000000002,\n",
            "  \"model.grad_norm\": 0.023323794826865196,\n",
            "  \"model.elapsed_time\": 0.0693206787109375,\n",
            "  \"model.engine_step\": 874,\n",
            "  \"model.loss.nll\": 0.0006022453308105469,\n",
            "  \"elapsed_time\": 0.0693206787109375,\n",
            "  \"wall_time\": 1677241388.3530722,\n",
            "  \"global_step\": 874\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00824737548828125,\n",
            "  \"model.lr\": 0.000174727,\n",
            "  \"model.grad_norm\": 1.0187573432922363,\n",
            "  \"model.elapsed_time\": 0.06968832015991211,\n",
            "  \"model.engine_step\": 875,\n",
            "  \"model.loss.nll\": 0.00824737548828125,\n",
            "  \"elapsed_time\": 0.06968832015991211,\n",
            "  \"wall_time\": 1677241388.4298227,\n",
            "  \"global_step\": 875\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00042438507080078125,\n",
            "  \"model.lr\": 0.000174926,\n",
            "  \"model.grad_norm\": 0.00542010273784399,\n",
            "  \"model.elapsed_time\": 0.07070255279541016,\n",
            "  \"model.engine_step\": 876,\n",
            "  \"model.loss.nll\": 0.00042438507080078125,\n",
            "  \"elapsed_time\": 0.07070255279541016,\n",
            "  \"wall_time\": 1677241388.5036561,\n",
            "  \"global_step\": 876\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005154609680175781,\n",
            "  \"model.lr\": 0.00017512500000000001,\n",
            "  \"model.grad_norm\": 0.009186219424009323,\n",
            "  \"model.elapsed_time\": 0.07553672790527344,\n",
            "  \"model.engine_step\": 877,\n",
            "  \"model.loss.nll\": 0.0005154609680175781,\n",
            "  \"elapsed_time\": 0.07553672790527344,\n",
            "  \"wall_time\": 1677241388.5872767,\n",
            "  \"global_step\": 877\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00323486328125,\n",
            "  \"model.lr\": 0.000175324,\n",
            "  \"model.grad_norm\": 0.12119777500629425,\n",
            "  \"model.elapsed_time\": 0.06919050216674805,\n",
            "  \"model.engine_step\": 878,\n",
            "  \"model.loss.nll\": 0.00323486328125,\n",
            "  \"elapsed_time\": 0.06919050216674805,\n",
            "  \"wall_time\": 1677241388.6593966,\n",
            "  \"global_step\": 878\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.006256103515625,\n",
            "  \"model.lr\": 0.00017552300000000002,\n",
            "  \"model.grad_norm\": 0.6333268880844116,\n",
            "  \"model.elapsed_time\": 0.06803703308105469,\n",
            "  \"model.engine_step\": 879,\n",
            "  \"model.loss.nll\": 0.006256103515625,\n",
            "  \"elapsed_time\": 0.06803703308105469,\n",
            "  \"wall_time\": 1677241388.7353566,\n",
            "  \"global_step\": 879\n",
            "}\n",
            "[2023-02-24 12:23:08,801] [INFO] [logging.py:75:log_dist] [Rank 0] step=880, skipped=1, lr=[0.000175722], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:08,802] [INFO] [timer.py:198:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=12.7970263352149, CurrSamplesPerSec=15.256230812879195, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008225440979003906,\n",
            "  \"model.lr\": 0.000175722,\n",
            "  \"model.grad_norm\": 0.08591842651367188,\n",
            "  \"model.elapsed_time\": 0.06598114967346191,\n",
            "  \"model.engine_step\": 880,\n",
            "  \"model.loss.nll\": 0.0008225440979003906,\n",
            "  \"elapsed_time\": 0.06598114967346191,\n",
            "  \"wall_time\": 1677241388.804067,\n",
            "  \"global_step\": 880\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005636215209960938,\n",
            "  \"model.lr\": 0.000175921,\n",
            "  \"model.grad_norm\": 0.020058462396264076,\n",
            "  \"model.elapsed_time\": 0.07537031173706055,\n",
            "  \"model.engine_step\": 881,\n",
            "  \"model.loss.nll\": 0.0005636215209960938,\n",
            "  \"elapsed_time\": 0.07537031173706055,\n",
            "  \"wall_time\": 1677241388.887538,\n",
            "  \"global_step\": 881\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008497238159179688,\n",
            "  \"model.lr\": 0.00017612000000000001,\n",
            "  \"model.grad_norm\": 0.10953028500080109,\n",
            "  \"model.elapsed_time\": 0.06758379936218262,\n",
            "  \"model.engine_step\": 882,\n",
            "  \"model.loss.nll\": 0.0008497238159179688,\n",
            "  \"elapsed_time\": 0.06758379936218262,\n",
            "  \"wall_time\": 1677241388.957417,\n",
            "  \"global_step\": 882\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:08\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005049705505371094,\n",
            "  \"model.lr\": 0.000176319,\n",
            "  \"model.grad_norm\": 0.006269526667892933,\n",
            "  \"model.elapsed_time\": 0.06700301170349121,\n",
            "  \"model.engine_step\": 883,\n",
            "  \"model.loss.nll\": 0.0005049705505371094,\n",
            "  \"elapsed_time\": 0.06700301170349121,\n",
            "  \"wall_time\": 1677241389.0322845,\n",
            "  \"global_step\": 883\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00046634674072265625,\n",
            "  \"model.lr\": 0.00017651800000000002,\n",
            "  \"model.grad_norm\": 0.012086896225810051,\n",
            "  \"model.elapsed_time\": 0.0693063735961914,\n",
            "  \"model.engine_step\": 884,\n",
            "  \"model.loss.nll\": 0.00046634674072265625,\n",
            "  \"elapsed_time\": 0.0693063735961914,\n",
            "  \"wall_time\": 1677241389.1049325,\n",
            "  \"global_step\": 884\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009965896606445312,\n",
            "  \"model.lr\": 0.000176717,\n",
            "  \"model.grad_norm\": 0.02618660219013691,\n",
            "  \"model.elapsed_time\": 0.06816792488098145,\n",
            "  \"model.engine_step\": 885,\n",
            "  \"model.loss.nll\": 0.0009965896606445312,\n",
            "  \"elapsed_time\": 0.06816792488098145,\n",
            "  \"wall_time\": 1677241389.1808841,\n",
            "  \"global_step\": 885\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005125999450683594,\n",
            "  \"model.lr\": 0.000176916,\n",
            "  \"model.grad_norm\": 0.014030016027390957,\n",
            "  \"model.elapsed_time\": 0.09728288650512695,\n",
            "  \"model.engine_step\": 886,\n",
            "  \"model.loss.nll\": 0.0005125999450683594,\n",
            "  \"elapsed_time\": 0.09728288650512695,\n",
            "  \"wall_time\": 1677241389.2813277,\n",
            "  \"global_step\": 886\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006089210510253906,\n",
            "  \"model.lr\": 0.00017711500000000001,\n",
            "  \"model.grad_norm\": 0.0256185382604599,\n",
            "  \"model.elapsed_time\": 0.10472607612609863,\n",
            "  \"model.engine_step\": 887,\n",
            "  \"model.loss.nll\": 0.0006089210510253906,\n",
            "  \"elapsed_time\": 0.10472607612609863,\n",
            "  \"wall_time\": 1677241389.3996012,\n",
            "  \"global_step\": 887\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002422332763671875,\n",
            "  \"model.lr\": 0.000177314,\n",
            "  \"model.grad_norm\": 0.070868581533432,\n",
            "  \"model.elapsed_time\": 0.09200787544250488,\n",
            "  \"model.engine_step\": 888,\n",
            "  \"model.loss.nll\": 0.002422332763671875,\n",
            "  \"elapsed_time\": 0.09200787544250488,\n",
            "  \"wall_time\": 1677241389.4950798,\n",
            "  \"global_step\": 888\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004482269287109375,\n",
            "  \"model.lr\": 0.00017751300000000002,\n",
            "  \"model.grad_norm\": 0.006509479135274887,\n",
            "  \"model.elapsed_time\": 0.09015130996704102,\n",
            "  \"model.engine_step\": 889,\n",
            "  \"model.loss.nll\": 0.0004482269287109375,\n",
            "  \"elapsed_time\": 0.09015130996704102,\n",
            "  \"wall_time\": 1677241389.5966318,\n",
            "  \"global_step\": 889\n",
            "}\n",
            "[2023-02-24 12:23:09,690] [INFO] [logging.py:75:log_dist] [Rank 0] step=890, skipped=1, lr=[0.000177712], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:09,691] [INFO] [timer.py:198:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=12.789233751811784, CurrSamplesPerSec=10.75868083611002, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0037441253662109375,\n",
            "  \"model.lr\": 0.000177712,\n",
            "  \"model.grad_norm\": 0.19644145667552948,\n",
            "  \"model.elapsed_time\": 0.09358978271484375,\n",
            "  \"model.engine_step\": 890,\n",
            "  \"model.loss.nll\": 0.0037441253662109375,\n",
            "  \"elapsed_time\": 0.09358978271484375,\n",
            "  \"wall_time\": 1677241389.693175,\n",
            "  \"global_step\": 890\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005640983581542969,\n",
            "  \"model.lr\": 0.000177911,\n",
            "  \"model.grad_norm\": 0.017123838886618614,\n",
            "  \"model.elapsed_time\": 0.08906960487365723,\n",
            "  \"model.engine_step\": 891,\n",
            "  \"model.loss.nll\": 0.0005640983581542969,\n",
            "  \"elapsed_time\": 0.08906960487365723,\n",
            "  \"wall_time\": 1677241389.793837,\n",
            "  \"global_step\": 891\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004851818084716797,\n",
            "  \"model.lr\": 0.00017811000000000001,\n",
            "  \"model.grad_norm\": 0.010676933452486992,\n",
            "  \"model.elapsed_time\": 0.1125783920288086,\n",
            "  \"model.engine_step\": 892,\n",
            "  \"model.loss.nll\": 0.0004851818084716797,\n",
            "  \"elapsed_time\": 0.1125783920288086,\n",
            "  \"wall_time\": 1677241389.9097004,\n",
            "  \"global_step\": 892\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:09\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00047969818115234375,\n",
            "  \"model.lr\": 0.000178309,\n",
            "  \"model.grad_norm\": 0.00887429341673851,\n",
            "  \"model.elapsed_time\": 0.10020828247070312,\n",
            "  \"model.engine_step\": 893,\n",
            "  \"model.loss.nll\": 0.00047969818115234375,\n",
            "  \"elapsed_time\": 0.10020828247070312,\n",
            "  \"wall_time\": 1677241390.0217214,\n",
            "  \"global_step\": 893\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004508495330810547,\n",
            "  \"model.lr\": 0.00017850800000000002,\n",
            "  \"model.grad_norm\": 0.009283619001507759,\n",
            "  \"model.elapsed_time\": 0.09175252914428711,\n",
            "  \"model.engine_step\": 894,\n",
            "  \"model.loss.nll\": 0.0004508495330810547,\n",
            "  \"elapsed_time\": 0.09175252914428711,\n",
            "  \"wall_time\": 1677241390.1161911,\n",
            "  \"global_step\": 894\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004992485046386719,\n",
            "  \"model.lr\": 0.000178707,\n",
            "  \"model.grad_norm\": 0.006549092475324869,\n",
            "  \"model.elapsed_time\": 0.0921940803527832,\n",
            "  \"model.engine_step\": 895,\n",
            "  \"model.loss.nll\": 0.0004992485046386719,\n",
            "  \"elapsed_time\": 0.0921940803527832,\n",
            "  \"wall_time\": 1677241390.219067,\n",
            "  \"global_step\": 895\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006036758422851562,\n",
            "  \"model.lr\": 0.00017890600000000002,\n",
            "  \"model.grad_norm\": 0.026524683460593224,\n",
            "  \"model.elapsed_time\": 0.09865331649780273,\n",
            "  \"model.engine_step\": 896,\n",
            "  \"model.loss.nll\": 0.0006036758422851562,\n",
            "  \"elapsed_time\": 0.09865331649780273,\n",
            "  \"wall_time\": 1677241390.3211212,\n",
            "  \"global_step\": 896\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009946823120117188,\n",
            "  \"model.lr\": 0.00017910500000000001,\n",
            "  \"model.grad_norm\": 0.09526284784078598,\n",
            "  \"model.elapsed_time\": 0.09389901161193848,\n",
            "  \"model.engine_step\": 897,\n",
            "  \"model.loss.nll\": 0.0009946823120117188,\n",
            "  \"elapsed_time\": 0.09389901161193848,\n",
            "  \"wall_time\": 1677241390.4271467,\n",
            "  \"global_step\": 897\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000400543212890625,\n",
            "  \"model.lr\": 0.000179304,\n",
            "  \"model.grad_norm\": 0.005344192963093519,\n",
            "  \"model.elapsed_time\": 0.09405946731567383,\n",
            "  \"model.engine_step\": 898,\n",
            "  \"model.loss.nll\": 0.000400543212890625,\n",
            "  \"elapsed_time\": 0.09405946731567383,\n",
            "  \"wall_time\": 1677241390.524151,\n",
            "  \"global_step\": 898\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0018243789672851562,\n",
            "  \"model.lr\": 0.00017950300000000002,\n",
            "  \"model.grad_norm\": 0.03808340057730675,\n",
            "  \"model.elapsed_time\": 0.09219050407409668,\n",
            "  \"model.engine_step\": 899,\n",
            "  \"model.loss.nll\": 0.0018243789672851562,\n",
            "  \"elapsed_time\": 0.09219050407409668,\n",
            "  \"wall_time\": 1677241390.6282196,\n",
            "  \"global_step\": 899\n",
            "}\n",
            "[2023-02-24 12:23:10,723] [INFO] [logging.py:75:log_dist] [Rank 0] step=900, skipped=1, lr=[0.000179702], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:10,723] [INFO] [timer.py:198:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=12.757366169496482, CurrSamplesPerSec=10.679213960901736, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0006418228149414062,\n",
            "  \"model.lr\": 0.000179702,\n",
            "  \"model.grad_norm\": 0.023055296391248703,\n",
            "  \"model.elapsed_time\": 0.09428882598876953,\n",
            "  \"model.engine_step\": 900,\n",
            "  \"model.loss.nll\": 0.0006418228149414062,\n",
            "  \"elapsed_time\": 0.09428882598876953,\n",
            "  \"wall_time\": 1677241390.7254736,\n",
            "  \"global_step\": 900\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007319450378417969,\n",
            "  \"model.lr\": 0.00017990100000000002,\n",
            "  \"model.grad_norm\": 0.043821875005960464,\n",
            "  \"model.elapsed_time\": 0.10012197494506836,\n",
            "  \"model.engine_step\": 901,\n",
            "  \"model.loss.nll\": 0.0007319450378417969,\n",
            "  \"elapsed_time\": 0.10012197494506836,\n",
            "  \"wall_time\": 1677241390.8382435,\n",
            "  \"global_step\": 901\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0022068023681640625,\n",
            "  \"model.lr\": 0.00018010000000000001,\n",
            "  \"model.grad_norm\": 0.05935932323336601,\n",
            "  \"model.elapsed_time\": 0.11707711219787598,\n",
            "  \"model.engine_step\": 902,\n",
            "  \"model.loss.nll\": 0.0022068023681640625,\n",
            "  \"elapsed_time\": 0.11707711219787598,\n",
            "  \"wall_time\": 1677241390.9625258,\n",
            "  \"global_step\": 902\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:10\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0030918121337890625,\n",
            "  \"model.lr\": 0.000180299,\n",
            "  \"model.grad_norm\": 0.08946390450000763,\n",
            "  \"model.elapsed_time\": 0.09105634689331055,\n",
            "  \"model.engine_step\": 903,\n",
            "  \"model.loss.nll\": 0.0030918121337890625,\n",
            "  \"elapsed_time\": 0.09105634689331055,\n",
            "  \"wall_time\": 1677241391.0650587,\n",
            "  \"global_step\": 903\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00047850608825683594,\n",
            "  \"model.lr\": 0.00018049800000000002,\n",
            "  \"model.grad_norm\": 0.012428713031113148,\n",
            "  \"model.elapsed_time\": 0.09957742691040039,\n",
            "  \"model.engine_step\": 904,\n",
            "  \"model.loss.nll\": 0.00047850608825683594,\n",
            "  \"elapsed_time\": 0.09957742691040039,\n",
            "  \"wall_time\": 1677241391.1681988,\n",
            "  \"global_step\": 904\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010089874267578125,\n",
            "  \"model.lr\": 0.000180697,\n",
            "  \"model.grad_norm\": 0.020926393568515778,\n",
            "  \"model.elapsed_time\": 0.09400200843811035,\n",
            "  \"model.engine_step\": 905,\n",
            "  \"model.loss.nll\": 0.0010089874267578125,\n",
            "  \"elapsed_time\": 0.09400200843811035,\n",
            "  \"wall_time\": 1677241391.273239,\n",
            "  \"global_step\": 905\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004744529724121094,\n",
            "  \"model.lr\": 0.00018089600000000002,\n",
            "  \"model.grad_norm\": 0.0068426234647631645,\n",
            "  \"model.elapsed_time\": 0.09999918937683105,\n",
            "  \"model.engine_step\": 906,\n",
            "  \"model.loss.nll\": 0.0004744529724121094,\n",
            "  \"elapsed_time\": 0.09999918937683105,\n",
            "  \"wall_time\": 1677241391.376702,\n",
            "  \"global_step\": 906\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009307861328125,\n",
            "  \"model.lr\": 0.00018109500000000001,\n",
            "  \"model.grad_norm\": 0.017443101853132248,\n",
            "  \"model.elapsed_time\": 0.09266495704650879,\n",
            "  \"model.engine_step\": 907,\n",
            "  \"model.loss.nll\": 0.0009307861328125,\n",
            "  \"elapsed_time\": 0.09266495704650879,\n",
            "  \"wall_time\": 1677241391.4802608,\n",
            "  \"global_step\": 907\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00048041343688964844,\n",
            "  \"model.lr\": 0.000181294,\n",
            "  \"model.grad_norm\": 0.013336013071238995,\n",
            "  \"model.elapsed_time\": 0.09428930282592773,\n",
            "  \"model.engine_step\": 908,\n",
            "  \"model.loss.nll\": 0.00048041343688964844,\n",
            "  \"elapsed_time\": 0.09428930282592773,\n",
            "  \"wall_time\": 1677241391.578908,\n",
            "  \"global_step\": 908\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005488395690917969,\n",
            "  \"model.lr\": 0.00018149300000000002,\n",
            "  \"model.grad_norm\": 0.018876630812883377,\n",
            "  \"model.elapsed_time\": 0.09799456596374512,\n",
            "  \"model.engine_step\": 909,\n",
            "  \"model.loss.nll\": 0.0005488395690917969,\n",
            "  \"elapsed_time\": 0.09799456596374512,\n",
            "  \"wall_time\": 1677241391.689179,\n",
            "  \"global_step\": 909\n",
            "}\n",
            "[2023-02-24 12:23:11,785] [INFO] [logging.py:75:log_dist] [Rank 0] step=910, skipped=1, lr=[0.000181692], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:11,786] [INFO] [timer.py:198:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=12.722190038943932, CurrSamplesPerSec=10.53495825505109, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0010404586791992188,\n",
            "  \"model.lr\": 0.000181692,\n",
            "  \"model.grad_norm\": 0.020268650725483894,\n",
            "  \"model.elapsed_time\": 0.0955498218536377,\n",
            "  \"model.engine_step\": 910,\n",
            "  \"model.loss.nll\": 0.0010404586791992188,\n",
            "  \"elapsed_time\": 0.0955498218536377,\n",
            "  \"wall_time\": 1677241391.7876394,\n",
            "  \"global_step\": 910\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:11\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004811286926269531,\n",
            "  \"model.lr\": 0.00018189100000000002,\n",
            "  \"model.grad_norm\": 0.014304165728390217,\n",
            "  \"model.elapsed_time\": 0.10034632682800293,\n",
            "  \"model.engine_step\": 911,\n",
            "  \"model.loss.nll\": 0.0004811286926269531,\n",
            "  \"elapsed_time\": 0.10034632682800293,\n",
            "  \"wall_time\": 1677241391.8994124,\n",
            "  \"global_step\": 911\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009694099426269531,\n",
            "  \"model.lr\": 0.00018209,\n",
            "  \"model.grad_norm\": 0.027128916233778,\n",
            "  \"model.elapsed_time\": 0.10859298706054688,\n",
            "  \"model.engine_step\": 912,\n",
            "  \"model.loss.nll\": 0.0009694099426269531,\n",
            "  \"elapsed_time\": 0.10859298706054688,\n",
            "  \"wall_time\": 1677241392.0114465,\n",
            "  \"global_step\": 912\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00047016143798828125,\n",
            "  \"model.lr\": 0.000182289,\n",
            "  \"model.grad_norm\": 0.013777034357190132,\n",
            "  \"model.elapsed_time\": 0.10230207443237305,\n",
            "  \"model.engine_step\": 913,\n",
            "  \"model.loss.nll\": 0.00047016143798828125,\n",
            "  \"elapsed_time\": 0.10230207443237305,\n",
            "  \"wall_time\": 1677241392.1258678,\n",
            "  \"global_step\": 913\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0017881393432617188,\n",
            "  \"model.lr\": 0.00018248800000000002,\n",
            "  \"model.grad_norm\": 0.0473850853741169,\n",
            "  \"model.elapsed_time\": 0.09078145027160645,\n",
            "  \"model.engine_step\": 914,\n",
            "  \"model.loss.nll\": 0.0017881393432617188,\n",
            "  \"elapsed_time\": 0.09078145027160645,\n",
            "  \"wall_time\": 1677241392.2196753,\n",
            "  \"global_step\": 914\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005931854248046875,\n",
            "  \"model.lr\": 0.000182687,\n",
            "  \"model.grad_norm\": 0.04268047958612442,\n",
            "  \"model.elapsed_time\": 0.0917978286743164,\n",
            "  \"model.engine_step\": 915,\n",
            "  \"model.loss.nll\": 0.0005931854248046875,\n",
            "  \"elapsed_time\": 0.0917978286743164,\n",
            "  \"wall_time\": 1677241392.3206863,\n",
            "  \"global_step\": 915\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00039577484130859375,\n",
            "  \"model.lr\": 0.00018288600000000002,\n",
            "  \"model.grad_norm\": 0.00457371398806572,\n",
            "  \"model.elapsed_time\": 0.10251498222351074,\n",
            "  \"model.engine_step\": 916,\n",
            "  \"model.loss.nll\": 0.00039577484130859375,\n",
            "  \"elapsed_time\": 0.10251498222351074,\n",
            "  \"wall_time\": 1677241392.4263756,\n",
            "  \"global_step\": 916\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00254058837890625,\n",
            "  \"model.lr\": 0.000183085,\n",
            "  \"model.grad_norm\": 0.13543549180030823,\n",
            "  \"model.elapsed_time\": 0.08919382095336914,\n",
            "  \"model.engine_step\": 917,\n",
            "  \"model.loss.nll\": 0.00254058837890625,\n",
            "  \"elapsed_time\": 0.08919382095336914,\n",
            "  \"wall_time\": 1677241392.5259721,\n",
            "  \"global_step\": 917\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005359649658203125,\n",
            "  \"model.lr\": 0.000183284,\n",
            "  \"model.grad_norm\": 0.017489992082118988,\n",
            "  \"model.elapsed_time\": 0.08816862106323242,\n",
            "  \"model.engine_step\": 918,\n",
            "  \"model.loss.nll\": 0.0005359649658203125,\n",
            "  \"elapsed_time\": 0.08816862106323242,\n",
            "  \"wall_time\": 1677241392.6173363,\n",
            "  \"global_step\": 918\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005068778991699219,\n",
            "  \"model.lr\": 0.00018348300000000002,\n",
            "  \"model.grad_norm\": 0.020157329738140106,\n",
            "  \"model.elapsed_time\": 0.09305977821350098,\n",
            "  \"model.engine_step\": 919,\n",
            "  \"model.loss.nll\": 0.0005068778991699219,\n",
            "  \"elapsed_time\": 0.09305977821350098,\n",
            "  \"wall_time\": 1677241392.7210531,\n",
            "  \"global_step\": 919\n",
            "}\n",
            "[2023-02-24 12:23:12,819] [INFO] [logging.py:75:log_dist] [Rank 0] step=920, skipped=1, lr=[0.000183682], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:12,820] [INFO] [timer.py:198:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=12.69096779369816, CurrSamplesPerSec=10.233903631625692, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005064010620117188,\n",
            "  \"model.lr\": 0.000183682,\n",
            "  \"model.grad_norm\": 0.01678580231964588,\n",
            "  \"model.elapsed_time\": 0.09837508201599121,\n",
            "  \"model.engine_step\": 920,\n",
            "  \"model.loss.nll\": 0.0005064010620117188,\n",
            "  \"elapsed_time\": 0.09837508201599121,\n",
            "  \"wall_time\": 1677241392.8221836,\n",
            "  \"global_step\": 920\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:12\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00046253204345703125,\n",
            "  \"model.lr\": 0.00018388100000000002,\n",
            "  \"model.grad_norm\": 0.013001196086406708,\n",
            "  \"model.elapsed_time\": 0.1076056957244873,\n",
            "  \"model.engine_step\": 921,\n",
            "  \"model.loss.nll\": 0.00046253204345703125,\n",
            "  \"elapsed_time\": 0.1076056957244873,\n",
            "  \"wall_time\": 1677241392.9412782,\n",
            "  \"global_step\": 921\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004699230194091797,\n",
            "  \"model.lr\": 0.00018408,\n",
            "  \"model.grad_norm\": 0.011795375496149063,\n",
            "  \"model.elapsed_time\": 0.09678220748901367,\n",
            "  \"model.engine_step\": 922,\n",
            "  \"model.loss.nll\": 0.0004699230194091797,\n",
            "  \"elapsed_time\": 0.09678220748901367,\n",
            "  \"wall_time\": 1677241393.0409448,\n",
            "  \"global_step\": 922\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002166748046875,\n",
            "  \"model.lr\": 0.00018427900000000003,\n",
            "  \"model.grad_norm\": 0.07434951514005661,\n",
            "  \"model.elapsed_time\": 0.09145760536193848,\n",
            "  \"model.engine_step\": 923,\n",
            "  \"model.loss.nll\": 0.002166748046875,\n",
            "  \"elapsed_time\": 0.09145760536193848,\n",
            "  \"wall_time\": 1677241393.1460953,\n",
            "  \"global_step\": 923\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004336833953857422,\n",
            "  \"model.lr\": 0.00018447800000000002,\n",
            "  \"model.grad_norm\": 0.008612768724560738,\n",
            "  \"model.elapsed_time\": 0.10068774223327637,\n",
            "  \"model.engine_step\": 924,\n",
            "  \"model.loss.nll\": 0.0004336833953857422,\n",
            "  \"elapsed_time\": 0.10068774223327637,\n",
            "  \"wall_time\": 1677241393.2497416,\n",
            "  \"global_step\": 924\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004911422729492188,\n",
            "  \"model.lr\": 0.000184677,\n",
            "  \"model.grad_norm\": 0.013041003607213497,\n",
            "  \"model.elapsed_time\": 0.10378408432006836,\n",
            "  \"model.engine_step\": 925,\n",
            "  \"model.loss.nll\": 0.0004911422729492188,\n",
            "  \"elapsed_time\": 0.10378408432006836,\n",
            "  \"wall_time\": 1677241393.367194,\n",
            "  \"global_step\": 925\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00043773651123046875,\n",
            "  \"model.lr\": 0.00018487600000000002,\n",
            "  \"model.grad_norm\": 0.005753788165748119,\n",
            "  \"model.elapsed_time\": 0.09991908073425293,\n",
            "  \"model.engine_step\": 926,\n",
            "  \"model.loss.nll\": 0.00043773651123046875,\n",
            "  \"elapsed_time\": 0.09991908073425293,\n",
            "  \"wall_time\": 1677241393.4702752,\n",
            "  \"global_step\": 926\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0021953582763671875,\n",
            "  \"model.lr\": 0.000185075,\n",
            "  \"model.grad_norm\": 0.05432227626442909,\n",
            "  \"model.elapsed_time\": 0.09957003593444824,\n",
            "  \"model.engine_step\": 927,\n",
            "  \"model.loss.nll\": 0.0021953582763671875,\n",
            "  \"elapsed_time\": 0.09957003593444824,\n",
            "  \"wall_time\": 1677241393.5821486,\n",
            "  \"global_step\": 927\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004150867462158203,\n",
            "  \"model.lr\": 0.00018527400000000003,\n",
            "  \"model.grad_norm\": 0.010298626497387886,\n",
            "  \"model.elapsed_time\": 0.1025996208190918,\n",
            "  \"model.engine_step\": 928,\n",
            "  \"model.loss.nll\": 0.0004150867462158203,\n",
            "  \"elapsed_time\": 0.1025996208190918,\n",
            "  \"wall_time\": 1677241393.687623,\n",
            "  \"global_step\": 928\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0015697479248046875,\n",
            "  \"model.lr\": 0.00018547300000000002,\n",
            "  \"model.grad_norm\": 0.03865458071231842,\n",
            "  \"model.elapsed_time\": 0.09975314140319824,\n",
            "  \"model.engine_step\": 929,\n",
            "  \"model.loss.nll\": 0.0015697479248046875,\n",
            "  \"elapsed_time\": 0.09975314140319824,\n",
            "  \"wall_time\": 1677241393.7986221,\n",
            "  \"global_step\": 929\n",
            "}\n",
            "[2023-02-24 12:23:13,902] [INFO] [logging.py:75:log_dist] [Rank 0] step=930, skipped=1, lr=[0.000185672], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:13,903] [INFO] [timer.py:198:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=12.653560029943085, CurrSamplesPerSec=9.705958989857383, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008668899536132812,\n",
            "  \"model.lr\": 0.000185672,\n",
            "  \"model.grad_norm\": 0.024295780807733536,\n",
            "  \"model.elapsed_time\": 0.10369014739990234,\n",
            "  \"model.engine_step\": 930,\n",
            "  \"model.loss.nll\": 0.0008668899536132812,\n",
            "  \"elapsed_time\": 0.10369014739990234,\n",
            "  \"wall_time\": 1677241393.9051914,\n",
            "  \"global_step\": 930\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:13\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004801750183105469,\n",
            "  \"model.lr\": 0.00018587100000000002,\n",
            "  \"model.grad_norm\": 0.01765393279492855,\n",
            "  \"model.elapsed_time\": 0.1081843376159668,\n",
            "  \"model.engine_step\": 931,\n",
            "  \"model.loss.nll\": 0.0004801750183105469,\n",
            "  \"elapsed_time\": 0.1081843376159668,\n",
            "  \"wall_time\": 1677241394.0262563,\n",
            "  \"global_step\": 931\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00036263465881347656,\n",
            "  \"model.lr\": 0.00018607,\n",
            "  \"model.grad_norm\": 0.004324279259890318,\n",
            "  \"model.elapsed_time\": 0.12276887893676758,\n",
            "  \"model.engine_step\": 932,\n",
            "  \"model.loss.nll\": 0.00036263465881347656,\n",
            "  \"elapsed_time\": 0.12276887893676758,\n",
            "  \"wall_time\": 1677241394.1533093,\n",
            "  \"global_step\": 932\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00039005279541015625,\n",
            "  \"model.lr\": 0.00018626900000000003,\n",
            "  \"model.grad_norm\": 0.006590081844478846,\n",
            "  \"model.elapsed_time\": 0.09862613677978516,\n",
            "  \"model.engine_step\": 933,\n",
            "  \"model.loss.nll\": 0.00039005279541015625,\n",
            "  \"elapsed_time\": 0.09862613677978516,\n",
            "  \"wall_time\": 1677241394.2616844,\n",
            "  \"global_step\": 933\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000988006591796875,\n",
            "  \"model.lr\": 0.00018646800000000002,\n",
            "  \"model.grad_norm\": 0.02889070101082325,\n",
            "  \"model.elapsed_time\": 0.10361123085021973,\n",
            "  \"model.engine_step\": 934,\n",
            "  \"model.loss.nll\": 0.000988006591796875,\n",
            "  \"elapsed_time\": 0.10361123085021973,\n",
            "  \"wall_time\": 1677241394.3685336,\n",
            "  \"global_step\": 934\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00046253204345703125,\n",
            "  \"model.lr\": 0.000186667,\n",
            "  \"model.grad_norm\": 0.01189328357577324,\n",
            "  \"model.elapsed_time\": 0.10533881187438965,\n",
            "  \"model.engine_step\": 935,\n",
            "  \"model.loss.nll\": 0.00046253204345703125,\n",
            "  \"elapsed_time\": 0.10533881187438965,\n",
            "  \"wall_time\": 1677241394.4829926,\n",
            "  \"global_step\": 935\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004265308380126953,\n",
            "  \"model.lr\": 0.00018686600000000002,\n",
            "  \"model.grad_norm\": 0.008023559115827084,\n",
            "  \"model.elapsed_time\": 0.10277771949768066,\n",
            "  \"model.engine_step\": 936,\n",
            "  \"model.loss.nll\": 0.0004265308380126953,\n",
            "  \"elapsed_time\": 0.10277771949768066,\n",
            "  \"wall_time\": 1677241394.5901685,\n",
            "  \"global_step\": 936\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004124641418457031,\n",
            "  \"model.lr\": 0.000187065,\n",
            "  \"model.grad_norm\": 0.00790926069021225,\n",
            "  \"model.elapsed_time\": 0.10291528701782227,\n",
            "  \"model.engine_step\": 937,\n",
            "  \"model.loss.nll\": 0.0004124641418457031,\n",
            "  \"elapsed_time\": 0.10291528701782227,\n",
            "  \"wall_time\": 1677241394.703827,\n",
            "  \"global_step\": 937\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003864765167236328,\n",
            "  \"model.lr\": 0.00018726400000000003,\n",
            "  \"model.grad_norm\": 0.008392948657274246,\n",
            "  \"model.elapsed_time\": 0.10261392593383789,\n",
            "  \"model.engine_step\": 938,\n",
            "  \"model.loss.nll\": 0.0003864765167236328,\n",
            "  \"elapsed_time\": 0.10261392593383789,\n",
            "  \"wall_time\": 1677241394.810303,\n",
            "  \"global_step\": 938\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:14\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003597736358642578,\n",
            "  \"model.lr\": 0.00018746300000000002,\n",
            "  \"model.grad_norm\": 0.0045168050564825535,\n",
            "  \"model.elapsed_time\": 0.10469174385070801,\n",
            "  \"model.engine_step\": 939,\n",
            "  \"model.loss.nll\": 0.0003597736358642578,\n",
            "  \"elapsed_time\": 0.10469174385070801,\n",
            "  \"wall_time\": 1677241394.9269109,\n",
            "  \"global_step\": 939\n",
            "}\n",
            "[2023-02-24 12:23:15,030] [INFO] [logging.py:75:log_dist] [Rank 0] step=940, skipped=1, lr=[0.000187662], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:15,031] [INFO] [timer.py:198:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=12.6089393780411, CurrSamplesPerSec=9.769690532425848, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00048041343688964844,\n",
            "  \"model.lr\": 0.000187662,\n",
            "  \"model.grad_norm\": 0.018363486975431442,\n",
            "  \"model.elapsed_time\": 0.10306787490844727,\n",
            "  \"model.engine_step\": 940,\n",
            "  \"model.loss.nll\": 0.00048041343688964844,\n",
            "  \"elapsed_time\": 0.10306787490844727,\n",
            "  \"wall_time\": 1677241395.0332747,\n",
            "  \"global_step\": 940\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009851455688476562,\n",
            "  \"model.lr\": 0.000187861,\n",
            "  \"model.grad_norm\": 0.018214670941233635,\n",
            "  \"model.elapsed_time\": 0.11155176162719727,\n",
            "  \"model.engine_step\": 941,\n",
            "  \"model.loss.nll\": 0.0009851455688476562,\n",
            "  \"elapsed_time\": 0.11155176162719727,\n",
            "  \"wall_time\": 1677241395.1547313,\n",
            "  \"global_step\": 941\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004096031188964844,\n",
            "  \"model.lr\": 0.00018805999999999998,\n",
            "  \"model.grad_norm\": 0.009448288008570671,\n",
            "  \"model.elapsed_time\": 0.10191488265991211,\n",
            "  \"model.engine_step\": 942,\n",
            "  \"model.loss.nll\": 0.0004096031188964844,\n",
            "  \"elapsed_time\": 0.10191488265991211,\n",
            "  \"wall_time\": 1677241395.2606215,\n",
            "  \"global_step\": 942\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004496574401855469,\n",
            "  \"model.lr\": 0.000188259,\n",
            "  \"model.grad_norm\": 0.009999513626098633,\n",
            "  \"model.elapsed_time\": 0.12108349800109863,\n",
            "  \"model.engine_step\": 943,\n",
            "  \"model.loss.nll\": 0.0004496574401855469,\n",
            "  \"elapsed_time\": 0.12108349800109863,\n",
            "  \"wall_time\": 1677241395.3930945,\n",
            "  \"global_step\": 943\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003504753112792969,\n",
            "  \"model.lr\": 0.000188458,\n",
            "  \"model.grad_norm\": 0.003956905100494623,\n",
            "  \"model.elapsed_time\": 0.10650897026062012,\n",
            "  \"model.engine_step\": 944,\n",
            "  \"model.loss.nll\": 0.0003504753112792969,\n",
            "  \"elapsed_time\": 0.10650897026062012,\n",
            "  \"wall_time\": 1677241395.5034764,\n",
            "  \"global_step\": 944\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004911422729492188,\n",
            "  \"model.lr\": 0.000188657,\n",
            "  \"model.grad_norm\": 0.016232263296842575,\n",
            "  \"model.elapsed_time\": 0.10328507423400879,\n",
            "  \"model.engine_step\": 945,\n",
            "  \"model.loss.nll\": 0.0004911422729492188,\n",
            "  \"elapsed_time\": 0.10328507423400879,\n",
            "  \"wall_time\": 1677241395.6173635,\n",
            "  \"global_step\": 945\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003299713134765625,\n",
            "  \"model.lr\": 0.000188856,\n",
            "  \"model.grad_norm\": 0.004061538726091385,\n",
            "  \"model.elapsed_time\": 0.10734176635742188,\n",
            "  \"model.engine_step\": 946,\n",
            "  \"model.loss.nll\": 0.0003299713134765625,\n",
            "  \"elapsed_time\": 0.10734176635742188,\n",
            "  \"wall_time\": 1677241395.7287827,\n",
            "  \"global_step\": 946\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00286865234375,\n",
            "  \"model.lr\": 0.000189055,\n",
            "  \"model.grad_norm\": 0.24598348140716553,\n",
            "  \"model.elapsed_time\": 0.10173201560974121,\n",
            "  \"model.engine_step\": 947,\n",
            "  \"model.loss.nll\": 0.00286865234375,\n",
            "  \"elapsed_time\": 0.10173201560974121,\n",
            "  \"wall_time\": 1677241395.8406978,\n",
            "  \"global_step\": 947\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00040793418884277344,\n",
            "  \"model.lr\": 0.000189254,\n",
            "  \"model.grad_norm\": 0.011369972489774227,\n",
            "  \"model.elapsed_time\": 0.10686373710632324,\n",
            "  \"model.engine_step\": 948,\n",
            "  \"model.loss.nll\": 0.00040793418884277344,\n",
            "  \"elapsed_time\": 0.10686373710632324,\n",
            "  \"wall_time\": 1677241395.9509356,\n",
            "  \"global_step\": 948\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:15\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00032830238342285156,\n",
            "  \"model.lr\": 0.000189453,\n",
            "  \"model.grad_norm\": 0.0034636419732123613,\n",
            "  \"model.elapsed_time\": 0.11372947692871094,\n",
            "  \"model.engine_step\": 949,\n",
            "  \"model.loss.nll\": 0.00032830238342285156,\n",
            "  \"elapsed_time\": 0.11372947692871094,\n",
            "  \"wall_time\": 1677241396.0780404,\n",
            "  \"global_step\": 949\n",
            "}\n",
            "[2023-02-24 12:23:16,185] [INFO] [logging.py:75:log_dist] [Rank 0] step=950, skipped=1, lr=[0.000189652], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:16,186] [INFO] [timer.py:198:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=12.561153895176767, CurrSamplesPerSec=9.416049676501093, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004048347473144531,\n",
            "  \"model.lr\": 0.000189652,\n",
            "  \"model.grad_norm\": 0.007140519563108683,\n",
            "  \"model.elapsed_time\": 0.10687637329101562,\n",
            "  \"model.engine_step\": 950,\n",
            "  \"model.loss.nll\": 0.0004048347473144531,\n",
            "  \"elapsed_time\": 0.10687637329101562,\n",
            "  \"wall_time\": 1677241396.1882143,\n",
            "  \"global_step\": 950\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003867149353027344,\n",
            "  \"model.lr\": 0.000189851,\n",
            "  \"model.grad_norm\": 0.006044237408787012,\n",
            "  \"model.elapsed_time\": 0.09966254234313965,\n",
            "  \"model.engine_step\": 951,\n",
            "  \"model.loss.nll\": 0.0003867149353027344,\n",
            "  \"elapsed_time\": 0.09966254234313965,\n",
            "  \"wall_time\": 1677241396.3008425,\n",
            "  \"global_step\": 951\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003743171691894531,\n",
            "  \"model.lr\": 0.00019005,\n",
            "  \"model.grad_norm\": 0.005014628171920776,\n",
            "  \"model.elapsed_time\": 0.10728883743286133,\n",
            "  \"model.engine_step\": 952,\n",
            "  \"model.loss.nll\": 0.0003743171691894531,\n",
            "  \"elapsed_time\": 0.10728883743286133,\n",
            "  \"wall_time\": 1677241396.4111304,\n",
            "  \"global_step\": 952\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009279251098632812,\n",
            "  \"model.lr\": 0.000190249,\n",
            "  \"model.grad_norm\": 0.025139236822724342,\n",
            "  \"model.elapsed_time\": 0.10504031181335449,\n",
            "  \"model.engine_step\": 953,\n",
            "  \"model.loss.nll\": 0.0009279251098632812,\n",
            "  \"elapsed_time\": 0.10504031181335449,\n",
            "  \"wall_time\": 1677241396.5252948,\n",
            "  \"global_step\": 953\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00040078163146972656,\n",
            "  \"model.lr\": 0.000190448,\n",
            "  \"model.grad_norm\": 0.0093574533239007,\n",
            "  \"model.elapsed_time\": 0.10150527954101562,\n",
            "  \"model.engine_step\": 954,\n",
            "  \"model.loss.nll\": 0.00040078163146972656,\n",
            "  \"elapsed_time\": 0.10150527954101562,\n",
            "  \"wall_time\": 1677241396.6302156,\n",
            "  \"global_step\": 954\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000469207763671875,\n",
            "  \"model.lr\": 0.000190647,\n",
            "  \"model.grad_norm\": 0.021544398739933968,\n",
            "  \"model.elapsed_time\": 0.11266350746154785,\n",
            "  \"model.engine_step\": 955,\n",
            "  \"model.loss.nll\": 0.000469207763671875,\n",
            "  \"elapsed_time\": 0.11266350746154785,\n",
            "  \"wall_time\": 1677241396.7512825,\n",
            "  \"global_step\": 955\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0016021728515625,\n",
            "  \"model.lr\": 0.000190846,\n",
            "  \"model.grad_norm\": 0.035090114921331406,\n",
            "  \"model.elapsed_time\": 0.1010732650756836,\n",
            "  \"model.engine_step\": 956,\n",
            "  \"model.loss.nll\": 0.0016021728515625,\n",
            "  \"elapsed_time\": 0.1010732650756836,\n",
            "  \"wall_time\": 1677241396.8560736,\n",
            "  \"global_step\": 956\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:16\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00041604042053222656,\n",
            "  \"model.lr\": 0.000191045,\n",
            "  \"model.grad_norm\": 0.01157345436513424,\n",
            "  \"model.elapsed_time\": 0.10570335388183594,\n",
            "  \"model.engine_step\": 957,\n",
            "  \"model.loss.nll\": 0.00041604042053222656,\n",
            "  \"elapsed_time\": 0.10570335388183594,\n",
            "  \"wall_time\": 1677241396.9737113,\n",
            "  \"global_step\": 957\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003631114959716797,\n",
            "  \"model.lr\": 0.000191244,\n",
            "  \"model.grad_norm\": 0.005044210702180862,\n",
            "  \"model.elapsed_time\": 0.10952043533325195,\n",
            "  \"model.engine_step\": 958,\n",
            "  \"model.loss.nll\": 0.0003631114959716797,\n",
            "  \"elapsed_time\": 0.10952043533325195,\n",
            "  \"wall_time\": 1677241397.086168,\n",
            "  \"global_step\": 958\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004010200500488281,\n",
            "  \"model.lr\": 0.000191443,\n",
            "  \"model.grad_norm\": 0.0068315910175442696,\n",
            "  \"model.elapsed_time\": 0.11588096618652344,\n",
            "  \"model.engine_step\": 959,\n",
            "  \"model.loss.nll\": 0.0004010200500488281,\n",
            "  \"elapsed_time\": 0.11588096618652344,\n",
            "  \"wall_time\": 1677241397.2113981,\n",
            "  \"global_step\": 959\n",
            "}\n",
            "[2023-02-24 12:23:17,321] [INFO] [logging.py:75:log_dist] [Rank 0] step=960, skipped=1, lr=[0.000191642], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:17,321] [INFO] [timer.py:198:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=12.516997868133442, CurrSamplesPerSec=9.264368780854142, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009584426879882812,\n",
            "  \"model.lr\": 0.000191642,\n",
            "  \"model.grad_norm\": 0.028307875618338585,\n",
            "  \"model.elapsed_time\": 0.10862398147583008,\n",
            "  \"model.engine_step\": 960,\n",
            "  \"model.loss.nll\": 0.0009584426879882812,\n",
            "  \"elapsed_time\": 0.10862398147583008,\n",
            "  \"wall_time\": 1677241397.3235166,\n",
            "  \"global_step\": 960\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005068778991699219,\n",
            "  \"model.lr\": 0.000191841,\n",
            "  \"model.grad_norm\": 0.02399536967277527,\n",
            "  \"model.elapsed_time\": 0.10890579223632812,\n",
            "  \"model.engine_step\": 961,\n",
            "  \"model.loss.nll\": 0.0005068778991699219,\n",
            "  \"elapsed_time\": 0.10890579223632812,\n",
            "  \"wall_time\": 1677241397.4423964,\n",
            "  \"global_step\": 961\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003695487976074219,\n",
            "  \"model.lr\": 0.00019204,\n",
            "  \"model.grad_norm\": 0.00759638799354434,\n",
            "  \"model.elapsed_time\": 0.10521245002746582,\n",
            "  \"model.engine_step\": 962,\n",
            "  \"model.loss.nll\": 0.0003695487976074219,\n",
            "  \"elapsed_time\": 0.10521245002746582,\n",
            "  \"wall_time\": 1677241397.5507972,\n",
            "  \"global_step\": 962\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0013828277587890625,\n",
            "  \"model.lr\": 0.000192239,\n",
            "  \"model.grad_norm\": 0.11613842099905014,\n",
            "  \"model.elapsed_time\": 0.11352038383483887,\n",
            "  \"model.engine_step\": 963,\n",
            "  \"model.loss.nll\": 0.0013828277587890625,\n",
            "  \"elapsed_time\": 0.11352038383483887,\n",
            "  \"wall_time\": 1677241397.673712,\n",
            "  \"global_step\": 963\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004279613494873047,\n",
            "  \"model.lr\": 0.000192438,\n",
            "  \"model.grad_norm\": 0.017072292044758797,\n",
            "  \"model.elapsed_time\": 0.11101984977722168,\n",
            "  \"model.engine_step\": 964,\n",
            "  \"model.loss.nll\": 0.0004279613494873047,\n",
            "  \"elapsed_time\": 0.11101984977722168,\n",
            "  \"wall_time\": 1677241397.7885878,\n",
            "  \"global_step\": 964\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:17\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007157325744628906,\n",
            "  \"model.lr\": 0.000192637,\n",
            "  \"model.grad_norm\": 0.013060256838798523,\n",
            "  \"model.elapsed_time\": 0.1038510799407959,\n",
            "  \"model.engine_step\": 965,\n",
            "  \"model.loss.nll\": 0.0007157325744628906,\n",
            "  \"elapsed_time\": 0.1038510799407959,\n",
            "  \"wall_time\": 1677241397.902265,\n",
            "  \"global_step\": 965\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004076957702636719,\n",
            "  \"model.lr\": 0.000192836,\n",
            "  \"model.grad_norm\": 0.011163881048560143,\n",
            "  \"model.elapsed_time\": 0.10426831245422363,\n",
            "  \"model.engine_step\": 966,\n",
            "  \"model.loss.nll\": 0.0004076957702636719,\n",
            "  \"elapsed_time\": 0.10426831245422363,\n",
            "  \"wall_time\": 1677241398.00962,\n",
            "  \"global_step\": 966\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007739067077636719,\n",
            "  \"model.lr\": 0.000193035,\n",
            "  \"model.grad_norm\": 0.028911683708429337,\n",
            "  \"model.elapsed_time\": 0.11409974098205566,\n",
            "  \"model.engine_step\": 967,\n",
            "  \"model.loss.nll\": 0.0007739067077636719,\n",
            "  \"elapsed_time\": 0.11409974098205566,\n",
            "  \"wall_time\": 1677241398.1326363,\n",
            "  \"global_step\": 967\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009946823120117188,\n",
            "  \"model.lr\": 0.000193234,\n",
            "  \"model.grad_norm\": 0.0324249304831028,\n",
            "  \"model.elapsed_time\": 0.11953544616699219,\n",
            "  \"model.engine_step\": 968,\n",
            "  \"model.loss.nll\": 0.0009946823120117188,\n",
            "  \"elapsed_time\": 0.11953544616699219,\n",
            "  \"wall_time\": 1677241398.2559593,\n",
            "  \"global_step\": 968\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00035262107849121094,\n",
            "  \"model.lr\": 0.00019343300000000002,\n",
            "  \"model.grad_norm\": 0.004467641469091177,\n",
            "  \"model.elapsed_time\": 0.11326789855957031,\n",
            "  \"model.engine_step\": 969,\n",
            "  \"model.loss.nll\": 0.00035262107849121094,\n",
            "  \"elapsed_time\": 0.11326789855957031,\n",
            "  \"wall_time\": 1677241398.3799808,\n",
            "  \"global_step\": 969\n",
            "}\n",
            "[2023-02-24 12:23:18,488] [INFO] [logging.py:75:log_dist] [Rank 0] step=970, skipped=1, lr=[0.000193632], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:18,489] [INFO] [timer.py:198:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=12.469249892278413, CurrSamplesPerSec=9.763163836547527, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003371238708496094,\n",
            "  \"model.lr\": 0.000193632,\n",
            "  \"model.grad_norm\": 0.006562523078173399,\n",
            "  \"model.elapsed_time\": 0.10306739807128906,\n",
            "  \"model.engine_step\": 970,\n",
            "  \"model.loss.nll\": 0.0003371238708496094,\n",
            "  \"elapsed_time\": 0.10306739807128906,\n",
            "  \"wall_time\": 1677241398.4906905,\n",
            "  \"global_step\": 970\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00044798851013183594,\n",
            "  \"model.lr\": 0.000193831,\n",
            "  \"model.grad_norm\": 0.02151593752205372,\n",
            "  \"model.elapsed_time\": 0.10218048095703125,\n",
            "  \"model.engine_step\": 971,\n",
            "  \"model.loss.nll\": 0.00044798851013183594,\n",
            "  \"elapsed_time\": 0.10218048095703125,\n",
            "  \"wall_time\": 1677241398.6030128,\n",
            "  \"global_step\": 971\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.002506256103515625,\n",
            "  \"model.lr\": 0.00019403,\n",
            "  \"model.grad_norm\": 0.1601151078939438,\n",
            "  \"model.elapsed_time\": 0.09958434104919434,\n",
            "  \"model.engine_step\": 972,\n",
            "  \"model.loss.nll\": 0.002506256103515625,\n",
            "  \"elapsed_time\": 0.09958434104919434,\n",
            "  \"wall_time\": 1677241398.7054398,\n",
            "  \"global_step\": 972\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003464221954345703,\n",
            "  \"model.lr\": 0.000194229,\n",
            "  \"model.grad_norm\": 0.004231034778058529,\n",
            "  \"model.elapsed_time\": 0.105438232421875,\n",
            "  \"model.engine_step\": 973,\n",
            "  \"model.loss.nll\": 0.0003464221954345703,\n",
            "  \"elapsed_time\": 0.105438232421875,\n",
            "  \"wall_time\": 1677241398.819992,\n",
            "  \"global_step\": 973\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004200935363769531,\n",
            "  \"model.lr\": 0.00019442800000000002,\n",
            "  \"model.grad_norm\": 0.02122165635228157,\n",
            "  \"model.elapsed_time\": 0.10447168350219727,\n",
            "  \"model.engine_step\": 974,\n",
            "  \"model.loss.nll\": 0.0004200935363769531,\n",
            "  \"elapsed_time\": 0.10447168350219727,\n",
            "  \"wall_time\": 1677241398.9277189,\n",
            "  \"global_step\": 974\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:18\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0004107952117919922,\n",
            "  \"model.lr\": 0.000194627,\n",
            "  \"model.grad_norm\": 0.009066450409591198,\n",
            "  \"model.elapsed_time\": 0.10876846313476562,\n",
            "  \"model.engine_step\": 975,\n",
            "  \"model.loss.nll\": 0.0004107952117919922,\n",
            "  \"elapsed_time\": 0.10876846313476562,\n",
            "  \"wall_time\": 1677241399.0477145,\n",
            "  \"global_step\": 975\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003859996795654297,\n",
            "  \"model.lr\": 0.000194826,\n",
            "  \"model.grad_norm\": 0.0072711980901658535,\n",
            "  \"model.elapsed_time\": 0.10755228996276855,\n",
            "  \"model.engine_step\": 976,\n",
            "  \"model.loss.nll\": 0.0003859996795654297,\n",
            "  \"elapsed_time\": 0.10755228996276855,\n",
            "  \"wall_time\": 1677241399.1587026,\n",
            "  \"global_step\": 976\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00139617919921875,\n",
            "  \"model.lr\": 0.000195025,\n",
            "  \"model.grad_norm\": 0.030597934499382973,\n",
            "  \"model.elapsed_time\": 0.10423898696899414,\n",
            "  \"model.engine_step\": 977,\n",
            "  \"model.loss.nll\": 0.00139617919921875,\n",
            "  \"elapsed_time\": 0.10423898696899414,\n",
            "  \"wall_time\": 1677241399.2738242,\n",
            "  \"global_step\": 977\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00038242340087890625,\n",
            "  \"model.lr\": 0.000195224,\n",
            "  \"model.grad_norm\": 0.010016802698373795,\n",
            "  \"model.elapsed_time\": 0.10490536689758301,\n",
            "  \"model.engine_step\": 978,\n",
            "  \"model.loss.nll\": 0.00038242340087890625,\n",
            "  \"elapsed_time\": 0.10490536689758301,\n",
            "  \"wall_time\": 1677241399.381848,\n",
            "  \"global_step\": 978\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0023746490478515625,\n",
            "  \"model.lr\": 0.00019542300000000002,\n",
            "  \"model.grad_norm\": 0.1648765206336975,\n",
            "  \"model.elapsed_time\": 0.10282015800476074,\n",
            "  \"model.engine_step\": 979,\n",
            "  \"model.loss.nll\": 0.0023746490478515625,\n",
            "  \"elapsed_time\": 0.10282015800476074,\n",
            "  \"wall_time\": 1677241399.4980886,\n",
            "  \"global_step\": 979\n",
            "}\n",
            "[2023-02-24 12:23:19,610] [INFO] [logging.py:75:log_dist] [Rank 0] step=980, skipped=1, lr=[0.000195622], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:19,611] [INFO] [timer.py:198:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=12.430047504562769, CurrSamplesPerSec=9.04574520625349, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008687973022460938,\n",
            "  \"model.lr\": 0.000195622,\n",
            "  \"model.grad_norm\": 0.03378057852387428,\n",
            "  \"model.elapsed_time\": 0.11120915412902832,\n",
            "  \"model.engine_step\": 980,\n",
            "  \"model.loss.nll\": 0.0008687973022460938,\n",
            "  \"elapsed_time\": 0.11120915412902832,\n",
            "  \"wall_time\": 1677241399.612958,\n",
            "  \"global_step\": 980\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00036978721618652344,\n",
            "  \"model.lr\": 0.000195821,\n",
            "  \"model.grad_norm\": 0.006357446312904358,\n",
            "  \"model.elapsed_time\": 0.10722589492797852,\n",
            "  \"model.engine_step\": 981,\n",
            "  \"model.loss.nll\": 0.00036978721618652344,\n",
            "  \"elapsed_time\": 0.10722589492797852,\n",
            "  \"wall_time\": 1677241399.7319489,\n",
            "  \"global_step\": 981\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00031065940856933594,\n",
            "  \"model.lr\": 0.00019602,\n",
            "  \"model.grad_norm\": 0.004037454724311829,\n",
            "  \"model.elapsed_time\": 0.1109166145324707,\n",
            "  \"model.engine_step\": 982,\n",
            "  \"model.loss.nll\": 0.00031065940856933594,\n",
            "  \"elapsed_time\": 0.1109166145324707,\n",
            "  \"wall_time\": 1677241399.8460212,\n",
            "  \"global_step\": 982\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:19\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00038313865661621094,\n",
            "  \"model.lr\": 0.000196219,\n",
            "  \"model.grad_norm\": 0.010919040068984032,\n",
            "  \"model.elapsed_time\": 0.1055912971496582,\n",
            "  \"model.engine_step\": 983,\n",
            "  \"model.loss.nll\": 0.00038313865661621094,\n",
            "  \"elapsed_time\": 0.1055912971496582,\n",
            "  \"wall_time\": 1677241399.961594,\n",
            "  \"global_step\": 983\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003628730773925781,\n",
            "  \"model.lr\": 0.00019641800000000002,\n",
            "  \"model.grad_norm\": 0.01237656269222498,\n",
            "  \"model.elapsed_time\": 0.08268427848815918,\n",
            "  \"model.engine_step\": 984,\n",
            "  \"model.loss.nll\": 0.0003628730773925781,\n",
            "  \"elapsed_time\": 0.08268427848815918,\n",
            "  \"wall_time\": 1677241400.046707,\n",
            "  \"global_step\": 984\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0008234977722167969,\n",
            "  \"model.lr\": 0.000196617,\n",
            "  \"model.grad_norm\": 0.021773740649223328,\n",
            "  \"model.elapsed_time\": 0.07250642776489258,\n",
            "  \"model.engine_step\": 985,\n",
            "  \"model.loss.nll\": 0.0008234977722167969,\n",
            "  \"elapsed_time\": 0.07250642776489258,\n",
            "  \"wall_time\": 1677241400.1258893,\n",
            "  \"global_step\": 985\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00044035911560058594,\n",
            "  \"model.lr\": 0.000196816,\n",
            "  \"model.grad_norm\": 0.013301369734108448,\n",
            "  \"model.elapsed_time\": 0.06869029998779297,\n",
            "  \"model.engine_step\": 986,\n",
            "  \"model.loss.nll\": 0.00044035911560058594,\n",
            "  \"elapsed_time\": 0.06869029998779297,\n",
            "  \"wall_time\": 1677241400.19738,\n",
            "  \"global_step\": 986\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.001445770263671875,\n",
            "  \"model.lr\": 0.000197015,\n",
            "  \"model.grad_norm\": 0.04222990572452545,\n",
            "  \"model.elapsed_time\": 0.06543779373168945,\n",
            "  \"model.engine_step\": 987,\n",
            "  \"model.loss.nll\": 0.001445770263671875,\n",
            "  \"elapsed_time\": 0.06543779373168945,\n",
            "  \"wall_time\": 1677241400.2711496,\n",
            "  \"global_step\": 987\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0007677078247070312,\n",
            "  \"model.lr\": 0.000197214,\n",
            "  \"model.grad_norm\": 0.12342566251754761,\n",
            "  \"model.elapsed_time\": 0.07628631591796875,\n",
            "  \"model.engine_step\": 988,\n",
            "  \"model.loss.nll\": 0.0007677078247070312,\n",
            "  \"elapsed_time\": 0.07628631591796875,\n",
            "  \"wall_time\": 1677241400.3502316,\n",
            "  \"global_step\": 988\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0015001296997070312,\n",
            "  \"model.lr\": 0.00019741300000000002,\n",
            "  \"model.grad_norm\": 0.10599945485591888,\n",
            "  \"model.elapsed_time\": 0.07627511024475098,\n",
            "  \"model.engine_step\": 989,\n",
            "  \"model.loss.nll\": 0.0015001296997070312,\n",
            "  \"elapsed_time\": 0.07627511024475098,\n",
            "  \"wall_time\": 1677241400.4347427,\n",
            "  \"global_step\": 989\n",
            "}\n",
            "[2023-02-24 12:23:20,499] [INFO] [logging.py:75:log_dist] [Rank 0] step=990, skipped=1, lr=[0.000197612], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:20,500] [INFO] [timer.py:198:stop] epoch=0/micro_step=990/global_step=990, RunningAvgSamplesPerSec=12.426223385297304, CurrSamplesPerSec=15.578425036584731, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00199127197265625,\n",
            "  \"model.lr\": 0.000197612,\n",
            "  \"model.grad_norm\": 0.06690745055675507,\n",
            "  \"model.elapsed_time\": 0.06461143493652344,\n",
            "  \"model.engine_step\": 990,\n",
            "  \"model.loss.nll\": 0.00199127197265625,\n",
            "  \"elapsed_time\": 0.06461143493652344,\n",
            "  \"wall_time\": 1677241400.5013864,\n",
            "  \"global_step\": 990\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00032520294189453125,\n",
            "  \"model.lr\": 0.00019781100000000002,\n",
            "  \"model.grad_norm\": 0.005919822491705418,\n",
            "  \"model.elapsed_time\": 0.06497049331665039,\n",
            "  \"model.engine_step\": 991,\n",
            "  \"model.loss.nll\": 0.00032520294189453125,\n",
            "  \"elapsed_time\": 0.06497049331665039,\n",
            "  \"wall_time\": 1677241400.5741298,\n",
            "  \"global_step\": 991\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003390312194824219,\n",
            "  \"model.lr\": 0.00019801,\n",
            "  \"model.grad_norm\": 0.005221276544034481,\n",
            "  \"model.elapsed_time\": 0.06720542907714844,\n",
            "  \"model.engine_step\": 992,\n",
            "  \"model.loss.nll\": 0.0003390312194824219,\n",
            "  \"elapsed_time\": 0.06720542907714844,\n",
            "  \"wall_time\": 1677241400.6441858,\n",
            "  \"global_step\": 992\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0019817352294921875,\n",
            "  \"model.lr\": 0.000198209,\n",
            "  \"model.grad_norm\": 0.1422426700592041,\n",
            "  \"model.elapsed_time\": 0.07625293731689453,\n",
            "  \"model.engine_step\": 993,\n",
            "  \"model.loss.nll\": 0.0019817352294921875,\n",
            "  \"elapsed_time\": 0.07625293731689453,\n",
            "  \"wall_time\": 1677241400.7274158,\n",
            "  \"global_step\": 993\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.000881195068359375,\n",
            "  \"model.lr\": 0.00019840800000000002,\n",
            "  \"model.grad_norm\": 0.019578734412789345,\n",
            "  \"model.elapsed_time\": 0.06742525100708008,\n",
            "  \"model.engine_step\": 994,\n",
            "  \"model.loss.nll\": 0.000881195068359375,\n",
            "  \"elapsed_time\": 0.06742525100708008,\n",
            "  \"wall_time\": 1677241400.7968512,\n",
            "  \"global_step\": 994\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0009603500366210938,\n",
            "  \"model.lr\": 0.000198607,\n",
            "  \"model.grad_norm\": 0.026287522166967392,\n",
            "  \"model.elapsed_time\": 0.06634306907653809,\n",
            "  \"model.engine_step\": 995,\n",
            "  \"model.loss.nll\": 0.0009603500366210938,\n",
            "  \"elapsed_time\": 0.06634306907653809,\n",
            "  \"wall_time\": 1677241400.8696113,\n",
            "  \"global_step\": 995\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003457069396972656,\n",
            "  \"model.lr\": 0.00019880600000000002,\n",
            "  \"model.grad_norm\": 0.005912134423851967,\n",
            "  \"model.elapsed_time\": 0.06633639335632324,\n",
            "  \"model.engine_step\": 996,\n",
            "  \"model.loss.nll\": 0.0003457069396972656,\n",
            "  \"elapsed_time\": 0.06633639335632324,\n",
            "  \"wall_time\": 1677241400.9385784,\n",
            "  \"global_step\": 996\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:20\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:21\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0003666877746582031,\n",
            "  \"model.lr\": 0.000199005,\n",
            "  \"model.grad_norm\": 0.007335916627198458,\n",
            "  \"model.elapsed_time\": 0.07164621353149414,\n",
            "  \"model.engine_step\": 997,\n",
            "  \"model.loss.nll\": 0.0003666877746582031,\n",
            "  \"elapsed_time\": 0.07164621353149414,\n",
            "  \"wall_time\": 1677241401.0182574,\n",
            "  \"global_step\": 997\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:21\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.00038504600524902344,\n",
            "  \"model.lr\": 0.000199204,\n",
            "  \"model.grad_norm\": 0.01038294192403555,\n",
            "  \"model.elapsed_time\": 0.0681605339050293,\n",
            "  \"model.engine_step\": 998,\n",
            "  \"model.loss.nll\": 0.00038504600524902344,\n",
            "  \"elapsed_time\": 0.0681605339050293,\n",
            "  \"wall_time\": 1677241401.0888448,\n",
            "  \"global_step\": 998\n",
            "}\n",
            "\u001b[32m2023-02-24 12:23:21\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n",
            "\u001b[32m2023-02-24 12:23:21\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0005888938903808594,\n",
            "  \"model.lr\": 0.00019940300000000002,\n",
            "  \"model.grad_norm\": 0.009885272942483425,\n",
            "  \"model.elapsed_time\": 0.06946921348571777,\n",
            "  \"model.engine_step\": 999,\n",
            "  \"model.loss.nll\": 0.0005888938903808594,\n",
            "  \"elapsed_time\": 0.06946921348571777,\n",
            "  \"wall_time\": 1677241401.1666207,\n",
            "  \"global_step\": 999\n",
            "}\n",
            "[2023-02-24 12:23:21,234] [INFO] [logging.py:75:log_dist] [Rank 0] step=1000, skipped=1, lr=[0.000199602], mom=[(0.9, 0.999)]\n",
            "[2023-02-24 12:23:21,236] [INFO] [timer.py:198:stop] epoch=0/micro_step=1000/global_step=1000, RunningAvgSamplesPerSec=12.444763515682505, CurrSamplesPerSec=14.693604156229966, MemAllocated=0.16GB, MaxMemAllocated=0.3GB\n",
            "\u001b[32m2023-02-24 12:23:21\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\n",
            "  \"model.loss\": 0.0018863677978515625,\n",
            "  \"model.lr\": 0.000199602,\n",
            "  \"model.grad_norm\": 0.08763942867517471,\n",
            "  \"model.elapsed_time\": 0.0684974193572998,\n",
            "  \"model.engine_step\": 1000,\n",
            "  \"model.loss.nll\": 0.0018863677978515625,\n",
            "  \"elapsed_time\": 0.0684974193572998,\n",
            "  \"wall_time\": 1677241401.237227,\n",
            "  \"global_step\": 1000\n",
            "}\n",
            "[2023-02-24 12:23:21,238] [INFO] [logging.py:75:log_dist] [Rank 0] [Torch] Checkpoint default is begin to save!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
            "  warnings.warn(\n",
            "[2023-02-24 12:23:21,241] [INFO] [logging.py:75:log_dist] [Rank 0] Saving model checkpoint: ckpts/test/ar/model/default/mp_rank_00_model_states.pt\n",
            "[2023-02-24 12:23:21,241] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving ckpts/test/ar/model/default/mp_rank_00_model_states.pt...\n",
            "[2023-02-24 12:23:21,633] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved ckpts/test/ar/model/default/mp_rank_00_model_states.pt.\n",
            "[2023-02-24 12:23:21,634] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint default is ready now!\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "  0% 1/300 [00:00<00:09, 30.98it/s]\n",
            " 50% 1/2 [00:00<00:00,  2.11it/s]\n",
            "  0% 1/300 [00:00<00:06, 47.41it/s]\n",
            "100% 2/2 [00:00<00:00,  3.84it/s]\n",
            "\u001b[32m2023-02-24 12:23:22\u001b[0m - \u001b[34m__main__\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "Eval: {'global_step': 1000, 'name': 'subtrain'}.\n",
            "\u001b[32m2023-02-24 12:23:22\u001b[0m - \u001b[34m__main__\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\"global_step\": 1000, \"name\": \"subtrain\"}.\n",
            "0it [00:00, ?it/s]\n",
            "\u001b[32m2023-02-24 12:23:22\u001b[0m - \u001b[34m__main__\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "Eval: {'global_step': 1000, 'name': 'val'}.\n",
            "\u001b[32m2023-02-24 12:23:22\u001b[0m - \u001b[34m__main__\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "{\"global_step\": 1000, \"name\": \"val\"}.\n",
            "\u001b[32m2023-02-24 12:23:22\u001b[0m - \u001b[34mvall_e.utils.trainer\u001b[0m - \u001b[1;30mINFO\u001b[0m - GR=0;LR=0 - \n",
            "New epoch starts.\n"
          ]
        }
      ],
      "source": [
        "!python -m vall_e.train yaml=config/test/ar.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T69JtuU9qEtM"
      },
      "outputs": [],
      "source": [
        "!mkdir -p zoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHIHmtMTgCVq",
        "outputId": "1512ce4a-e2b9-4156-dc7c-a1778e9694f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-02-22 09:41:56,677] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2023-02-22 09:41:59,053] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.6 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu117/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.0766761302947998 seconds\n",
            "[2023-02-22 09:41:59,494] [INFO] [logging.py:75:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2023-02-22 09:41:59,498] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2023-02-22 09:41:59,498] [INFO] [logging.py:75:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n",
            "[2023-02-22 09:41:59,505] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2023-02-22 09:41:59,505] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR\n",
            "[2023-02-22 09:41:59,505] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x7f3d13c9edd0>\n",
            "[2023-02-22 09:41:59,505] [INFO] [logging.py:75:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
            "[2023-02-22 09:41:59,505] [INFO] [config.py:1009:print] DeepSpeedEngine configuration:\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   amp_enabled .................. False\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   amp_params ................... False\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   bfloat16_enabled ............. False\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3d13c9e860>\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   communication_data_type ...... None\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   curriculum_enabled_legacy .... False\n",
            "[2023-02-22 09:41:59,506] [INFO] [config.py:1013:print]   curriculum_params_legacy ..... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   data_efficiency_enabled ...... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   dataloader_drop_last ......... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   disable_allgather ............ False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   dump_state ................... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   dynamic_loss_scale_args ...... None\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_enabled ........... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   eigenvalue_verbose ........... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   elasticity_enabled ........... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   fp16_auto_cast ............... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   fp16_enabled ................. True\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   global_rank .................. 0\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   grad_accum_dtype ............. None\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   gradient_accumulation_steps .. 1\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   gradient_clipping ............ 100.0\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   initial_dynamic_scale ........ 65536\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   load_universal_checkpoint .... False\n",
            "[2023-02-22 09:41:59,507] [INFO] [config.py:1013:print]   loss_scale ................... 0\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   memory_breakdown ............. False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   optimizer_name ............... adam\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   optimizer_params ............. None\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   pld_enabled .................. False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   pld_params ................... False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   prescale_gradients ........... False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   scheduler_name ............... WarmupDecayLR\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   scheduler_params ............. {'warmup_min_lr': 1e-06, 'warmup_max_lr': 0.0002, 'warmup_num_steps': 1000, 'total_num_steps': 1000, 'warmup_type': 'linear'}\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   sparse_attention ............. None\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   sparse_gradients_enabled ..... False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   steps_per_print .............. 10\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   train_batch_size ............. 1\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   train_micro_batch_size_per_gpu  1\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   use_node_local_storage ....... False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   wall_clock_breakdown ......... False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   world_size ................... 1\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   zero_allow_untested_optimizer  False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2023-02-22 09:41:59,508] [INFO] [config.py:1013:print]   zero_enabled ................. False\n",
            "[2023-02-22 09:41:59,509] [INFO] [config.py:1013:print]   zero_optimization_stage ...... 0\n",
            "[2023-02-22 09:41:59,509] [INFO] [config.py:998:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 1, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"lr\": 1e-06\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupDecayLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 1e-06, \n",
            "            \"warmup_max_lr\": 0.0002, \n",
            "            \"warmup_num_steps\": 1000, \n",
            "            \"total_num_steps\": 1000, \n",
            "            \"warmup_type\": \"linear\"\n",
            "        }\n",
            "    }, \n",
            "    \"gradient_clipping\": 100.0, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu117/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0805668830871582 seconds\n",
            "[2023-02-22 09:41:59,590] [INFO] [torch_checkpoint_engine.py:21:load] [Torch] Loading checkpoint from ckpts/test/ar/model/default/mp_rank_00_model_states.pt...\n",
            "[2023-02-22 09:41:59,693] [INFO] [torch_checkpoint_engine.py:23:load] [Torch] Loaded checkpoint from ckpts/test/ar/model/default/mp_rank_00_model_states.pt.\n",
            "[2023-02-22 09:41:59,700] [INFO] [torch_checkpoint_engine.py:21:load] [Torch] Loading checkpoint from ckpts/test/ar/model/default/mp_rank_00_model_states.pt...\n",
            "[2023-02-22 09:41:59,794] [INFO] [torch_checkpoint_engine.py:23:load] [Torch] Loaded checkpoint from ckpts/test/ar/model/default/mp_rank_00_model_states.pt.\n",
            "2it [00:00, 4834.93it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "zoo/ar.pt saved.\n",
            "[2023-02-22 09:42:06,478] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2023-02-22 09:42:09,321] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Installed CUDA version 11.6 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination\n",
            "Using /root/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu117/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.07619261741638184 seconds\n",
            "[2023-02-22 09:42:09,782] [INFO] [logging.py:75:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2023-02-22 09:42:09,784] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2023-02-22 09:42:09,785] [INFO] [logging.py:75:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n",
            "[2023-02-22 09:42:09,791] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2023-02-22 09:42:09,791] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR\n",
            "[2023-02-22 09:42:09,791] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x7f85e6faee60>\n",
            "[2023-02-22 09:42:09,791] [INFO] [logging.py:75:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
            "[2023-02-22 09:42:09,792] [INFO] [config.py:1009:print] DeepSpeedEngine configuration:\n",
            "[2023-02-22 09:42:09,792] [INFO] [config.py:1013:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-02-22 09:42:09,792] [INFO] [config.py:1013:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-02-22 09:42:09,792] [INFO] [config.py:1013:print]   amp_enabled .................. False\n",
            "[2023-02-22 09:42:09,792] [INFO] [config.py:1013:print]   amp_params ................... False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   bfloat16_enabled ............. False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f85e6fae9b0>\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   communication_data_type ...... None\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   curriculum_enabled_legacy .... False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   curriculum_params_legacy ..... False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   data_efficiency_enabled ...... False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   dataloader_drop_last ......... False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   disable_allgather ............ False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   dump_state ................... False\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   dynamic_loss_scale_args ...... None\n",
            "[2023-02-22 09:42:09,793] [INFO] [config.py:1013:print]   eigenvalue_enabled ........... False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   eigenvalue_verbose ........... False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   elasticity_enabled ........... False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   fp16_auto_cast ............... False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   fp16_enabled ................. True\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   global_rank .................. 0\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   grad_accum_dtype ............. None\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   gradient_accumulation_steps .. 1\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   gradient_clipping ............ 100.0\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   initial_dynamic_scale ........ 65536\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   load_universal_checkpoint .... False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   loss_scale ................... 0\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   memory_breakdown ............. False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2023-02-22 09:42:09,794] [INFO] [config.py:1013:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   optimizer_name ............... adam\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   optimizer_params ............. None\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   pld_enabled .................. False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   pld_params ................... False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   prescale_gradients ........... False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   scheduler_name ............... WarmupDecayLR\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   scheduler_params ............. {'warmup_min_lr': 1e-06, 'warmup_max_lr': 0.0002, 'warmup_num_steps': 1000, 'total_num_steps': 1000, 'warmup_type': 'linear'}\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   sparse_attention ............. None\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   sparse_gradients_enabled ..... False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   steps_per_print .............. 10\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   train_batch_size ............. 1\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   train_micro_batch_size_per_gpu  1\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   use_node_local_storage ....... False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   wall_clock_breakdown ......... False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   world_size ................... 1\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   zero_allow_untested_optimizer  False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   zero_enabled ................. False\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:1013:print]   zero_optimization_stage ...... 0\n",
            "[2023-02-22 09:42:09,795] [INFO] [config.py:998:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 1, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"lr\": 1e-06\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupDecayLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 1e-06, \n",
            "            \"warmup_max_lr\": 0.0002, \n",
            "            \"warmup_num_steps\": 1000, \n",
            "            \"total_num_steps\": 1000, \n",
            "            \"warmup_type\": \"linear\"\n",
            "        }\n",
            "    }, \n",
            "    \"gradient_clipping\": 100.0, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu117/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0728905200958252 seconds\n",
            "[2023-02-22 09:42:09,869] [WARNING] [engine.py:2757:load_checkpoint] Unable to find latest file at ckpts/test/nar/model/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.\n",
            "2it [00:00, 5108.77it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "zoo/nar.pt saved.\n"
          ]
        }
      ],
      "source": [
        "!python -m vall_e.export zoo/ar.pt yaml=config/test/ar.yml\n",
        "!python -m vall_e.export zoo/nar.pt yaml=config/test/nar.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNxsVmZLgDAP",
        "outputId": "ed5911ae-d37b-4a01-de4e-f42f60b66ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 15% 152/1000 [00:04<00:22, 37.87it/s]\n",
            "toy.wav saved.\n"
          ]
        }
      ],
      "source": [
        "!python -m vall_e 'hello world' data/test/test.wav toy.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "JKFp5-XYgRjP",
        "outputId": "527c3d5e-b9c5-4d67-c99e-f28fa03e9a34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Audio\n",
        "Audio('toy.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXrM2nKcgYvg",
        "outputId": "b31d1f0f-1715-4a4c-e80f-d657b6826490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build\tdata\t       logs\t  setup.py  vall_e.egg-info\n",
            "ckpts\thello_toy.wav  README.md  toy.wav   vall-e.png\n",
            "config\tLICENSE        scripts\t  vall_e    zoo\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "with open('data/hello.txt', 'w') as f:\n",
        "    f.write(\"Hello Valle how's you doing nowadays\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY3DY3OehsRF"
      },
      "outputs": [],
      "source": [
        "!cd data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXCEt-7fhu3j"
      },
      "outputs": [],
      "source": [
        "!touch hello_toy.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoJVF4F1h8mk"
      },
      "outputs": [],
      "source": [
        "!python -m vall_e 'hello world' data/test/test.wav hello_toy.wav"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2HKuPu1nShg04fdGdguFJ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}